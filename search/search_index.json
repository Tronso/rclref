{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to the rclref develoment site riak_core is a distributed systems framework that is based on the Dynamo-Style architecture. It has served as the basis of Riak KV, a highly available masterless distributed database, providing essential features for controlling the behaviour of nodes in a database cluster. riak_core_lite is an updated version of riak_core which ensures compatibility with the recent OTP version and rebar, a build tool for erlang application and releases. rclref is a reference implementation of a key-value store built on riak_core_lite. rclref was created as part of Google Summer of Code 2020 with the aim of exercising various APIs of riak_core_lite with documented support. This implementation can also be used for detecting regressions and serve as a starting point to try new ideas and show how different parts of riak_core_lite are used in practice. Tip Updated version of the code is here . Summary Describe my work briefly Implemented a riak_core_lite based distributed application. What is done Created a RiakKV-like sample key-value store application on riak_core_lite with documents of the implemented features. Introduced how to test an Erlang distributed application using Common Test framework. Introduced how to benchmark key-value application using rcl_bench . TODO Show benchmark results of rclref with riak_core backend and compare it with riak_core_lite. Abstract the testing module for more generic use. Use CRDTs for merging the replicated values. Development languages and tools The code is fully written in Erlang OTP >= 22. License rclref is released under Apache License, Version 2.0 Table of Cotents How to setup riak_core_lite application? How are put, get, delete implemented in rclref? How to test distributed Erlang application using Common Test? How to benchmark riak_core_lite application? How to actually use rclref? Other","title":"Home"},{"location":"#welcome-to-the-rclref-develoment-site","text":"riak_core is a distributed systems framework that is based on the Dynamo-Style architecture. It has served as the basis of Riak KV, a highly available masterless distributed database, providing essential features for controlling the behaviour of nodes in a database cluster. riak_core_lite is an updated version of riak_core which ensures compatibility with the recent OTP version and rebar, a build tool for erlang application and releases. rclref is a reference implementation of a key-value store built on riak_core_lite. rclref was created as part of Google Summer of Code 2020 with the aim of exercising various APIs of riak_core_lite with documented support. This implementation can also be used for detecting regressions and serve as a starting point to try new ideas and show how different parts of riak_core_lite are used in practice. Tip Updated version of the code is here .","title":"Welcome to the rclref develoment site"},{"location":"#summary","text":"","title":"Summary"},{"location":"#describe-my-work-briefly","text":"Implemented a riak_core_lite based distributed application.","title":"Describe my work briefly"},{"location":"#what-is-done","text":"Created a RiakKV-like sample key-value store application on riak_core_lite with documents of the implemented features. Introduced how to test an Erlang distributed application using Common Test framework. Introduced how to benchmark key-value application using rcl_bench .","title":"What is done"},{"location":"#todo","text":"Show benchmark results of rclref with riak_core backend and compare it with riak_core_lite. Abstract the testing module for more generic use. Use CRDTs for merging the replicated values.","title":"TODO"},{"location":"#development-languages-and-tools","text":"The code is fully written in Erlang OTP >= 22.","title":"Development languages and tools"},{"location":"#license","text":"rclref is released under Apache License, Version 2.0","title":"License"},{"location":"#table-of-cotents","text":"How to setup riak_core_lite application? How are put, get, delete implemented in rclref? How to test distributed Erlang application using Common Test? How to benchmark riak_core_lite application? How to actually use rclref? Other","title":"Table of Cotents"},{"location":"backend/","text":"Backend Warning Please check out the repository for the latest code. As shown in the diagram, each vnode will have their own backend to store the key-value. Backend Behaviour In order to make a generic backend that can support storages engines like ets or dets or even other modules depending on the user's preference, we will first implement a backend behaviour called rclref_backend.erl . In this module, we will declare functions that are essential for a backend to work. - module ( rclref_backend ). - type state () :: term (). - type fold_keys_fun () :: fun (( term (), any ()) -> any () | no_return ()). - type fold_objects_fun () :: fun (( term (), term (), any ()) -> any () | no_return ()). - type fold_acc () :: term (). - type fold_opts () :: [ term ()]. - type fold_result () :: { ok , fold_acc ()} | { async , fun ()} | { error , term ()}. - callback start ( PartitionIndex :: non_neg_integer (), Config :: [{ atom (), term ()}]) -> { ok , state ()}. - callback stop ( state ()) -> ok . - callback get ( rclref_object : key (), state ()) -> { ok , Value :: term (), state ()} | { ok , not_found , state ()} | { error , term (), state ()}. - callback put ( rclref_object : key (), Value :: binary (), state ()) -> { ok , state ()} | { error , term (), state ()}. - callback delete ( rclref_object : key (), state ()) -> { ok , state ()} | { error , term (), state ()}. - callback drop ( state ()) -> { ok , state ()} | { error , term (), state ()}. - callback fold_keys ( fold_keys_fun (), fold_acc (), fold_opts (), state ()) -> fold_result (). - callback fold_objects ( fold_objects_fun (), fold_acc (), fold_opts (), state ()) -> fold_result (). - callback is_empty ( state ()) -> boolean () | { error , term ()}. - callback status ( state ()) -> [{ atom (), term ()}]. ETS backend After implementing rclref_backend.erl , we need to implement an actual backend that utilizes this behaviour. rclref_ets_backend.erl is a sample implementation of a backend using Erlang Term Storage (ets). - module ( rclref_ets_backend ). - behaviour ( rclref_backend ). - record ( state , { table_id }). - export ([ start / 2 , stop / 1 , get / 2 , put / 3 , delete / 2 , drop / 1 , fold_keys / 3 , fold_keys / 4 , fold_objects / 3 , fold_objects / 4 , is_empty / 1 , status / 1 ]). start (_ PartitionIndex , _ Config ) -> TableId = ets : new ( ? MODULE , [ set , { write_concurrency , false }, { read_concurrency , false }]), State = #state { table_id = TableId }, { ok , State }. stop (_ State = #state { table_id = TableId }) -> true = ets : delete ( TableId ), ok . get ( Key , State = #state { table_id = TableId }) -> case ets : lookup ( TableId , Key ) of [] -> { ok , not_found , State }; [{_, Value }] -> { ok , Value , State }; Reason -> { error , Reason , State } end . put ( Key , Value , State = #state { table_id = TableId }) -> true = ets : insert ( TableId , { Key , Value }), { ok , State }. delete ( Key , State = #state { table_id = TableId }) -> true = ets : delete ( TableId , Key ), { ok , State }. drop ( State = #state { table_id = TableId }) -> true = ets : delete_all_objects ( TableId ), { ok , State }. is_empty (_ State = #state { table_id = TableId }) -> ets : first ( TableId ) =:= '$end_of_table' . fold_keys ( Fun , Acc , State ) -> fold_keys ( Fun , Acc , [], State ). fold_keys ( Fun , Acc0 , _ Options , _ State = #state { table_id = TableId }) -> FoldKeysFun = fun ({ K , _}, A ) -> Fun ( K , A ) end , ets : foldl ( FoldKeysFun , Acc0 , TableId ). fold_objects ( Fun , Acc , State ) -> fold_objects ( Fun , Acc , [], State ). fold_objects ( Fun , Acc0 , _ Options , _ State = #state { table_id = TableId }) -> FoldObjectsFun = fun ({ K , V }, A ) -> Fun ( K , V , A ) end , ets : foldl ( FoldObjectsFun , Acc0 , TableId ). status (_ State = #state { table_id = TableId }) -> ets : info ( TableId ). DETS backend Implementation using disk-based term storage (dets) is also provided in rclref_dets_backend . - module ( rclref_dets_backend ). - behaviour ( rclref_backend ). - record ( state , { table_id }). - export ([ start / 2 , stop / 1 , get / 2 , put / 3 , delete / 2 , drop / 1 , fold_keys / 3 , fold_keys / 4 , fold_objects / 3 , fold_objects / 4 , is_empty / 1 , status / 1 ]). start ( Partition , _ Config ) -> { ok , TableId } = dets : open_file ( integer_to_list ( Partition ), [{ type , set }]), State = #state { table_id = TableId }, { ok , State }. stop (_ State = #state { table_id = TableId }) -> ok = dets : close ( TableId ), ok . get ( Key , State = #state { table_id = TableId }) -> case dets : lookup ( TableId , Key ) of [] -> { ok , not_found , State }; [{_, Value }] -> { ok , Value , State }; Reason -> { error , Reason , State } end . put ( Key , Value , State = #state { table_id = TableId }) -> ok = dets : insert ( TableId , { Key , Value }), { ok , State }. delete ( Key , State = #state { table_id = TableId }) -> ok = dets : delete ( TableId , Key ), { ok , State }. drop ( State = #state { table_id = TableId }) -> ok = dets : delete_all_objects ( TableId ), { ok , State }. is_empty (_ State = #state { table_id = TableId }) -> dets : first ( TableId ) =:= '$end_of_table' . fold_keys ( Fun , Acc , State ) -> fold_keys ( Fun , Acc , [], State ). fold_keys ( Fun , Acc0 , _ Options , _ State = #state { table_id = TableId }) -> FoldKeysFun = fun ({ K , _}, A ) -> Fun ( K , A ) end , dets : foldl ( FoldKeysFun , Acc0 , TableId ). fold_objects ( Fun , Acc , State ) -> fold_objects ( Fun , Acc , [], State ). fold_objects ( Fun , Acc0 , _ Options , _ State = #state { table_id = TableId }) -> FoldObjectsFun = fun ({ K , V }, A ) -> Fun ( K , V , A ) end , dets : foldl ( FoldObjectsFun , Acc0 , TableId ). status (_ State = #state { table_id = TableId }) -> dets : info ( TableId ).","title":"Backend"},{"location":"backend/#backend","text":"Warning Please check out the repository for the latest code. As shown in the diagram, each vnode will have their own backend to store the key-value.","title":"Backend"},{"location":"backend/#backend-behaviour","text":"In order to make a generic backend that can support storages engines like ets or dets or even other modules depending on the user's preference, we will first implement a backend behaviour called rclref_backend.erl . In this module, we will declare functions that are essential for a backend to work. - module ( rclref_backend ). - type state () :: term (). - type fold_keys_fun () :: fun (( term (), any ()) -> any () | no_return ()). - type fold_objects_fun () :: fun (( term (), term (), any ()) -> any () | no_return ()). - type fold_acc () :: term (). - type fold_opts () :: [ term ()]. - type fold_result () :: { ok , fold_acc ()} | { async , fun ()} | { error , term ()}. - callback start ( PartitionIndex :: non_neg_integer (), Config :: [{ atom (), term ()}]) -> { ok , state ()}. - callback stop ( state ()) -> ok . - callback get ( rclref_object : key (), state ()) -> { ok , Value :: term (), state ()} | { ok , not_found , state ()} | { error , term (), state ()}. - callback put ( rclref_object : key (), Value :: binary (), state ()) -> { ok , state ()} | { error , term (), state ()}. - callback delete ( rclref_object : key (), state ()) -> { ok , state ()} | { error , term (), state ()}. - callback drop ( state ()) -> { ok , state ()} | { error , term (), state ()}. - callback fold_keys ( fold_keys_fun (), fold_acc (), fold_opts (), state ()) -> fold_result (). - callback fold_objects ( fold_objects_fun (), fold_acc (), fold_opts (), state ()) -> fold_result (). - callback is_empty ( state ()) -> boolean () | { error , term ()}. - callback status ( state ()) -> [{ atom (), term ()}].","title":"Backend Behaviour"},{"location":"backend/#ets-backend","text":"After implementing rclref_backend.erl , we need to implement an actual backend that utilizes this behaviour. rclref_ets_backend.erl is a sample implementation of a backend using Erlang Term Storage (ets). - module ( rclref_ets_backend ). - behaviour ( rclref_backend ). - record ( state , { table_id }). - export ([ start / 2 , stop / 1 , get / 2 , put / 3 , delete / 2 , drop / 1 , fold_keys / 3 , fold_keys / 4 , fold_objects / 3 , fold_objects / 4 , is_empty / 1 , status / 1 ]). start (_ PartitionIndex , _ Config ) -> TableId = ets : new ( ? MODULE , [ set , { write_concurrency , false }, { read_concurrency , false }]), State = #state { table_id = TableId }, { ok , State }. stop (_ State = #state { table_id = TableId }) -> true = ets : delete ( TableId ), ok . get ( Key , State = #state { table_id = TableId }) -> case ets : lookup ( TableId , Key ) of [] -> { ok , not_found , State }; [{_, Value }] -> { ok , Value , State }; Reason -> { error , Reason , State } end . put ( Key , Value , State = #state { table_id = TableId }) -> true = ets : insert ( TableId , { Key , Value }), { ok , State }. delete ( Key , State = #state { table_id = TableId }) -> true = ets : delete ( TableId , Key ), { ok , State }. drop ( State = #state { table_id = TableId }) -> true = ets : delete_all_objects ( TableId ), { ok , State }. is_empty (_ State = #state { table_id = TableId }) -> ets : first ( TableId ) =:= '$end_of_table' . fold_keys ( Fun , Acc , State ) -> fold_keys ( Fun , Acc , [], State ). fold_keys ( Fun , Acc0 , _ Options , _ State = #state { table_id = TableId }) -> FoldKeysFun = fun ({ K , _}, A ) -> Fun ( K , A ) end , ets : foldl ( FoldKeysFun , Acc0 , TableId ). fold_objects ( Fun , Acc , State ) -> fold_objects ( Fun , Acc , [], State ). fold_objects ( Fun , Acc0 , _ Options , _ State = #state { table_id = TableId }) -> FoldObjectsFun = fun ({ K , V }, A ) -> Fun ( K , V , A ) end , ets : foldl ( FoldObjectsFun , Acc0 , TableId ). status (_ State = #state { table_id = TableId }) -> ets : info ( TableId ).","title":"ETS backend"},{"location":"backend/#dets-backend","text":"Implementation using disk-based term storage (dets) is also provided in rclref_dets_backend . - module ( rclref_dets_backend ). - behaviour ( rclref_backend ). - record ( state , { table_id }). - export ([ start / 2 , stop / 1 , get / 2 , put / 3 , delete / 2 , drop / 1 , fold_keys / 3 , fold_keys / 4 , fold_objects / 3 , fold_objects / 4 , is_empty / 1 , status / 1 ]). start ( Partition , _ Config ) -> { ok , TableId } = dets : open_file ( integer_to_list ( Partition ), [{ type , set }]), State = #state { table_id = TableId }, { ok , State }. stop (_ State = #state { table_id = TableId }) -> ok = dets : close ( TableId ), ok . get ( Key , State = #state { table_id = TableId }) -> case dets : lookup ( TableId , Key ) of [] -> { ok , not_found , State }; [{_, Value }] -> { ok , Value , State }; Reason -> { error , Reason , State } end . put ( Key , Value , State = #state { table_id = TableId }) -> ok = dets : insert ( TableId , { Key , Value }), { ok , State }. delete ( Key , State = #state { table_id = TableId }) -> ok = dets : delete ( TableId , Key ), { ok , State }. drop ( State = #state { table_id = TableId }) -> ok = dets : delete_all_objects ( TableId ), { ok , State }. is_empty (_ State = #state { table_id = TableId }) -> dets : first ( TableId ) =:= '$end_of_table' . fold_keys ( Fun , Acc , State ) -> fold_keys ( Fun , Acc , [], State ). fold_keys ( Fun , Acc0 , _ Options , _ State = #state { table_id = TableId }) -> FoldKeysFun = fun ({ K , _}, A ) -> Fun ( K , A ) end , dets : foldl ( FoldKeysFun , Acc0 , TableId ). fold_objects ( Fun , Acc , State ) -> fold_objects ( Fun , Acc , [], State ). fold_objects ( Fun , Acc0 , _ Options , _ State = #state { table_id = TableId }) -> FoldObjectsFun = fun ({ K , V }, A ) -> Fun ( K , V , A ) end , dets : foldl ( FoldObjectsFun , Acc0 , TableId ). status (_ State = #state { table_id = TableId }) -> dets : info ( TableId ).","title":"DETS backend"},{"location":"benchmark/","text":"How to benchmark riak_core_lite application? How to configure rcl_bench? rcl_bench is a benchmarking tools for key-value store application. It is a lighter verison of basho_bench and it is easy to use. To use it, first clone the rcl_bench repository. git clone git@github.com:riak-core-lite/rcl_bench.git Configure rcl_bench To configure rcl_bench, you need to modify the following in rcl_bench repo. config/sys.config config/vm.args The sys.config for benchmarking rclref was below. {rcl_bench, [ %% Mode of load generation: %% max - Generate as many requests as possible per worker %% {rate, Rate} - Exp. distributed Mean reqs/sec %% {rate, max} - as fast as possible {mode, {rate, max}}, %% Base test output directory {test_dir, \"tests\"}, %% Test duration (minutes) {duration, 15}, %% Number of concurrent workers {concurrent, 4}, %% Operations (and associated mix) {operations, [{get_own_puts, 3}, {put, 10}, {get, 2}]}, %% Key generators %% {uniform_int, N} - Choose a uniformly distributed integer between 0 and N {key_generator, {uniform_int, 100000}}, %% Value generators %% {fixed_bin, N} - Fixed size binary blob of N bytes {value_generator, {fixed_bin, 100}}, {random_algorithm, exsss}, {random_seed, {1,4,3}}, {ip, '127.0.0.1'}, {port, 8080} ]} The important part in the snippet above is the operations tuple. %% Operations (and associated mix) {operations, [{get_own_puts, 3}, {put, 10}, {get, 2}]}, Associated mix is the weight of the operations. This means that on average, it will execute get_own_puts 3/15, put 10/15, get 2/15. The contents of the operations are implemented in the rcl_bench_dirver.erl module. Implement more operations in rcl_bench_dirver.erl If new operations are added and you want to benchmark them, you need to add it in the sys.config as well. For testing rclref, the following operations are implemented. get_own_puts : get a stored value get : get a value put : put a value Run the benchmark after starting the database application. Start rclref and then run the follwoing in rcl_bench repository. make run Where to find the results? The results of the benchmark are stored as csv in rcl_bench/_build/default/rel/rcl_bench/tests . The current results can be found in the current directory as well. Run the R script in the R directory to visualize the results by reading the csvs in the current directory. Rscript latency.R TITILE_OF_CSV Rscript throughput.R TITLE_OF_CSV To see the results of all the operations, concatenate the result csvs in the current directory. cat get_single.csv get-own-puts_single.csv put_single.csv | sed '2, $s/timestamp, unit, microseconds//g' >> all_single.csv Then you can visualize by the following commnand in the R directory. Rscript throughput.R all_single Rscript latency.R all_single This will create png file of the result. Results of benchmarking rcl_bench The results of benchmarking rclref were the follwoing. Environment Processor Name Dual-Core Intel Core i5 Processor Speed 2 GHz Number of Processors 1 Total Number of Cores 2 L2 Cache (per Core) 256 KB L3 Cache 4 MB Memory 8 GB Single node A single node cluster with N=3, R=1, W=1 using ETS as backend. Multi node 3 node cluster with N=3, R=1, W=1 using ETS as backend.","title":"How to benchmark riak_core_lite application?"},{"location":"benchmark/#how-to-benchmark-riak_core_lite-application","text":"","title":"How to benchmark riak_core_lite application?"},{"location":"benchmark/#how-to-configure-rcl_bench","text":"rcl_bench is a benchmarking tools for key-value store application. It is a lighter verison of basho_bench and it is easy to use. To use it, first clone the rcl_bench repository. git clone git@github.com:riak-core-lite/rcl_bench.git Configure rcl_bench To configure rcl_bench, you need to modify the following in rcl_bench repo. config/sys.config config/vm.args The sys.config for benchmarking rclref was below. {rcl_bench, [ %% Mode of load generation: %% max - Generate as many requests as possible per worker %% {rate, Rate} - Exp. distributed Mean reqs/sec %% {rate, max} - as fast as possible {mode, {rate, max}}, %% Base test output directory {test_dir, \"tests\"}, %% Test duration (minutes) {duration, 15}, %% Number of concurrent workers {concurrent, 4}, %% Operations (and associated mix) {operations, [{get_own_puts, 3}, {put, 10}, {get, 2}]}, %% Key generators %% {uniform_int, N} - Choose a uniformly distributed integer between 0 and N {key_generator, {uniform_int, 100000}}, %% Value generators %% {fixed_bin, N} - Fixed size binary blob of N bytes {value_generator, {fixed_bin, 100}}, {random_algorithm, exsss}, {random_seed, {1,4,3}}, {ip, '127.0.0.1'}, {port, 8080} ]} The important part in the snippet above is the operations tuple. %% Operations (and associated mix) {operations, [{get_own_puts, 3}, {put, 10}, {get, 2}]}, Associated mix is the weight of the operations. This means that on average, it will execute get_own_puts 3/15, put 10/15, get 2/15. The contents of the operations are implemented in the rcl_bench_dirver.erl module. Implement more operations in rcl_bench_dirver.erl If new operations are added and you want to benchmark them, you need to add it in the sys.config as well. For testing rclref, the following operations are implemented. get_own_puts : get a stored value get : get a value put : put a value Run the benchmark after starting the database application. Start rclref and then run the follwoing in rcl_bench repository. make run","title":"How to configure rcl_bench?"},{"location":"benchmark/#where-to-find-the-results","text":"The results of the benchmark are stored as csv in rcl_bench/_build/default/rel/rcl_bench/tests . The current results can be found in the current directory as well. Run the R script in the R directory to visualize the results by reading the csvs in the current directory. Rscript latency.R TITILE_OF_CSV Rscript throughput.R TITLE_OF_CSV To see the results of all the operations, concatenate the result csvs in the current directory. cat get_single.csv get-own-puts_single.csv put_single.csv | sed '2, $s/timestamp, unit, microseconds//g' >> all_single.csv Then you can visualize by the following commnand in the R directory. Rscript throughput.R all_single Rscript latency.R all_single This will create png file of the result.","title":"Where to find the results?"},{"location":"benchmark/#results-of-benchmarking-rcl_bench","text":"The results of benchmarking rclref were the follwoing.","title":"Results of benchmarking rcl_bench"},{"location":"benchmark/#environment","text":"Processor Name Dual-Core Intel Core i5 Processor Speed 2 GHz Number of Processors 1 Total Number of Cores 2 L2 Cache (per Core) 256 KB L3 Cache 4 MB Memory 8 GB","title":"Environment"},{"location":"benchmark/#single-node","text":"A single node cluster with N=3, R=1, W=1 using ETS as backend.","title":"Single node"},{"location":"benchmark/#multi-node","text":"3 node cluster with N=3, R=1, W=1 using ETS as backend.","title":"Multi node"},{"location":"coordinator/","text":"Coordinator Warning Please check out the repository for the latest code. This page provides an overview of how coordinators are implemented in rclref. What does a coordinator do? Applications that use distributed databases tend to store multiple versions of the same object because it results in better fault tolerance. In riak_core_lite, this is done by distributing the same request to multiple vnodes such as putting a key-value. When a client requests a key-value, even when the primary vnode responsible for the key-value is not responding due to a failure, it is possible to retrieve it from other nodes with the replicas. The coordinator is responsible for distributing the request to the vnodes and collecting the results from them. How many replicas does it make? To understand the mechanism of replication we need to understand the N, R, and W values. These are numbers that defines the level of fault tolerancy and reliability of the operations. N Number of how many replicas it will store in the backend. R Number of how many responses the coordinator will receive from the vnodes on get before it will return the result to the client W Number of how many responses the coordinator will receive from the vnodes on put before it will return the result to the client For instance, if N=3, R=1, and W=2, this means whenever a client issues a request, these request will be sent to 3 vnodes by the coordinator. If it is a get request, the coordinator will wait for 1 vnode to respond with the data and send it back to the client. If it is a put request, the coordinator will wait for 2 vnodes to respond and send it back to the client. If N is large, it results in better fault tolerance because it is likely that the copies be distributed to different nodes in the cluster by the consistent hashing algorithm. This, however, also means that it will take more time for a request to terminate. If R is small, it results in better throughput for get request. This, however, means that the reliability of the data is comparatively low because it will only wait for a partial number of vnodes to respond. If W is small, it results in better throughput for put request. This, however, means that the reliability of the put has succeeded is comparatively low because it will only wait for a partial number of vnodes to respond. Implementation details There are 3 coordinators in rclref: rclref_put_statem.erl , rclref_get_statem.erl , rclref_coverage_fsm . put coordinator A put coordinator is in rclref_put_statem.erl . This is implemented using gen_statem behaviour with 1 main state, which is waiting. On initialize, it will send the put request to N vnodes. Then in the waiting state, it will wait for either of the condition holds. W vnodes respond with ok N-W vnodes respond with errror % State function % WAITING STATE will wait for the responses from vnodes until % When a vnode return {ok, RObj} waiting ( cast , { ok , RObj }, State = #state { req_id = ReqId , client_pid = ClientPid , w_val = W , num_ok = NumOk0 , riak_objects = RObjs0 }) -> % Update State RObjs = [ RObj ] ++ RObjs0 , NumOk = NumOk0 + 1 , NewState = State #state { num_ok = NumOk , riak_objects = RObjs }, % When more than or equal to W vnodes responded with {ok, RObj}, return W RObjs to client case NumOk >= W of true -> ClientPid ! { ReqId , { ok , RObjs }}, { stop , normal , NewState }; false -> { keep_state , NewState } end ; % When a vnode return {error, VnodeError} waiting ( cast , { error , VnodeError }, State = #state { req_id = ReqId , client_pid = ClientPid , n_val = N , w_val = W , num_vnode_error = NumVnodeError0 , vnode_errors = VnodeErrors0 , riak_objects = RObjs0 }) -> % Update State NumVnodeError = NumVnodeError0 + 1 , VnodeErrors = [ VnodeError ] ++ VnodeErrors0 , NewState = State #state { num_vnode_error = NumVnodeError , vnode_errors = VnodeErrors }, % When more than (N-W) vnodes responded with {error, VnodeError}, return all RObjs and VnodeErrors it has received to client case NumVnodeError > N - W of true -> ClientPid ! { ReqId , {{ ok , RObjs0 }, { error , VnodeErrors }}}, { stop , normal , NewState }; false -> { keep_state , NewState } end ; waiting ( state_timeout , hard_stop , State = #state { req_id = ReqId , client_pid = ClientPid }) -> ClientPid ! { ReqId , { error , timeout }}, { stop , waiting_timed_out , State }; waiting (_ EventType , _ EventContent , State = #state {}) -> { keep_state , State }. get coordinator A get coordinator is in rclref_get_statem . It is also implemented using gen_statem behaviour which has two main states, waiting and finalize. On initialize, the get coordinator will send the get requests to N vnodes. Then in the waiting state, it wait until either of the conditions holds. R vnodes respond with a valid value N-R vnodes respond with an error After the waiting state, it will transit to the finalize state where it repairs the values of the vnodes with broken data. In transit state, the get coordinator will first wait for N vnodes to respond and then compute the latest value using the vector clocks of the valid values it has received. Then, it will send this latest value to the vnodes which did not respond with a valid value. This is called read_repair and you can read more about it here . % FINALIZE STATE will wait for ?N vnodes to return response and then issue read_pair % When a vnode returns {ok, RObj} finalize ( cast , { ok , RObj }, State = #state { n_val = N , num_ok = NumOk0 , num_vnode_error = NumVnodeError0 , riak_objects = RObjs0 , undefined_objects = UObjs0 }) -> % Update State case rclref_object : value ( RObj ) of undefined -> NumVnodeError = NumVnodeError0 + 1 , UObjs = UObjs0 ++ [ RObj ], NumOk = NumOk0 , RObjs = RObjs0 ; _ -> NumVnodeError = NumVnodeError0 , UObjs = UObjs0 , NumOk = NumOk0 + 1 , RObjs = RObjs0 ++ [ RObj ] end , NewState = State #state { num_ok = NumOk , num_vnode_error = NumVnodeError , riak_objects = RObjs , undefined_objects = UObjs }, % When all ?N vnodes has responded, do read_repair case NumOk + NumVnodeError >= N of true -> MergedRObj = rclref_object : merge ( RObjs ++ UObjs ), ok = repair ( MergedRObj , N , RObjs ++ UObjs ), { stop , normal , NewState }; false -> { keep_state , NewState } end ; % When a vnode returns {error, VnodeError} finalize ( cast , { error , VnodeError }, State = #state { n_val = N , num_ok = NumOk0 , num_vnode_error = NumVnodeError0 , riak_objects = RObjs0 , undefined_objects = UObjs0 , vnode_errors = VnodeErrors0 }) -> % Update Satte NumVnodeError = NumVnodeError0 + 1 , VnodeErrors = VnodeErrors0 ++ [ VnodeError ], NewState = State #state { num_vnode_error = NumVnodeError , vnode_errors = VnodeErrors }, % When all ?N vnodes has responded, do read_repair case NumOk0 + NumVnodeError >= N of true -> case RObjs0 ++ UObjs0 of % When any of the vnodes responded with {ok, RObj}, do not issue read_repair [] -> { stop , normal , NewState }; _ -> MergedRObj = rclref_object : merge ( RObjs0 ++ UObjs0 ), ok = repair ( MergedRObj , N , RObjs0 ++ UObjs0 ), { stop , normal , NewState } end ; false -> { keep_state , NewState } end ; % When finalize state timeouts, issue a read_repair finalize ( state_timeout , hard_stop , State = #state { n_val = N , riak_objects = RObjs , undefined_objects = UObjs }) -> case RObjs ++ UObjs of [] -> { stop , normal , State }; _ -> MergedRObj = rclref_object : merge ( RObjs ++ UObjs ), ok = repair ( MergedRObj , N , RObjs ++ UObjs ), { stop , normal , State } end ; finalize (_ EventType , _ EventContent , State = #state {}) -> { keep_state , State }. % Use RObj to repair vnodes with different content (i.e Value, VClock) repair ( RObj , N , RObjs ) -> Key = rclref_object : key ( RObj ), Content = rclref_object : content ( RObj ), % Exclude repairing of vnodes that has the same content OkNodesIndexes = [{ rclref_object : partition ( X ), rclref_object : node ( X )} || X <- RObjs , Key =:= rclref_object : key ( X ), Content =:= rclref_object : content ( X )], DocIdx = riak_core_util : chash_key ({ Key , undefined }), PrefList = riak_core_apl : get_primary_apl ( DocIdx , N , rclref ), lists : foreach ( fun ({ IndexNode , _}) -> case lists : member ( IndexNode , OkNodesIndexes ) of false -> logger : info ( \"Sending repair RObj: ~p to IndexNode: ~p \" , [ RObj , IndexNode ]), riak_core_vnode_master : command ( IndexNode , { repair_request , RObj }, rclref_vnode_master ); _ -> ok end end , PrefList ), ok . coverage coordinator The coverage coordinator is implmeneted using riak_core_coverage_fsm behaviour. In rclref, there are two types of coverage calls. unique This coverage call will request for one replica per key. This means that the coverage plan aims to send the request to a minimum number of vnode which can cover all the unique keys existing in the backend. all This coverage call will request for all replicas per key. This means that the coverage plan aims to send the request to ALL the vnodes which is compuationally very expensive. You can see the difference between them in the return value of the init funciton. Read this page for more details. - module ( rclref_coverage_fsm ). - behaviour ( riak_core_coverage_fsm ). - export ([ start_link / 1 ]). - export ([ init / 2 , process_results / 2 , finish / 2 ]). - define ( N , rclref_config : n_val ()). - define ( W , rclref_config : w_val ()). - define ( R , rclref_config : r_val ()). - define ( TIMEOUT_COVERAGE , rclref_config : timeout_coverage ()). - record ( state , { req_id , client_pid , request , accum = []}). start_link ([ ReqId , Client_Pid , _ Client_Node , Request , Options ]) -> Timeout = proplists : get_value ( timeout , Options , ? TIMEOUT_COVERAGE ), riak_core_coverage_fsm : start_link ( ? MODULE , { pid , ReqId , Client_Pid }, [ Request , Timeout ]). % Callbacks % Client_Pid: Pid, Client_Node: Node init ({ pid , ReqId , Client_Pid }, [ Request = { unique , _}, Timeout ]) -> logger : info ( \"Initializing CoverageFsm, Pid: ~p \" , [ self ()]), State = #state { req_id = ReqId , client_pid = Client_Pid , request = Request , accum = []}, { Request , allup , ? N , 1 , rclref , rclref_vnode_master , Timeout , State }; init ({ pid , ReqId , Client_Pid }, [ Request = { all , _}, Timeout ]) -> logger : info ( \"Initializing CoverageFsm, Pid: ~p \" , [ self ()]), State = #state { req_id = ReqId , client_pid = Client_Pid , request = Request , accum = []}, { Request , allup , ? N , ? N , rclref , rclref_vnode_master , Timeout , State }. process_results ({{_ ReqId , {_ Partition , _ Node }}, []}, State ) -> { done , State }; process_results ({{_ ReqId , {_ Partition , _ Node }}, Data }, State = #state { accum = Accum }) -> % If you need to get which partition and node the data comes from % NewAccum = [{Partition, Node, Data} | Accum], NewAccum = Data ++ Accum , { done , State #state { accum = NewAccum }}. finish ( clean , State = #state { req_id = ReqId , request = { unique , _}, client_pid = Client_Pid , accum = Accum }) -> logger : info ( \"Terminating CoverageFsm, Pid: ~p \" , [ self ()]), NewAccum = lists : usort ( Accum ), Client_Pid ! { ReqId , { ok , NewAccum }}, { stop , normal , State }; finish ( clean , State = #state { req_id = ReqId , request = { all , _}, client_pid = Client_Pid , accum = Accum }) -> logger : info ( \"Terminating CoverageFsm, Pid: ~p \" , [ self ()]), Client_Pid ! { ReqId , { ok , Accum }}, { stop , normal , State }; finish ({ error , Reason }, State = #state { req_id = ReqId , request = { unique , _}, client_pid = Client_Pid , accum = Accum }) -> logger : error ( \"Coverage query failed! Reason: ~p \" , [ Reason ]), NewAccum = lists : usort ( Accum ), Client_Pid ! { ReqId , { partial , Reason , NewAccum }}, { stop , normal , State }; finish ({ error , Reason }, State = #state { req_id = ReqId , request = { all , _}, client_pid = Client_Pid , accum = Accum }) -> logger : error ( \"Coverage query failed! Reason: ~p \" , [ Reason ]), Client_Pid ! { ReqId , { partial , Reason , Accum }}, { stop , normal , State }. process_results function will be used to concatenate results from different vnodes. After receiving all the responses, finish will be called. This will send back the coverage result to the client.","title":"Coordinator"},{"location":"coordinator/#coordinator","text":"Warning Please check out the repository for the latest code. This page provides an overview of how coordinators are implemented in rclref.","title":"Coordinator"},{"location":"coordinator/#what-does-a-coordinator-do","text":"Applications that use distributed databases tend to store multiple versions of the same object because it results in better fault tolerance. In riak_core_lite, this is done by distributing the same request to multiple vnodes such as putting a key-value. When a client requests a key-value, even when the primary vnode responsible for the key-value is not responding due to a failure, it is possible to retrieve it from other nodes with the replicas. The coordinator is responsible for distributing the request to the vnodes and collecting the results from them.","title":"What does a coordinator do?"},{"location":"coordinator/#how-many-replicas-does-it-make","text":"To understand the mechanism of replication we need to understand the N, R, and W values. These are numbers that defines the level of fault tolerancy and reliability of the operations. N Number of how many replicas it will store in the backend. R Number of how many responses the coordinator will receive from the vnodes on get before it will return the result to the client W Number of how many responses the coordinator will receive from the vnodes on put before it will return the result to the client For instance, if N=3, R=1, and W=2, this means whenever a client issues a request, these request will be sent to 3 vnodes by the coordinator. If it is a get request, the coordinator will wait for 1 vnode to respond with the data and send it back to the client. If it is a put request, the coordinator will wait for 2 vnodes to respond and send it back to the client. If N is large, it results in better fault tolerance because it is likely that the copies be distributed to different nodes in the cluster by the consistent hashing algorithm. This, however, also means that it will take more time for a request to terminate. If R is small, it results in better throughput for get request. This, however, means that the reliability of the data is comparatively low because it will only wait for a partial number of vnodes to respond. If W is small, it results in better throughput for put request. This, however, means that the reliability of the put has succeeded is comparatively low because it will only wait for a partial number of vnodes to respond.","title":"How many replicas does it make?"},{"location":"coordinator/#implementation-details","text":"There are 3 coordinators in rclref: rclref_put_statem.erl , rclref_get_statem.erl , rclref_coverage_fsm .","title":"Implementation details"},{"location":"coordinator/#put-coordinator","text":"A put coordinator is in rclref_put_statem.erl . This is implemented using gen_statem behaviour with 1 main state, which is waiting. On initialize, it will send the put request to N vnodes. Then in the waiting state, it will wait for either of the condition holds. W vnodes respond with ok N-W vnodes respond with errror % State function % WAITING STATE will wait for the responses from vnodes until % When a vnode return {ok, RObj} waiting ( cast , { ok , RObj }, State = #state { req_id = ReqId , client_pid = ClientPid , w_val = W , num_ok = NumOk0 , riak_objects = RObjs0 }) -> % Update State RObjs = [ RObj ] ++ RObjs0 , NumOk = NumOk0 + 1 , NewState = State #state { num_ok = NumOk , riak_objects = RObjs }, % When more than or equal to W vnodes responded with {ok, RObj}, return W RObjs to client case NumOk >= W of true -> ClientPid ! { ReqId , { ok , RObjs }}, { stop , normal , NewState }; false -> { keep_state , NewState } end ; % When a vnode return {error, VnodeError} waiting ( cast , { error , VnodeError }, State = #state { req_id = ReqId , client_pid = ClientPid , n_val = N , w_val = W , num_vnode_error = NumVnodeError0 , vnode_errors = VnodeErrors0 , riak_objects = RObjs0 }) -> % Update State NumVnodeError = NumVnodeError0 + 1 , VnodeErrors = [ VnodeError ] ++ VnodeErrors0 , NewState = State #state { num_vnode_error = NumVnodeError , vnode_errors = VnodeErrors }, % When more than (N-W) vnodes responded with {error, VnodeError}, return all RObjs and VnodeErrors it has received to client case NumVnodeError > N - W of true -> ClientPid ! { ReqId , {{ ok , RObjs0 }, { error , VnodeErrors }}}, { stop , normal , NewState }; false -> { keep_state , NewState } end ; waiting ( state_timeout , hard_stop , State = #state { req_id = ReqId , client_pid = ClientPid }) -> ClientPid ! { ReqId , { error , timeout }}, { stop , waiting_timed_out , State }; waiting (_ EventType , _ EventContent , State = #state {}) -> { keep_state , State }.","title":"put coordinator"},{"location":"coordinator/#get-coordinator","text":"A get coordinator is in rclref_get_statem . It is also implemented using gen_statem behaviour which has two main states, waiting and finalize. On initialize, the get coordinator will send the get requests to N vnodes. Then in the waiting state, it wait until either of the conditions holds. R vnodes respond with a valid value N-R vnodes respond with an error After the waiting state, it will transit to the finalize state where it repairs the values of the vnodes with broken data. In transit state, the get coordinator will first wait for N vnodes to respond and then compute the latest value using the vector clocks of the valid values it has received. Then, it will send this latest value to the vnodes which did not respond with a valid value. This is called read_repair and you can read more about it here . % FINALIZE STATE will wait for ?N vnodes to return response and then issue read_pair % When a vnode returns {ok, RObj} finalize ( cast , { ok , RObj }, State = #state { n_val = N , num_ok = NumOk0 , num_vnode_error = NumVnodeError0 , riak_objects = RObjs0 , undefined_objects = UObjs0 }) -> % Update State case rclref_object : value ( RObj ) of undefined -> NumVnodeError = NumVnodeError0 + 1 , UObjs = UObjs0 ++ [ RObj ], NumOk = NumOk0 , RObjs = RObjs0 ; _ -> NumVnodeError = NumVnodeError0 , UObjs = UObjs0 , NumOk = NumOk0 + 1 , RObjs = RObjs0 ++ [ RObj ] end , NewState = State #state { num_ok = NumOk , num_vnode_error = NumVnodeError , riak_objects = RObjs , undefined_objects = UObjs }, % When all ?N vnodes has responded, do read_repair case NumOk + NumVnodeError >= N of true -> MergedRObj = rclref_object : merge ( RObjs ++ UObjs ), ok = repair ( MergedRObj , N , RObjs ++ UObjs ), { stop , normal , NewState }; false -> { keep_state , NewState } end ; % When a vnode returns {error, VnodeError} finalize ( cast , { error , VnodeError }, State = #state { n_val = N , num_ok = NumOk0 , num_vnode_error = NumVnodeError0 , riak_objects = RObjs0 , undefined_objects = UObjs0 , vnode_errors = VnodeErrors0 }) -> % Update Satte NumVnodeError = NumVnodeError0 + 1 , VnodeErrors = VnodeErrors0 ++ [ VnodeError ], NewState = State #state { num_vnode_error = NumVnodeError , vnode_errors = VnodeErrors }, % When all ?N vnodes has responded, do read_repair case NumOk0 + NumVnodeError >= N of true -> case RObjs0 ++ UObjs0 of % When any of the vnodes responded with {ok, RObj}, do not issue read_repair [] -> { stop , normal , NewState }; _ -> MergedRObj = rclref_object : merge ( RObjs0 ++ UObjs0 ), ok = repair ( MergedRObj , N , RObjs0 ++ UObjs0 ), { stop , normal , NewState } end ; false -> { keep_state , NewState } end ; % When finalize state timeouts, issue a read_repair finalize ( state_timeout , hard_stop , State = #state { n_val = N , riak_objects = RObjs , undefined_objects = UObjs }) -> case RObjs ++ UObjs of [] -> { stop , normal , State }; _ -> MergedRObj = rclref_object : merge ( RObjs ++ UObjs ), ok = repair ( MergedRObj , N , RObjs ++ UObjs ), { stop , normal , State } end ; finalize (_ EventType , _ EventContent , State = #state {}) -> { keep_state , State }. % Use RObj to repair vnodes with different content (i.e Value, VClock) repair ( RObj , N , RObjs ) -> Key = rclref_object : key ( RObj ), Content = rclref_object : content ( RObj ), % Exclude repairing of vnodes that has the same content OkNodesIndexes = [{ rclref_object : partition ( X ), rclref_object : node ( X )} || X <- RObjs , Key =:= rclref_object : key ( X ), Content =:= rclref_object : content ( X )], DocIdx = riak_core_util : chash_key ({ Key , undefined }), PrefList = riak_core_apl : get_primary_apl ( DocIdx , N , rclref ), lists : foreach ( fun ({ IndexNode , _}) -> case lists : member ( IndexNode , OkNodesIndexes ) of false -> logger : info ( \"Sending repair RObj: ~p to IndexNode: ~p \" , [ RObj , IndexNode ]), riak_core_vnode_master : command ( IndexNode , { repair_request , RObj }, rclref_vnode_master ); _ -> ok end end , PrefList ), ok .","title":"get coordinator"},{"location":"coordinator/#coverage-coordinator","text":"The coverage coordinator is implmeneted using riak_core_coverage_fsm behaviour. In rclref, there are two types of coverage calls. unique This coverage call will request for one replica per key. This means that the coverage plan aims to send the request to a minimum number of vnode which can cover all the unique keys existing in the backend. all This coverage call will request for all replicas per key. This means that the coverage plan aims to send the request to ALL the vnodes which is compuationally very expensive. You can see the difference between them in the return value of the init funciton. Read this page for more details. - module ( rclref_coverage_fsm ). - behaviour ( riak_core_coverage_fsm ). - export ([ start_link / 1 ]). - export ([ init / 2 , process_results / 2 , finish / 2 ]). - define ( N , rclref_config : n_val ()). - define ( W , rclref_config : w_val ()). - define ( R , rclref_config : r_val ()). - define ( TIMEOUT_COVERAGE , rclref_config : timeout_coverage ()). - record ( state , { req_id , client_pid , request , accum = []}). start_link ([ ReqId , Client_Pid , _ Client_Node , Request , Options ]) -> Timeout = proplists : get_value ( timeout , Options , ? TIMEOUT_COVERAGE ), riak_core_coverage_fsm : start_link ( ? MODULE , { pid , ReqId , Client_Pid }, [ Request , Timeout ]). % Callbacks % Client_Pid: Pid, Client_Node: Node init ({ pid , ReqId , Client_Pid }, [ Request = { unique , _}, Timeout ]) -> logger : info ( \"Initializing CoverageFsm, Pid: ~p \" , [ self ()]), State = #state { req_id = ReqId , client_pid = Client_Pid , request = Request , accum = []}, { Request , allup , ? N , 1 , rclref , rclref_vnode_master , Timeout , State }; init ({ pid , ReqId , Client_Pid }, [ Request = { all , _}, Timeout ]) -> logger : info ( \"Initializing CoverageFsm, Pid: ~p \" , [ self ()]), State = #state { req_id = ReqId , client_pid = Client_Pid , request = Request , accum = []}, { Request , allup , ? N , ? N , rclref , rclref_vnode_master , Timeout , State }. process_results ({{_ ReqId , {_ Partition , _ Node }}, []}, State ) -> { done , State }; process_results ({{_ ReqId , {_ Partition , _ Node }}, Data }, State = #state { accum = Accum }) -> % If you need to get which partition and node the data comes from % NewAccum = [{Partition, Node, Data} | Accum], NewAccum = Data ++ Accum , { done , State #state { accum = NewAccum }}. finish ( clean , State = #state { req_id = ReqId , request = { unique , _}, client_pid = Client_Pid , accum = Accum }) -> logger : info ( \"Terminating CoverageFsm, Pid: ~p \" , [ self ()]), NewAccum = lists : usort ( Accum ), Client_Pid ! { ReqId , { ok , NewAccum }}, { stop , normal , State }; finish ( clean , State = #state { req_id = ReqId , request = { all , _}, client_pid = Client_Pid , accum = Accum }) -> logger : info ( \"Terminating CoverageFsm, Pid: ~p \" , [ self ()]), Client_Pid ! { ReqId , { ok , Accum }}, { stop , normal , State }; finish ({ error , Reason }, State = #state { req_id = ReqId , request = { unique , _}, client_pid = Client_Pid , accum = Accum }) -> logger : error ( \"Coverage query failed! Reason: ~p \" , [ Reason ]), NewAccum = lists : usort ( Accum ), Client_Pid ! { ReqId , { partial , Reason , NewAccum }}, { stop , normal , State }; finish ({ error , Reason }, State = #state { req_id = ReqId , request = { all , _}, client_pid = Client_Pid , accum = Accum }) -> logger : error ( \"Coverage query failed! Reason: ~p \" , [ Reason ]), Client_Pid ! { ReqId , { partial , Reason , Accum }}, { stop , normal , State }. process_results function will be used to concatenate results from different vnodes. After receiving all the responses, finish will be called. This will send back the coverage result to the client.","title":"coverage coordinator"},{"location":"httpapi/","text":"HttpAPI This page provides an overview of how Http API is implemented in rclref. Http API is implemented using the cowboy library. Check here for details of cowboy. Warning Please check out the repository for the latest code. Note Add cowboy and jsx as the dependency in rebar.config and rclref.app.src . Starting Http Server To start the http server on starting the application, add the following function in the rclref_app.erl and call it inside rclref_app:start/2 . setup_http_api () -> Dispatch = cowboy_router : compile ([{ '_' , [{ \"/rclref/:key\" , rclref_http_handler , []}]}]), HttpPort = rclref_config : http_port (), HttpAcceptors = rclref_config : http_acceptors (), HttpMaxConnections = rclref_config : http_max_connections (), logger : info ( \"Starting HTTP API at port ~p \" , [ HttpPort ]), { ok , _} = cowboy : start_clear ( rclref_http_listener , [{ port , HttpPort }, { num_acceptors , HttpAcceptors }, { max_connections , HttpMaxConnections }], #{ env => #{ dispatch => Dispatch }}), ok . Writing the handler The handler for http request is defined in rclref_http_handler . A http request will be converted to a request using rclref_client module. Then the response will be converted to a JSON format using the jsx library and sent back to the client. - module ( rclref_http_handler ). - export ([ init / 2 ]). init ( ReqIn = #{ method : = << \"POST\" >> }, State ) -> Key = cowboy_req : binding ( key , ReqIn ), { ok , Value , Req1 } = read_all_body ( ReqIn ), ReqOut = case rclref_client : put ( Key , Value ) of ok -> OK = #{ ok => #{ code => 200 }}, EncodedOK = jsx : encode ( OK , [{ space , 1 }, { indent , 2 }]), cowboy_req : reply ( 200 , #{ << \"content-type\" >> => << \"application/json\" >> }, EncodedOK , Req1 ); { error , partial } -> Error = #{ error => #{ reason => partial , code => 500 }}, EncodedError = jsx : encode ( Error , [{ space , 1 }, { indent , 2 }]), cowboy_req : reply ( 500 , #{ << \"content-type\" >> => << \"application/json\" >> }, EncodedError , Req1 ); { error , timeout } -> Error = #{ error => #{ reason => timeout , code => 408 }}, EncodedError = jsx : encode ( Error , [{ space , 1 }, { indent , 2 }]), cowboy_req : reply ( 408 , #{ << \"content-type\" >> => << \"application/json\" >> }, EncodedError , Req1 ); { error , Reasons } -> Error = #{ error => #{ reason => Reasons , code => 500 }}, EncodedError = jsx : encode ( Error , [{ space , 1 }, { indent , 2 }]), cowboy_req : reply ( 500 , #{ << \"content-type\" >> => << \"application/json\" >> }, EncodedError , Req1 ) end , { ok , ReqOut , State }; init ( ReqIn = #{ method : = << \"DELETE\" >> }, State ) -> Key = cowboy_req : binding ( key , ReqIn ), ReqOut = case rclref_client : delete ( Key ) of ok -> OK = #{ ok => #{ code => 200 }}, EncodedOK = jsx : encode ( OK , [{ space , 1 }, { indent , 2 }]), cowboy_req : reply ( 200 , #{ << \"content-type\" >> => << \"application/json\" >> }, EncodedOK , ReqIn ); { error , partial } -> Error = #{ error => #{ reason => partial , code => 500 }}, EncodedError = jsx : encode ( Error , [{ space , 1 }, { indent , 2 }]), cowboy_req : reply ( 500 , #{ << \"content-type\" >> => << \"application/json\" >> }, EncodedError , ReqIn ); { error , timeout } -> Error = #{ error => #{ reason => timeout , code => 408 }}, EncodedError = jsx : encode ( Error , [{ space , 1 }, { indent , 2 }]), cowboy_req : reply ( 408 , #{ << \"content-type\" >> => << \"application/json\" >> }, EncodedError , ReqIn ); { error , Reasons } -> Error = #{ error => #{ reason => Reasons , code => 500 }}, EncodedError = jsx : encode ( Error , [{ space , 1 }, { indent , 2 }]), cowboy_req : reply ( 500 , #{ << \"content-type\" >> => << \"application/json\" >> }, EncodedError , ReqIn ) end , { ok , ReqOut , State }; init ( ReqIn = #{ method : = << \"GET\" >> }, State ) -> Key = cowboy_req : binding ( key , ReqIn ), ReqOut = case rclref_client : get ( Key ) of { ok , Values } -> Data = #{ ok => #{ values => Values , code => 200 }}, EncodedData = jsx : encode ( Data , [{ space , 1 }, { indent , 2 }]), cowboy_req : reply ( 200 , #{ << \"content-type\" >> => << \"application/json\" >> }, EncodedData , ReqIn ); { error , not_found } -> Error = #{ error => #{ reason => not_found , code => 404 }}, EncodedError = jsx : encode ( Error , [{ space , 1 }, { indent , 2 }]), cowboy_req : reply ( 404 , #{ << \"content-type\" >> => << \"application/json\" >> }, EncodedError , ReqIn ); { error , partial } -> Error = #{ error => #{ reason => partial , code => 500 }}, EncodedError = jsx : encode ( Error , [{ space , 1 }, { indent , 2 }]), cowboy_req : reply ( 500 , #{ << \"content-type\" >> => << \"application/json\" >> }, EncodedError , ReqIn ); { error , timeout } -> Error = #{ error => #{ reason => timeout , code => 408 }}, EncodedError = jsx : encode ( Error , [{ space , 1 }, { indent , 2 }]), cowboy_req : reply ( 408 , #{ << \"content-type\" >> => << \"application/json\" >> }, EncodedError , ReqIn ); { error , Reasons } -> Error = #{ error => #{ reason => Reasons , code => 500 }}, EncodedError = jsx : encode ( Error , [{ space , 1 }, { indent , 2 }]), cowboy_req : reply ( 500 , #{ << \"content-type\" >> => << \"application/json\" >> }, EncodedError , ReqIn ) end , { ok , ReqOut , State }. read_all_body ( ReqIn ) -> read_all_body ( ReqIn , <<>> ). read_all_body ( Req0 , Acc ) -> case cowboy_req : read_body ( Req0 ) of { ok , Data , Req } -> { ok , << Acc / binary , Data / binary >> , Req }; { more , Data , Req } -> read_all_body ( Req , << Acc / binary , Data / binary >> ) end .","title":"HttpAPI"},{"location":"httpapi/#httpapi","text":"This page provides an overview of how Http API is implemented in rclref. Http API is implemented using the cowboy library. Check here for details of cowboy. Warning Please check out the repository for the latest code. Note Add cowboy and jsx as the dependency in rebar.config and rclref.app.src .","title":"HttpAPI"},{"location":"httpapi/#starting-http-server","text":"To start the http server on starting the application, add the following function in the rclref_app.erl and call it inside rclref_app:start/2 . setup_http_api () -> Dispatch = cowboy_router : compile ([{ '_' , [{ \"/rclref/:key\" , rclref_http_handler , []}]}]), HttpPort = rclref_config : http_port (), HttpAcceptors = rclref_config : http_acceptors (), HttpMaxConnections = rclref_config : http_max_connections (), logger : info ( \"Starting HTTP API at port ~p \" , [ HttpPort ]), { ok , _} = cowboy : start_clear ( rclref_http_listener , [{ port , HttpPort }, { num_acceptors , HttpAcceptors }, { max_connections , HttpMaxConnections }], #{ env => #{ dispatch => Dispatch }}), ok .","title":"Starting Http Server"},{"location":"httpapi/#writing-the-handler","text":"The handler for http request is defined in rclref_http_handler . A http request will be converted to a request using rclref_client module. Then the response will be converted to a JSON format using the jsx library and sent back to the client. - module ( rclref_http_handler ). - export ([ init / 2 ]). init ( ReqIn = #{ method : = << \"POST\" >> }, State ) -> Key = cowboy_req : binding ( key , ReqIn ), { ok , Value , Req1 } = read_all_body ( ReqIn ), ReqOut = case rclref_client : put ( Key , Value ) of ok -> OK = #{ ok => #{ code => 200 }}, EncodedOK = jsx : encode ( OK , [{ space , 1 }, { indent , 2 }]), cowboy_req : reply ( 200 , #{ << \"content-type\" >> => << \"application/json\" >> }, EncodedOK , Req1 ); { error , partial } -> Error = #{ error => #{ reason => partial , code => 500 }}, EncodedError = jsx : encode ( Error , [{ space , 1 }, { indent , 2 }]), cowboy_req : reply ( 500 , #{ << \"content-type\" >> => << \"application/json\" >> }, EncodedError , Req1 ); { error , timeout } -> Error = #{ error => #{ reason => timeout , code => 408 }}, EncodedError = jsx : encode ( Error , [{ space , 1 }, { indent , 2 }]), cowboy_req : reply ( 408 , #{ << \"content-type\" >> => << \"application/json\" >> }, EncodedError , Req1 ); { error , Reasons } -> Error = #{ error => #{ reason => Reasons , code => 500 }}, EncodedError = jsx : encode ( Error , [{ space , 1 }, { indent , 2 }]), cowboy_req : reply ( 500 , #{ << \"content-type\" >> => << \"application/json\" >> }, EncodedError , Req1 ) end , { ok , ReqOut , State }; init ( ReqIn = #{ method : = << \"DELETE\" >> }, State ) -> Key = cowboy_req : binding ( key , ReqIn ), ReqOut = case rclref_client : delete ( Key ) of ok -> OK = #{ ok => #{ code => 200 }}, EncodedOK = jsx : encode ( OK , [{ space , 1 }, { indent , 2 }]), cowboy_req : reply ( 200 , #{ << \"content-type\" >> => << \"application/json\" >> }, EncodedOK , ReqIn ); { error , partial } -> Error = #{ error => #{ reason => partial , code => 500 }}, EncodedError = jsx : encode ( Error , [{ space , 1 }, { indent , 2 }]), cowboy_req : reply ( 500 , #{ << \"content-type\" >> => << \"application/json\" >> }, EncodedError , ReqIn ); { error , timeout } -> Error = #{ error => #{ reason => timeout , code => 408 }}, EncodedError = jsx : encode ( Error , [{ space , 1 }, { indent , 2 }]), cowboy_req : reply ( 408 , #{ << \"content-type\" >> => << \"application/json\" >> }, EncodedError , ReqIn ); { error , Reasons } -> Error = #{ error => #{ reason => Reasons , code => 500 }}, EncodedError = jsx : encode ( Error , [{ space , 1 }, { indent , 2 }]), cowboy_req : reply ( 500 , #{ << \"content-type\" >> => << \"application/json\" >> }, EncodedError , ReqIn ) end , { ok , ReqOut , State }; init ( ReqIn = #{ method : = << \"GET\" >> }, State ) -> Key = cowboy_req : binding ( key , ReqIn ), ReqOut = case rclref_client : get ( Key ) of { ok , Values } -> Data = #{ ok => #{ values => Values , code => 200 }}, EncodedData = jsx : encode ( Data , [{ space , 1 }, { indent , 2 }]), cowboy_req : reply ( 200 , #{ << \"content-type\" >> => << \"application/json\" >> }, EncodedData , ReqIn ); { error , not_found } -> Error = #{ error => #{ reason => not_found , code => 404 }}, EncodedError = jsx : encode ( Error , [{ space , 1 }, { indent , 2 }]), cowboy_req : reply ( 404 , #{ << \"content-type\" >> => << \"application/json\" >> }, EncodedError , ReqIn ); { error , partial } -> Error = #{ error => #{ reason => partial , code => 500 }}, EncodedError = jsx : encode ( Error , [{ space , 1 }, { indent , 2 }]), cowboy_req : reply ( 500 , #{ << \"content-type\" >> => << \"application/json\" >> }, EncodedError , ReqIn ); { error , timeout } -> Error = #{ error => #{ reason => timeout , code => 408 }}, EncodedError = jsx : encode ( Error , [{ space , 1 }, { indent , 2 }]), cowboy_req : reply ( 408 , #{ << \"content-type\" >> => << \"application/json\" >> }, EncodedError , ReqIn ); { error , Reasons } -> Error = #{ error => #{ reason => Reasons , code => 500 }}, EncodedError = jsx : encode ( Error , [{ space , 1 }, { indent , 2 }]), cowboy_req : reply ( 500 , #{ << \"content-type\" >> => << \"application/json\" >> }, EncodedError , ReqIn ) end , { ok , ReqOut , State }. read_all_body ( ReqIn ) -> read_all_body ( ReqIn , <<>> ). read_all_body ( Req0 , Acc ) -> case cowboy_req : read_body ( Req0 ) of { ok , Data , Req } -> { ok , << Acc / binary , Data / binary >> , Req }; { more , Data , Req } -> read_all_body ( Req , << Acc / binary , Data / binary >> ) end .","title":"Writing the handler"},{"location":"other/","text":"Other This page provides information on stuff that has not been explained in other pages. How to configure rclref? Configuring rclref is done in mostly in rclref.app.src . Environemntal values are defined in this module. In order to check bugs in the config as earily as possible, environmental values are read using the rclref_config module. How are vector clocks implemented? Please read the wiki if you don't know what vector clocks do. When a client on node1 requests to put a new key-value in the database, a vector clock [{node1, 1}] will be created and stored together with the value. Then if another client on node2 requests to put a value on the same key, the vector clock will be updated to [{node1, 1}, {node2, 1}] and stored together with the new value. These vector clock operations are implemeted in the rclref_object.erl module using the vector clock library . - spec new_vclock () -> vclock (). new_vclock () -> vectorclock : new (). - spec increment_vclock ( node (), vclock ()) -> vclock (). increment_vclock ( Node , VClock ) -> vectorclock : update_with ( Node , fun ( X ) -> X + 1 end , 1 , VClock ). It is not always the case, however, that there is an order between two vector clocks. For example, [{node1, 2}, {node2, 1}] and [{node1, 1}, {node2, 2}] have no orders between them. When updates happen concurrently, there is no causality between the two. On such occastion, it is necessary to have a strategy to merge two objects or a heuristic to select one from them or a strategy for not dealing with the conflict i.e. simply return two different values so that the client can resolve the conflict. In rclref, no heuristics were implemented for selecting the value on concurrent updates. For simplicity, when concurrent updates happen, it just chooses either of the values. This is implemented in the merge function in rclref_object.erl module. - spec merge ([ riak_object ()]) -> riak_object (). merge ([ RObj ]) -> RObj ; merge ([ RObj0 , RObj1 | RObjs ]) -> VClock0 = vclock ( RObj0 ), VClock1 = vclock ( RObj1 ), NewRObj = case vectorclock : le ( VClock0 , VClock1 ) of true -> RObj1 ; false -> RObj0 end , merge ([ NewRObj ] ++ RObjs ). How to delete a tombstone from backend? Tombstone is a key-value which has an undefined value. Tombstone is created when a client request a delete on a Key because delete request is internally converetd into a put request with key=Key, value=undefined. Tombstones are not transparent to the user but you can see them using the coverage calls in LowLevelAPI such as rclref:list_all_objects() . The LowLevelAPI also provides a method to delete the tombstone completely from the backend which is rclref:reap(Key) . This function should only be used when the connection between nodes is stable otherwise the deleted value might resurrect. How to use riak_core instead of riak_core_lite? Remove riak_core_lite and riak_core_lite_utils from rebar.config Add riak_core as dependency. Make a _checkouts directory in rclref. Clone riak_core into that and checkout branch develop-3.0 Comment riak_core_coverage_fsm.erl and riak_core_coverage_plan.erl out Add riak_core.schema to dir _build/dev1/rel/rclref/lib manually Use at most Erlang 22 More information on riak_core These are websites that explain how to create riak_core applicaiton. Note that riak_core and riak_core_lite have some differences e.g. coverage calls. Riak Core wiki Riak Core Tutorial: lambda class Riak Core Tutorial: Mariano Guerra A Gentle Introduction to Riak Core: Enrique Fernandez TryTryTry","title":"Other"},{"location":"other/#other","text":"This page provides information on stuff that has not been explained in other pages.","title":"Other"},{"location":"other/#how-to-configure-rclref","text":"Configuring rclref is done in mostly in rclref.app.src . Environemntal values are defined in this module. In order to check bugs in the config as earily as possible, environmental values are read using the rclref_config module.","title":"How to configure rclref?"},{"location":"other/#how-are-vector-clocks-implemented","text":"Please read the wiki if you don't know what vector clocks do. When a client on node1 requests to put a new key-value in the database, a vector clock [{node1, 1}] will be created and stored together with the value. Then if another client on node2 requests to put a value on the same key, the vector clock will be updated to [{node1, 1}, {node2, 1}] and stored together with the new value. These vector clock operations are implemeted in the rclref_object.erl module using the vector clock library . - spec new_vclock () -> vclock (). new_vclock () -> vectorclock : new (). - spec increment_vclock ( node (), vclock ()) -> vclock (). increment_vclock ( Node , VClock ) -> vectorclock : update_with ( Node , fun ( X ) -> X + 1 end , 1 , VClock ). It is not always the case, however, that there is an order between two vector clocks. For example, [{node1, 2}, {node2, 1}] and [{node1, 1}, {node2, 2}] have no orders between them. When updates happen concurrently, there is no causality between the two. On such occastion, it is necessary to have a strategy to merge two objects or a heuristic to select one from them or a strategy for not dealing with the conflict i.e. simply return two different values so that the client can resolve the conflict. In rclref, no heuristics were implemented for selecting the value on concurrent updates. For simplicity, when concurrent updates happen, it just chooses either of the values. This is implemented in the merge function in rclref_object.erl module. - spec merge ([ riak_object ()]) -> riak_object (). merge ([ RObj ]) -> RObj ; merge ([ RObj0 , RObj1 | RObjs ]) -> VClock0 = vclock ( RObj0 ), VClock1 = vclock ( RObj1 ), NewRObj = case vectorclock : le ( VClock0 , VClock1 ) of true -> RObj1 ; false -> RObj0 end , merge ([ NewRObj ] ++ RObjs ).","title":"How are vector clocks implemented?"},{"location":"other/#how-to-delete-a-tombstone-from-backend","text":"Tombstone is a key-value which has an undefined value. Tombstone is created when a client request a delete on a Key because delete request is internally converetd into a put request with key=Key, value=undefined. Tombstones are not transparent to the user but you can see them using the coverage calls in LowLevelAPI such as rclref:list_all_objects() . The LowLevelAPI also provides a method to delete the tombstone completely from the backend which is rclref:reap(Key) . This function should only be used when the connection between nodes is stable otherwise the deleted value might resurrect.","title":"How to delete a tombstone from backend?"},{"location":"other/#how-to-use-riak_core-instead-of-riak_core_lite","text":"Remove riak_core_lite and riak_core_lite_utils from rebar.config Add riak_core as dependency. Make a _checkouts directory in rclref. Clone riak_core into that and checkout branch develop-3.0 Comment riak_core_coverage_fsm.erl and riak_core_coverage_plan.erl out Add riak_core.schema to dir _build/dev1/rel/rclref/lib manually Use at most Erlang 22","title":"How to use riak_core instead of riak_core_lite?"},{"location":"other/#more-information-on-riak_core","text":"These are websites that explain how to create riak_core applicaiton. Note that riak_core and riak_core_lite have some differences e.g. coverage calls. Riak Core wiki Riak Core Tutorial: lambda class Riak Core Tutorial: Mariano Guerra A Gentle Introduction to Riak Core: Enrique Fernandez TryTryTry","title":"More information on riak_core"},{"location":"put_get_delete/","text":"How are put, get, delete implemented in rclref? Warning Please check out the repository for the latest code. This page provides an overview of how put, get and delete are implemented in rclref. Code flow Put, get and delete have almost the same code flow. The code flow of rclref_client:get(Key) is shown in the following diagram. The main component of rclref is shown in the diagram above. When a user commands rclref_client:get(Key) , it will start a supervisor which manages a coodinator in simle one for one strategy. Then the coordinator will ask the vnodes for the requested data and send it back to the API module once it has collected a certain number of responses. Let's look at how each part of them are implemented from bottom up. Backend Two types of backend is provided in rclref, which are ETS and DETS. ETS is short for Erlang Term Storage which is an in-memory storage that can store erlang terms. DETS is short for Disk ETS which is an disk based persistent storage with almost the same interface as ETS. Since DETS store data in the disk, it is much slower than ETS but has smaller memory footprint. Read here for implementation details. Vnodes The main feature of riak_core(riak_core_lite) is to distribute client requests to processes in the nodes in the cluster. These processes are often referred to as virtual nodes (vnodes). The number of vnodes in a cluster is dependent on the size of the ring of that cluster. A ring is divided into a fixed number of partitions and each vnode is responsible for one of them. When a client makes a request, a hash will be calculated from a client\u2019s request denoting which partition of the ring (thus, vnode) is responsible for handling the request. This is called consistent hashing. With consistent hashing, the following can be achieved. Even distribution of key workload between vnodes. Smooth adaption to dynamic changes in the cluster by replication of data. A detailed explanation of consistent hashing is provided here . In rclref, a vnode handles the following requests. put, get, delete request handoff request coverage request Read here for implementation details. Coordinator Requests made by a client are handled by a coordinator. The coordinator will interact with the vnodes by sending and receiving the requests. For example, if it receives a put request, it generates a hash to determine which vnodes to send the requests to and send it to them. Usually, the coordinator will send the put request to multiple vnodes so that multiple copies of the object exist in the cluster. This is called replication and this ensures the fault tolerance of the database. Read here for implementation details. Supervisor Supervisors are used to manage the coordinators. They will restart the coordinator process when needed. Read here for implementation details. API In rclref, three APIs are provided that can be used to put, get and delete an object from the backend. LowLevelAPI UserAPI HttpAPI It is recommended that the user only use the UserLevelAPI and HttpAPI for manipulating the database. LowLevelAPI should only be used for debugging. The usage of UserAPI and HttpAPI is provided here . LowLevelAPI LowLevelAPI is provided by rclref.erl module. This API should only be used in the case of debugging because it reveals detailed information about the object on put, get and delete which should be transparent to the user of rclref. Such as node partition number vector clock In addition, some queries are exclusive to this module such as reap list_all_keys list_all_objects Read here for implementation details. UserAPI UserAPI is provided by rclref_client.erl module. Compared with the LowLevelAPI, this API reveals less information on put, get, and delete. Read here for implementation details. HttpAPI HttpAPI is provided using the rclref_http_handler.erl using the Cowboy library. This API reveals the same amount of information on put, get, and delete as the UserAPI. Read here for implementation details.","title":"How are put, get, delete implemented in rclref?"},{"location":"put_get_delete/#how-are-put-get-delete-implemented-in-rclref","text":"Warning Please check out the repository for the latest code. This page provides an overview of how put, get and delete are implemented in rclref.","title":"How are put, get, delete implemented in rclref?"},{"location":"put_get_delete/#code-flow","text":"Put, get and delete have almost the same code flow. The code flow of rclref_client:get(Key) is shown in the following diagram. The main component of rclref is shown in the diagram above. When a user commands rclref_client:get(Key) , it will start a supervisor which manages a coodinator in simle one for one strategy. Then the coordinator will ask the vnodes for the requested data and send it back to the API module once it has collected a certain number of responses. Let's look at how each part of them are implemented from bottom up.","title":"Code flow"},{"location":"put_get_delete/#backend","text":"Two types of backend is provided in rclref, which are ETS and DETS. ETS is short for Erlang Term Storage which is an in-memory storage that can store erlang terms. DETS is short for Disk ETS which is an disk based persistent storage with almost the same interface as ETS. Since DETS store data in the disk, it is much slower than ETS but has smaller memory footprint. Read here for implementation details.","title":"Backend"},{"location":"put_get_delete/#vnodes","text":"The main feature of riak_core(riak_core_lite) is to distribute client requests to processes in the nodes in the cluster. These processes are often referred to as virtual nodes (vnodes). The number of vnodes in a cluster is dependent on the size of the ring of that cluster. A ring is divided into a fixed number of partitions and each vnode is responsible for one of them. When a client makes a request, a hash will be calculated from a client\u2019s request denoting which partition of the ring (thus, vnode) is responsible for handling the request. This is called consistent hashing. With consistent hashing, the following can be achieved. Even distribution of key workload between vnodes. Smooth adaption to dynamic changes in the cluster by replication of data. A detailed explanation of consistent hashing is provided here . In rclref, a vnode handles the following requests. put, get, delete request handoff request coverage request Read here for implementation details.","title":"Vnodes"},{"location":"put_get_delete/#coordinator","text":"Requests made by a client are handled by a coordinator. The coordinator will interact with the vnodes by sending and receiving the requests. For example, if it receives a put request, it generates a hash to determine which vnodes to send the requests to and send it to them. Usually, the coordinator will send the put request to multiple vnodes so that multiple copies of the object exist in the cluster. This is called replication and this ensures the fault tolerance of the database. Read here for implementation details.","title":"Coordinator"},{"location":"put_get_delete/#supervisor","text":"Supervisors are used to manage the coordinators. They will restart the coordinator process when needed. Read here for implementation details.","title":"Supervisor"},{"location":"put_get_delete/#api","text":"In rclref, three APIs are provided that can be used to put, get and delete an object from the backend. LowLevelAPI UserAPI HttpAPI It is recommended that the user only use the UserLevelAPI and HttpAPI for manipulating the database. LowLevelAPI should only be used for debugging. The usage of UserAPI and HttpAPI is provided here .","title":"API"},{"location":"put_get_delete/#lowlevelapi","text":"LowLevelAPI is provided by rclref.erl module. This API should only be used in the case of debugging because it reveals detailed information about the object on put, get and delete which should be transparent to the user of rclref. Such as node partition number vector clock In addition, some queries are exclusive to this module such as reap list_all_keys list_all_objects Read here for implementation details.","title":"LowLevelAPI"},{"location":"put_get_delete/#userapi","text":"UserAPI is provided by rclref_client.erl module. Compared with the LowLevelAPI, this API reveals less information on put, get, and delete. Read here for implementation details.","title":"UserAPI"},{"location":"put_get_delete/#httpapi","text":"HttpAPI is provided using the rclref_http_handler.erl using the Cowboy library. This API reveals the same amount of information on put, get, and delete as the UserAPI. Read here for implementation details.","title":"HttpAPI"},{"location":"setup/","text":"How to a setup riak_core_lite application? This page provides an overview of how to setup a riak_core_lite applicaiton. Erlang Install Erlang OTP version >= 22 rebar3 Install rebar3 riak_core_lite Clone riak_core_lite template by the following command: mkdir -p ~/.config/rebar3/templates git clone https://github.com/riak-core-lite/rebar3_template_riak_core_lite.git ~/.config/rebar3/templates/rebar3_template_riak_core_lite Create a new riak_core_lite project: rebar3 new rebar3_riak_core_lite name = YOURAPP See here for details. elvis Elvis is a Erlang style reviewer. Install Elvis from here . Configure it by creating elvis.config in the repository. The following snippet is the configuration used in rclref. %linting and style rules [{ elvis , [{ config , [#{ dirs => [ \"apps/*/src\" ], filter => \"*.erl\" , rules => [{ elvis_style , line_length , #{ ignore => [], limit => 100 , skip_comments => false }}, { elvis_style , no_tabs }, { elvis_style , no_trailing_whitespace }, { elvis_style , macro_names , #{ ignore => []}}, { elvis_style , macro_module_names }, { elvis_style , operator_spaces , #{ rules => [{ right , \",\" }, { right , \"++\" }, { left , \"++\" }, { right , \"--\" }, { left , \"--\" }]}}, %{elvis_style, god_modules, %#{limit => 40, % ignore => []}}, { elvis_style , used_ignored_variable }, { elvis_style , no_behavior_info }, { elvis_style , module_naming_convention , #{ regex => \"^[a-z]([a-z0-9]*_?)*(_SUITE)?$\" , ignore => []} }, { elvis_style , function_naming_convention , #{ regex => \"^[a-z]([a-z0-9]*_?)*$\" } %base: ^([a-z][a-z0-9]*_?)*$ }, { elvis_style , state_record_and_type }, { elvis_style , no_spec_with_records } ] }, #{ dirs => [ \".\" ], filter => \"Makefile\" , rules => [{ elvis_project , no_deps_master_erlang_mk , #{ ignore => []}}, { elvis_project , protocol_for_deps_erlang_mk , #{ ignore => []}}] }, #{ dirs => [ \".\" ], filter => \"rebar.config\" , rules => [{ elvis_project , no_deps_master_rebar , #{ ignore => []}}, { elvis_project , protocol_for_deps_rebar , #{ ignore => []}}] } ] }] }]. After configuring, the code can be reviewed by: elvis rock --config elvis.config rebar3_format rebar3_format is a code formatter for Erlang. Add the following lines to rebar.config . { plugins , [ rebar3_format ]}. { format , [{ files , [ \"apps/rclref/src/*.erl\" , \"test/*.erl\" , \"test/utils/*.erl\" ]}]}. Then the code can be formatted by rebar3 format dialyzer A static type checking can be done by: rebar3 dialyzer","title":"How to setup a riak_core_lite application?"},{"location":"setup/#how-to-a-setup-riak_core_lite-application","text":"This page provides an overview of how to setup a riak_core_lite applicaiton.","title":"How to a setup riak_core_lite application?"},{"location":"setup/#erlang","text":"Install Erlang OTP version >= 22","title":"Erlang"},{"location":"setup/#rebar3","text":"Install rebar3","title":"rebar3"},{"location":"setup/#riak_core_lite","text":"Clone riak_core_lite template by the following command: mkdir -p ~/.config/rebar3/templates git clone https://github.com/riak-core-lite/rebar3_template_riak_core_lite.git ~/.config/rebar3/templates/rebar3_template_riak_core_lite Create a new riak_core_lite project: rebar3 new rebar3_riak_core_lite name = YOURAPP See here for details.","title":"riak_core_lite"},{"location":"setup/#elvis","text":"Elvis is a Erlang style reviewer. Install Elvis from here . Configure it by creating elvis.config in the repository. The following snippet is the configuration used in rclref. %linting and style rules [{ elvis , [{ config , [#{ dirs => [ \"apps/*/src\" ], filter => \"*.erl\" , rules => [{ elvis_style , line_length , #{ ignore => [], limit => 100 , skip_comments => false }}, { elvis_style , no_tabs }, { elvis_style , no_trailing_whitespace }, { elvis_style , macro_names , #{ ignore => []}}, { elvis_style , macro_module_names }, { elvis_style , operator_spaces , #{ rules => [{ right , \",\" }, { right , \"++\" }, { left , \"++\" }, { right , \"--\" }, { left , \"--\" }]}}, %{elvis_style, god_modules, %#{limit => 40, % ignore => []}}, { elvis_style , used_ignored_variable }, { elvis_style , no_behavior_info }, { elvis_style , module_naming_convention , #{ regex => \"^[a-z]([a-z0-9]*_?)*(_SUITE)?$\" , ignore => []} }, { elvis_style , function_naming_convention , #{ regex => \"^[a-z]([a-z0-9]*_?)*$\" } %base: ^([a-z][a-z0-9]*_?)*$ }, { elvis_style , state_record_and_type }, { elvis_style , no_spec_with_records } ] }, #{ dirs => [ \".\" ], filter => \"Makefile\" , rules => [{ elvis_project , no_deps_master_erlang_mk , #{ ignore => []}}, { elvis_project , protocol_for_deps_erlang_mk , #{ ignore => []}}] }, #{ dirs => [ \".\" ], filter => \"rebar.config\" , rules => [{ elvis_project , no_deps_master_rebar , #{ ignore => []}}, { elvis_project , protocol_for_deps_rebar , #{ ignore => []}}] } ] }] }]. After configuring, the code can be reviewed by: elvis rock --config elvis.config","title":"elvis"},{"location":"setup/#rebar3_format","text":"rebar3_format is a code formatter for Erlang. Add the following lines to rebar.config . { plugins , [ rebar3_format ]}. { format , [{ files , [ \"apps/rclref/src/*.erl\" , \"test/*.erl\" , \"test/utils/*.erl\" ]}]}. Then the code can be formatted by rebar3 format","title":"rebar3_format"},{"location":"setup/#dialyzer","text":"A static type checking can be done by: rebar3 dialyzer","title":"dialyzer"},{"location":"supervisor/","text":"Supervisor This page provides an overview of how supervisors are implemented in rclref. Warning Please check out the repository for the latest code. What does a supervisor do? Supervisor in rclref supervises the coordinators. Since there are 3 coordinators, there are 3 supervisors as well. Coordinator Supervisor rclref_put_statem.erl rclref_put_statem_sup.erl rclref_get_statem.erl rclref_get_statem_sup.erl riak_core_coverage_fsm.erl rclref_coverage_fsm_sup.erl There is also another supervisor that supervises these supervisors. These supevisors are activated on starting up the application by this supervisor. This is defined in rclref_sup.erl . - module ( rclref_sup ). - behaviour ( supervisor ). - export ([ start_link / 0 ]). - export ([ init / 1 ]). % API start_link () -> supervisor : start_link ({ local , ? MODULE }, ? MODULE , []). % Callbacks init (_ Args ) -> VMaster = { rclref_vnode_master , { riak_core_vnode_master , start_link , [ rclref_vnode ]}, permanent , 5000 , worker , [ riak_core_vnode_master ]}, PutStatem = { rclref_put_statem_sup , { rclref_put_statem_sup , start_link , []}, permanent , infinity , supervisor , [ rclref_put_statem_sup ]}, GetStatem = { rclref_get_statem_sup , { rclref_get_statem_sup , start_link , []}, permanent , infinity , supervisor , [ rclref_get_statem_sup ]}, CoverageFsm = { rclref_coverage_fsm_sup , { rclref_coverage_fsm_sup , start_link , []}, permanent , infinity , supervisor , [ rclref_coverage_fsm_sup ]}, { ok , {{ one_for_one , 5 , 10 }, [ VMaster , PutStatem , GetStatem , CoverageFsm ]}}. put supervisor A put supervisor is defined in rclref_put_statem_sup.erl . - module ( rclref_put_statem_sup ). - behaviour ( supervisor ). - export ([ start_put_statem / 1 , stop_put_statem / 1 , start_link / 0 ]). - export ([ init / 1 ]). start_put_statem ( Args ) -> ReqId = reqid (), { ok , _} = supervisor : start_child ( ? MODULE , [[ ReqId ] ++ Args ]), { ok , ReqId }. stop_put_statem ( Pid ) -> ok = supervisor : terminate_child ( ? MODULE , Pid ), ok = supervisor : delete_child ( ? MODULE , Pid ). start_link () -> { ok , _} = supervisor : start_link ({ local , ? MODULE }, ? MODULE , []). % Callbacks init ([]) -> PutStatem = { undefined , { rclref_put_statem , start_link , []}, temporary , 5000 , worker , [ rclref_put_statem ]}, { ok , {{ simple_one_for_one , 10 , 10 }, [ PutStatem ]}}. % Internal Functions - spec reqid () -> non_neg_integer (). reqid () -> erlang : phash2 ( erlang : monotonic_time ()). The important function in the snippet above is the start_put_statem/1 . This function will be called by the LowLevelAPI on request from the client. This will return a unique id to the client so that the client can distinguish the responses from the coordinator. get supervisor A get supervisor is defined in rclref_get_statem_sup.erl - module ( rclref_get_statem_sup ). - behaviour ( supervisor ). - export ([ start_get_statem / 1 , stop_get_statem / 1 , start_link / 0 ]). - export ([ init / 1 ]). - spec start_get_statem ([ term ()]) -> { ok , undefined } | { ok , non_neg_integer ()}. start_get_statem ( Args ) -> ReqId = reqid (), { ok , _} = supervisor : start_child ( ? MODULE , [[ ReqId ] ++ Args ]), { ok , ReqId }. - spec stop_get_statem ( pid ()) -> ok . stop_get_statem ( Pid ) -> ok = supervisor : terminate_child ( ? MODULE , Pid ), ok = supervisor : delete_child ( ? MODULE , Pid ). - spec start_link () -> { ok , pid ()}. start_link () -> { ok , _} = supervisor : start_link ({ local , ? MODULE }, ? MODULE , []). % Callbacks init ([]) -> GetStatem = { undefined , { rclref_get_statem , start_link , []}, temporary , 5000 , worker , [ rclref_put_statem ]}, { ok , {{ simple_one_for_one , 10 , 10 }, [ GetStatem ]}}. % Internal Functions - spec reqid () -> non_neg_integer (). reqid () -> erlang : phash2 ( erlang : monotonic_time ()). coverage call supervisor A coverage call supervisor is defined in rclref_coverage_fsm_sup.erl - module ( rclref_coverage_fsm_sup ). - behaviour ( supervisor ). - export ([ start_link / 0 , start_coverage_fsm / 1 , stop_coverage_fsm / 1 ]). - export ([ init / 1 ]). start_coverage_fsm ( Args ) -> ReqId = reqid (), { ok , _} = supervisor : start_child ( ? MODULE , [[ ReqId ] ++ Args ]), { ok , ReqId }. stop_coverage_fsm ( Pid ) -> ok = supervisor : terminate_child ( ? MODULE , Pid ), ok = supervisor : delete_child ( ? MODULE , Pid ). start_link () -> supervisor : start_link ({ local , ? MODULE }, ? MODULE , []). init ([]) -> CoverageFsm = { undefined , { rclref_coverage_fsm , start_link , []}, temporary , 5000 , worker , [ rclref_coverage_fsm ]}, { ok , {{ simple_one_for_one , 10 , 10 }, [ CoverageFsm ]}}. % Internal Functions - spec reqid () -> non_neg_integer (). reqid () -> erlang : phash2 ( erlang : monotonic_time ()).","title":"Supervisor"},{"location":"supervisor/#supervisor","text":"This page provides an overview of how supervisors are implemented in rclref. Warning Please check out the repository for the latest code.","title":"Supervisor"},{"location":"supervisor/#what-does-a-supervisor-do","text":"Supervisor in rclref supervises the coordinators. Since there are 3 coordinators, there are 3 supervisors as well. Coordinator Supervisor rclref_put_statem.erl rclref_put_statem_sup.erl rclref_get_statem.erl rclref_get_statem_sup.erl riak_core_coverage_fsm.erl rclref_coverage_fsm_sup.erl There is also another supervisor that supervises these supervisors. These supevisors are activated on starting up the application by this supervisor. This is defined in rclref_sup.erl . - module ( rclref_sup ). - behaviour ( supervisor ). - export ([ start_link / 0 ]). - export ([ init / 1 ]). % API start_link () -> supervisor : start_link ({ local , ? MODULE }, ? MODULE , []). % Callbacks init (_ Args ) -> VMaster = { rclref_vnode_master , { riak_core_vnode_master , start_link , [ rclref_vnode ]}, permanent , 5000 , worker , [ riak_core_vnode_master ]}, PutStatem = { rclref_put_statem_sup , { rclref_put_statem_sup , start_link , []}, permanent , infinity , supervisor , [ rclref_put_statem_sup ]}, GetStatem = { rclref_get_statem_sup , { rclref_get_statem_sup , start_link , []}, permanent , infinity , supervisor , [ rclref_get_statem_sup ]}, CoverageFsm = { rclref_coverage_fsm_sup , { rclref_coverage_fsm_sup , start_link , []}, permanent , infinity , supervisor , [ rclref_coverage_fsm_sup ]}, { ok , {{ one_for_one , 5 , 10 }, [ VMaster , PutStatem , GetStatem , CoverageFsm ]}}.","title":"What does a supervisor do?"},{"location":"supervisor/#put-supervisor","text":"A put supervisor is defined in rclref_put_statem_sup.erl . - module ( rclref_put_statem_sup ). - behaviour ( supervisor ). - export ([ start_put_statem / 1 , stop_put_statem / 1 , start_link / 0 ]). - export ([ init / 1 ]). start_put_statem ( Args ) -> ReqId = reqid (), { ok , _} = supervisor : start_child ( ? MODULE , [[ ReqId ] ++ Args ]), { ok , ReqId }. stop_put_statem ( Pid ) -> ok = supervisor : terminate_child ( ? MODULE , Pid ), ok = supervisor : delete_child ( ? MODULE , Pid ). start_link () -> { ok , _} = supervisor : start_link ({ local , ? MODULE }, ? MODULE , []). % Callbacks init ([]) -> PutStatem = { undefined , { rclref_put_statem , start_link , []}, temporary , 5000 , worker , [ rclref_put_statem ]}, { ok , {{ simple_one_for_one , 10 , 10 }, [ PutStatem ]}}. % Internal Functions - spec reqid () -> non_neg_integer (). reqid () -> erlang : phash2 ( erlang : monotonic_time ()). The important function in the snippet above is the start_put_statem/1 . This function will be called by the LowLevelAPI on request from the client. This will return a unique id to the client so that the client can distinguish the responses from the coordinator.","title":"put supervisor"},{"location":"supervisor/#get-supervisor","text":"A get supervisor is defined in rclref_get_statem_sup.erl - module ( rclref_get_statem_sup ). - behaviour ( supervisor ). - export ([ start_get_statem / 1 , stop_get_statem / 1 , start_link / 0 ]). - export ([ init / 1 ]). - spec start_get_statem ([ term ()]) -> { ok , undefined } | { ok , non_neg_integer ()}. start_get_statem ( Args ) -> ReqId = reqid (), { ok , _} = supervisor : start_child ( ? MODULE , [[ ReqId ] ++ Args ]), { ok , ReqId }. - spec stop_get_statem ( pid ()) -> ok . stop_get_statem ( Pid ) -> ok = supervisor : terminate_child ( ? MODULE , Pid ), ok = supervisor : delete_child ( ? MODULE , Pid ). - spec start_link () -> { ok , pid ()}. start_link () -> { ok , _} = supervisor : start_link ({ local , ? MODULE }, ? MODULE , []). % Callbacks init ([]) -> GetStatem = { undefined , { rclref_get_statem , start_link , []}, temporary , 5000 , worker , [ rclref_put_statem ]}, { ok , {{ simple_one_for_one , 10 , 10 }, [ GetStatem ]}}. % Internal Functions - spec reqid () -> non_neg_integer (). reqid () -> erlang : phash2 ( erlang : monotonic_time ()).","title":"get supervisor"},{"location":"supervisor/#coverage-call-supervisor","text":"A coverage call supervisor is defined in rclref_coverage_fsm_sup.erl - module ( rclref_coverage_fsm_sup ). - behaviour ( supervisor ). - export ([ start_link / 0 , start_coverage_fsm / 1 , stop_coverage_fsm / 1 ]). - export ([ init / 1 ]). start_coverage_fsm ( Args ) -> ReqId = reqid (), { ok , _} = supervisor : start_child ( ? MODULE , [[ ReqId ] ++ Args ]), { ok , ReqId }. stop_coverage_fsm ( Pid ) -> ok = supervisor : terminate_child ( ? MODULE , Pid ), ok = supervisor : delete_child ( ? MODULE , Pid ). start_link () -> supervisor : start_link ({ local , ? MODULE }, ? MODULE , []). init ([]) -> CoverageFsm = { undefined , { rclref_coverage_fsm , start_link , []}, temporary , 5000 , worker , [ rclref_coverage_fsm ]}, { ok , {{ simple_one_for_one , 10 , 10 }, [ CoverageFsm ]}}. % Internal Functions - spec reqid () -> non_neg_integer (). reqid () -> erlang : phash2 ( erlang : monotonic_time ()).","title":"coverage call supervisor"},{"location":"test/","text":"How to test distributed Erlang application using Common Test? This page provides an overview of how to test distributed application in Erlang. In rclref, Common Test (CT) is used for integrated testing. This post explains how to use CT for distributed applications assuming that the reader already knows how to use CT in a single node environment. The issue in testing distributed application in Erlang often relies on how to spawn multiple Erlang nodes from CT and how to manage their logs. The Goal of this post is to be able to test distirbuted Erlang application using rebar3 and understand how to organize the logs of several distributed nodes. The following is a snippet from client_SUITE.erl in rclref repository. init_per_suite ( Config ) -> application : ensure_all_started ( rclref ), Names = [ node1 ], Ports = [ 30400 ], Nodes = node_utils : set_up_nodes ( Names , Ports , [{ module , ? MODULE }]), [{ module , ? MODULE }, { names , Names }, { nodes , Nodes }, { ports , Ports } | Config ]. end_per_suite ( Config ) -> Nodes = ? config ( nodes , Config ), node_utils : kill_nodes ( Nodes ), Config . put_get_delete_test ( Config ) -> [ Node ] = ? config ( nodes , Config ), Keys = [ \"key--\" ++ integer_to_list ( Num ) || Num <- lists : seq ( 1 , 20 )], Values = [ \"value--\" ++ integer_to_list ( Num ) || Num <- lists : seq ( 1 , 20 )], % check not_found lists : foreach ( fun ( Key ) -> { error , not_found } = rpc : call ( Node , rclref_client , get , [ Key ]) end , Keys ), % put values lists : foreach ( fun ({ Key , Value }) -> ok = rpc : call ( Node , rclref_client , put , [ Key , Value ]) end , lists : zip ( Keys , Values )), % confirm values lists : foreach ( fun ({ Key , Value }) -> { ok , GotValues } = rpc : call ( Node , rclref_client , get , [ Key ]), true = lists : all ( fun ( GotValue ) -> Value =:= GotValue end , GotValues ) end , lists : zip ( Keys , Values )), % delete values lists : foreach ( fun ( Key ) -> ok = rpc : call ( Node , rclref_client , delete , [ Key ]) end , Keys ), % check not_found lists : foreach ( fun ( Key ) -> { error , not_found } = rpc : call ( Node , rclref_client , get , [ Key ]) end , Keys ), ok . The init_per_suite/1 will start an applicaiotn with nodename \"node1\" on port 30400 by calling node_utils:set_upnodes(Names, Ports, [{module, ?MODULE}]) . Internally, the node_util module basically spawns a slave node with ct_slave:start/2 and configures environmental variales. CT will automatically call put_get_delete_test/1 after init_per_suite/1 is called. put_get_delete_test/1 is a basic test storing and deleteing 20 key-values to the slave node that has just been staretd by init_per_suite/1 . Note that in order to access the remote node, remote procedure call should be used. For example, putting a key-value in the slave node is done by ok = rpc:call(Node, rclref_client, put, [Key, Value]) . Now let's see the node_utls module in more detail. - spec set_up_nodes ([ atom ()], [ non_neg_integer ()], [ tuple ()]) -> [ node ()]. set_up_nodes ( Names , Ports , Config ) -> NodesWithStatus = node_utils : pmap ( fun ({ Name , Port }) -> node_utils : start_node ( Name , Port , Config ) end , lists : zip ( Names , Ports )), Nodes = [ Node || { connect , Node } <- NodesWithStatus ], ok = riak_utils : wait_until_ring_converged ( Nodes ), Nodes . As shown in the snippet above, a node is spawned by node_utls:start_node/3 . The function node_utils:pmap/2 is an asynchronous map fuction which is used to start multiple slave nodes asynchronously. - spec start_node ( atom (), non_neg_integer (), [ tuple ()]) -> { connect , node ()} | { ready , node ()}. start_node ( Name , Port , Config ) -> ct : log ( \"Starting node ~p \" , [ Name ]), CodePath = lists : filter ( fun filelib : is_dir / 1 , code : get_path ()), { ok , Cwd } = file : get_cwd (), % RclrefFolder is .../rclref/_build/test _ RclrefFolder = filename : dirname ( filename : dirname ( Cwd )), NodeConfig = [{ init_timeout , 3000 }, { startup_timeout , 3000 }, { monitor_master , true }, { startup_functions , [{ code , set_path , [ CodePath ]}]}], case ct_slave : start ( Name , NodeConfig ) of { ok , Node } -> % Load application to allow configuring the environment before starting ok = rpc : call ( Node , application , load , [ riak_core ]), ok = rpc : call ( Node , application , load , [ rclref ]), % Get remote working dir of node % NodeWorkingDir is .../rclref/_build/test/logs/ct_run.test@127.0.0.1.2020-00-00_00.00.00 { ok , NodeWorkingDir } = rpc : call ( Node , file , get_cwd , []), SuiteName = proplists : get_value ( module , Config , '' ), % Data Dirs ok = rpc : call ( Node , application , set_env , [ riak_core , ring_state_dir , filename : join ([ NodeWorkingDir , \"suites\" , SuiteName , Node , \"data/ring\" ])]), ok = rpc : call ( Node , application , set_env , [ riak_core , platform_data_dir , filename : join ([ NodeWorkingDir , \"suites\" , SuiteName , Node , \"data\" ])]), ok = rpc : call ( Node , application , set_env , [ riak_core , schema_dirs , filename : join ([ NodeWorkingDir , \"suites\" , SuiteName , Node , \"data\" ])]), % Set ports ok = rpc : call ( Node , application , set_env , [ riak_core , handoff_port , Port ]), ok = rpc : call ( Node , application , set_env , [ rclref , http_port , Port + 1 ]), % Logging Configuration LogRoot = filename : join ([ NodeWorkingDir , \"suites\" , SuiteName , Node , \"logs\" ]), ok = rpc : call ( Node , application , set_env , [ rclref , logger , log_config ( LogRoot )]), rpc : call ( Node , logger , set_primary_config , [ level , all ]), rpc : call ( Node , logger , add_handlers , [ rclref ]), % redirect slave logs to ct_master logs ok = rpc : call ( Node , application , set_env , [ rclref , ct_master , node ()]), ConfLog = #{ level => debug , formatter => { logger_formatter , #{ single_line => true , max_size => 2048 }}, config => #{ type => standard_io }}, _ = rpc : call ( Node , logger , add_handler , [ rclref_redirect_ct , ct_redirect_handler , ConfLog ]), % Configuration ok = rpc : call ( Node , application , set_env , [ riak_core , ring_creation_size , 8 ]), { ok , _} = rpc : call ( Node , application , ensure_all_started , [ riak_core ]), { ok , _} = rpc : call ( Node , application , ensure_all_started , [ rclref ]), ct : pal ( \"Node ~p stated with (handoff) port ~p \" , [ Node , Port ]), { connect , Node }; { error , already_started , Node } -> ct : log ( \"Node ~p already started, reusing node\" , [ Node ]), { ready , Node }; { error , Reason , Node } -> ct : pal ( \"Error starting node ~p , reason ~p , will retry\" , [ Node , Reason ]), ct_slave : stop ( Name ), time_utils : wait_until_offline ( Node ), start_node ( Name , Port , Config ) end . start_node/3 is the main fuction for starting up the nodes. As soon as the slave node has started by using ct_slave:start/2 , it is loading the applicaiton by rpc calls, such as ok = rpc:call(Node, application, load, [riak_core]) and ok = rpc:call(Node, application, load, [rclref]) . Once these are called, you can update the environment vairbales from the default values with rpc:call(Node, appcliation, set_env, [...]) . In rclref, setting environmental values such as where to store the riak_core related data and which port is used for handoff and http communication are managed this way. % Logging Configuration LogRoot = filename : join ([ NodeWorkingDir , \"suites\" , SuiteName , Node , \"logs\" ]), ok = rpc : call ( Node , application , set_env , [ rclref , logger , log_config ( LogRoot )]), The snippet above is for setting up the logging environment. LogRoot is the log directory for each node. In rclref, nodes are not reused for each test suite for saftey reasons so logs are seperated from each suite. For test suite that uses two nodes, the log directory looks like the following. | -- handoff_SUITE | | -- node1@localhost | | | -- data | | | ` -- ring | | | | -- riak_core_ring.default.20200817183651 | | | ` -- riak_core_ring.default.20200817183720 | | ` -- logs | | | -- debug.log | | | -- error.log | | | -- info.log | | | -- notice.log | | ` -- warning.log | ` -- node2@localhost | | -- data | | ` -- ring | | | -- riak_core_ring.default.20200817183650 | | | -- riak_core_ring.default.20200817183710 | | ` -- riak_core_ring.default.20200817183720 | ` -- logs | | -- debug.log | | -- error.log | | -- info.log | | -- notice.log | ` -- warning.log","title":"How to test distributed Erlang application using Common Test?"},{"location":"test/#how-to-test-distributed-erlang-application-using-common-test","text":"This page provides an overview of how to test distributed application in Erlang. In rclref, Common Test (CT) is used for integrated testing. This post explains how to use CT for distributed applications assuming that the reader already knows how to use CT in a single node environment. The issue in testing distributed application in Erlang often relies on how to spawn multiple Erlang nodes from CT and how to manage their logs. The Goal of this post is to be able to test distirbuted Erlang application using rebar3 and understand how to organize the logs of several distributed nodes. The following is a snippet from client_SUITE.erl in rclref repository. init_per_suite ( Config ) -> application : ensure_all_started ( rclref ), Names = [ node1 ], Ports = [ 30400 ], Nodes = node_utils : set_up_nodes ( Names , Ports , [{ module , ? MODULE }]), [{ module , ? MODULE }, { names , Names }, { nodes , Nodes }, { ports , Ports } | Config ]. end_per_suite ( Config ) -> Nodes = ? config ( nodes , Config ), node_utils : kill_nodes ( Nodes ), Config . put_get_delete_test ( Config ) -> [ Node ] = ? config ( nodes , Config ), Keys = [ \"key--\" ++ integer_to_list ( Num ) || Num <- lists : seq ( 1 , 20 )], Values = [ \"value--\" ++ integer_to_list ( Num ) || Num <- lists : seq ( 1 , 20 )], % check not_found lists : foreach ( fun ( Key ) -> { error , not_found } = rpc : call ( Node , rclref_client , get , [ Key ]) end , Keys ), % put values lists : foreach ( fun ({ Key , Value }) -> ok = rpc : call ( Node , rclref_client , put , [ Key , Value ]) end , lists : zip ( Keys , Values )), % confirm values lists : foreach ( fun ({ Key , Value }) -> { ok , GotValues } = rpc : call ( Node , rclref_client , get , [ Key ]), true = lists : all ( fun ( GotValue ) -> Value =:= GotValue end , GotValues ) end , lists : zip ( Keys , Values )), % delete values lists : foreach ( fun ( Key ) -> ok = rpc : call ( Node , rclref_client , delete , [ Key ]) end , Keys ), % check not_found lists : foreach ( fun ( Key ) -> { error , not_found } = rpc : call ( Node , rclref_client , get , [ Key ]) end , Keys ), ok . The init_per_suite/1 will start an applicaiotn with nodename \"node1\" on port 30400 by calling node_utils:set_upnodes(Names, Ports, [{module, ?MODULE}]) . Internally, the node_util module basically spawns a slave node with ct_slave:start/2 and configures environmental variales. CT will automatically call put_get_delete_test/1 after init_per_suite/1 is called. put_get_delete_test/1 is a basic test storing and deleteing 20 key-values to the slave node that has just been staretd by init_per_suite/1 . Note that in order to access the remote node, remote procedure call should be used. For example, putting a key-value in the slave node is done by ok = rpc:call(Node, rclref_client, put, [Key, Value]) . Now let's see the node_utls module in more detail. - spec set_up_nodes ([ atom ()], [ non_neg_integer ()], [ tuple ()]) -> [ node ()]. set_up_nodes ( Names , Ports , Config ) -> NodesWithStatus = node_utils : pmap ( fun ({ Name , Port }) -> node_utils : start_node ( Name , Port , Config ) end , lists : zip ( Names , Ports )), Nodes = [ Node || { connect , Node } <- NodesWithStatus ], ok = riak_utils : wait_until_ring_converged ( Nodes ), Nodes . As shown in the snippet above, a node is spawned by node_utls:start_node/3 . The function node_utils:pmap/2 is an asynchronous map fuction which is used to start multiple slave nodes asynchronously. - spec start_node ( atom (), non_neg_integer (), [ tuple ()]) -> { connect , node ()} | { ready , node ()}. start_node ( Name , Port , Config ) -> ct : log ( \"Starting node ~p \" , [ Name ]), CodePath = lists : filter ( fun filelib : is_dir / 1 , code : get_path ()), { ok , Cwd } = file : get_cwd (), % RclrefFolder is .../rclref/_build/test _ RclrefFolder = filename : dirname ( filename : dirname ( Cwd )), NodeConfig = [{ init_timeout , 3000 }, { startup_timeout , 3000 }, { monitor_master , true }, { startup_functions , [{ code , set_path , [ CodePath ]}]}], case ct_slave : start ( Name , NodeConfig ) of { ok , Node } -> % Load application to allow configuring the environment before starting ok = rpc : call ( Node , application , load , [ riak_core ]), ok = rpc : call ( Node , application , load , [ rclref ]), % Get remote working dir of node % NodeWorkingDir is .../rclref/_build/test/logs/ct_run.test@127.0.0.1.2020-00-00_00.00.00 { ok , NodeWorkingDir } = rpc : call ( Node , file , get_cwd , []), SuiteName = proplists : get_value ( module , Config , '' ), % Data Dirs ok = rpc : call ( Node , application , set_env , [ riak_core , ring_state_dir , filename : join ([ NodeWorkingDir , \"suites\" , SuiteName , Node , \"data/ring\" ])]), ok = rpc : call ( Node , application , set_env , [ riak_core , platform_data_dir , filename : join ([ NodeWorkingDir , \"suites\" , SuiteName , Node , \"data\" ])]), ok = rpc : call ( Node , application , set_env , [ riak_core , schema_dirs , filename : join ([ NodeWorkingDir , \"suites\" , SuiteName , Node , \"data\" ])]), % Set ports ok = rpc : call ( Node , application , set_env , [ riak_core , handoff_port , Port ]), ok = rpc : call ( Node , application , set_env , [ rclref , http_port , Port + 1 ]), % Logging Configuration LogRoot = filename : join ([ NodeWorkingDir , \"suites\" , SuiteName , Node , \"logs\" ]), ok = rpc : call ( Node , application , set_env , [ rclref , logger , log_config ( LogRoot )]), rpc : call ( Node , logger , set_primary_config , [ level , all ]), rpc : call ( Node , logger , add_handlers , [ rclref ]), % redirect slave logs to ct_master logs ok = rpc : call ( Node , application , set_env , [ rclref , ct_master , node ()]), ConfLog = #{ level => debug , formatter => { logger_formatter , #{ single_line => true , max_size => 2048 }}, config => #{ type => standard_io }}, _ = rpc : call ( Node , logger , add_handler , [ rclref_redirect_ct , ct_redirect_handler , ConfLog ]), % Configuration ok = rpc : call ( Node , application , set_env , [ riak_core , ring_creation_size , 8 ]), { ok , _} = rpc : call ( Node , application , ensure_all_started , [ riak_core ]), { ok , _} = rpc : call ( Node , application , ensure_all_started , [ rclref ]), ct : pal ( \"Node ~p stated with (handoff) port ~p \" , [ Node , Port ]), { connect , Node }; { error , already_started , Node } -> ct : log ( \"Node ~p already started, reusing node\" , [ Node ]), { ready , Node }; { error , Reason , Node } -> ct : pal ( \"Error starting node ~p , reason ~p , will retry\" , [ Node , Reason ]), ct_slave : stop ( Name ), time_utils : wait_until_offline ( Node ), start_node ( Name , Port , Config ) end . start_node/3 is the main fuction for starting up the nodes. As soon as the slave node has started by using ct_slave:start/2 , it is loading the applicaiton by rpc calls, such as ok = rpc:call(Node, application, load, [riak_core]) and ok = rpc:call(Node, application, load, [rclref]) . Once these are called, you can update the environment vairbales from the default values with rpc:call(Node, appcliation, set_env, [...]) . In rclref, setting environmental values such as where to store the riak_core related data and which port is used for handoff and http communication are managed this way. % Logging Configuration LogRoot = filename : join ([ NodeWorkingDir , \"suites\" , SuiteName , Node , \"logs\" ]), ok = rpc : call ( Node , application , set_env , [ rclref , logger , log_config ( LogRoot )]), The snippet above is for setting up the logging environment. LogRoot is the log directory for each node. In rclref, nodes are not reused for each test suite for saftey reasons so logs are seperated from each suite. For test suite that uses two nodes, the log directory looks like the following. | -- handoff_SUITE | | -- node1@localhost | | | -- data | | | ` -- ring | | | | -- riak_core_ring.default.20200817183651 | | | ` -- riak_core_ring.default.20200817183720 | | ` -- logs | | | -- debug.log | | | -- error.log | | | -- info.log | | | -- notice.log | | ` -- warning.log | ` -- node2@localhost | | -- data | | ` -- ring | | | -- riak_core_ring.default.20200817183650 | | | -- riak_core_ring.default.20200817183710 | | ` -- riak_core_ring.default.20200817183720 | ` -- logs | | -- debug.log | | -- error.log | | -- info.log | | -- notice.log | ` -- warning.log","title":"How to test distributed Erlang application using Common Test?"},{"location":"usage/","text":"How to actually use rclref? This page descirbes how to use rclref as a key-value store. Set up the cluster Single Node Cluster Build the applicaiton by make release Start the application in background. make start If you want to start the application in foreground. make console 3 Node Cluster Build the application by make devrel Start 3 nodes in background make devrel-start Join 2 nodes to the first node. make devrel-join Check the cluster plan. make devrel-cluster-plan Commit the join. make devrel-cluster-commit See the status of the cluster. make dev1-status make dev2-status make dev3-status Leave node from cluster. make dev1-leave make dev2-leave make dev3-leave UserAPI Get a Key-Value with key = dog ( rclref @ 127 . 0 . 0 . 1 ) 1 > rclref_client : get ( << \"dog\" >> ). { error , not_found } Store a Key-Value with key = dog, value = cat ( rclref @ 127 . 0 . 0 . 1 ) 2 > rclref_client : put ( << \"dog\" >> , << \"cat\" >> ). ok Get a Key-Value with key = dog ( rclref @ 127 . 0 . 0 . 1 ) 3 > rclref_client : get ( << \"dog\" >> ). { ok ,[ << \"cat\" >> , << \"cat\" >> , << \"cat\" >> ]} List all keys ( rclref @ 127 . 0 . 0 . 1 ) 4 > rclref_client : list_keys (). { ok ,[ << \"dog\" >> ]} Delete a Key-Value with key = dog. (Internally, this will not delete the value but leave it as a tombstone) ( rclref @ 127 . 0 . 0 . 1 ) 5 > rclref_client : delete ( << \"dog\" >> ). ok Get a Key-Value with key = dog. Note that tombstones are not observable. ( rclref @ 127 . 0 . 0 . 1 ) 6 > rclref_client : get ( << \"dog\" >> ). { error , not_found } HttpAPI Get a Key-Value with key = dog | = > curl -X GET http://localhost:8080/rclref/dog { \"error\" : { \"code\" : 404 , \"reason\" : \"not_found\" } } Store a Key-Value with key = dog, value = cat | = > curl -X POST http://localhost:8080/rclref/dog -d 'cat' { \"ok\" : { \"code\" : 200 } } Get a Key-Value with key = dog | = > curl -X GET http://localhost:8080/rclref/dog { \"ok\" : { \"code\" : 200 , \"values\" : [ \"cat\" , \"cat\" , \"cat\" ] } } Delete a Key-Value with key = dog. (Internally, this will not delete the value but leave it as a tombstone) | = > curl -X DELETE http://localhost:8080/rclref/dog { \"ok\" : { \"code\" : 200 } } Get a Key-Value with key = dog. Note that tombstones are not observable. | = > curl -X GET http://localhost:8080/rclref/dog { \"error\" : { \"code\" : 404 , \"reason\" : \"not_found\" } }","title":"How to actually use rclref?"},{"location":"usage/#how-to-actually-use-rclref","text":"This page descirbes how to use rclref as a key-value store.","title":"How to actually use rclref?"},{"location":"usage/#set-up-the-cluster","text":"","title":"Set up the cluster"},{"location":"usage/#single-node-cluster","text":"Build the applicaiton by make release Start the application in background. make start If you want to start the application in foreground. make console","title":"Single Node Cluster"},{"location":"usage/#3-node-cluster","text":"Build the application by make devrel Start 3 nodes in background make devrel-start Join 2 nodes to the first node. make devrel-join Check the cluster plan. make devrel-cluster-plan Commit the join. make devrel-cluster-commit See the status of the cluster. make dev1-status make dev2-status make dev3-status Leave node from cluster. make dev1-leave make dev2-leave make dev3-leave","title":"3 Node Cluster"},{"location":"usage/#userapi","text":"Get a Key-Value with key = dog ( rclref @ 127 . 0 . 0 . 1 ) 1 > rclref_client : get ( << \"dog\" >> ). { error , not_found } Store a Key-Value with key = dog, value = cat ( rclref @ 127 . 0 . 0 . 1 ) 2 > rclref_client : put ( << \"dog\" >> , << \"cat\" >> ). ok Get a Key-Value with key = dog ( rclref @ 127 . 0 . 0 . 1 ) 3 > rclref_client : get ( << \"dog\" >> ). { ok ,[ << \"cat\" >> , << \"cat\" >> , << \"cat\" >> ]} List all keys ( rclref @ 127 . 0 . 0 . 1 ) 4 > rclref_client : list_keys (). { ok ,[ << \"dog\" >> ]} Delete a Key-Value with key = dog. (Internally, this will not delete the value but leave it as a tombstone) ( rclref @ 127 . 0 . 0 . 1 ) 5 > rclref_client : delete ( << \"dog\" >> ). ok Get a Key-Value with key = dog. Note that tombstones are not observable. ( rclref @ 127 . 0 . 0 . 1 ) 6 > rclref_client : get ( << \"dog\" >> ). { error , not_found }","title":"UserAPI"},{"location":"usage/#httpapi","text":"Get a Key-Value with key = dog | = > curl -X GET http://localhost:8080/rclref/dog { \"error\" : { \"code\" : 404 , \"reason\" : \"not_found\" } } Store a Key-Value with key = dog, value = cat | = > curl -X POST http://localhost:8080/rclref/dog -d 'cat' { \"ok\" : { \"code\" : 200 } } Get a Key-Value with key = dog | = > curl -X GET http://localhost:8080/rclref/dog { \"ok\" : { \"code\" : 200 , \"values\" : [ \"cat\" , \"cat\" , \"cat\" ] } } Delete a Key-Value with key = dog. (Internally, this will not delete the value but leave it as a tombstone) | = > curl -X DELETE http://localhost:8080/rclref/dog { \"ok\" : { \"code\" : 200 } } Get a Key-Value with key = dog. Note that tombstones are not observable. | = > curl -X GET http://localhost:8080/rclref/dog { \"error\" : { \"code\" : 404 , \"reason\" : \"not_found\" } }","title":"HttpAPI"},{"location":"userapi/","text":"UserAPI rclref_client Module rclref_client Module Summary Basic functions for manipulating rclref Description This module provides basic funcitons for reading data from and storing data into rclref, a key-value store on riak-core-lite. put(Key, Value) put(Key, Value, Options) get(Key) get(Key, Options) delete(Key) delete(Key, Options) list_keys() list_keys(Options) put(Key, Value) 1 -spec put(rclref_object:key(), rclref_object:value()) -> ok | {error, timeout} | {error, partial} | {error, term()}. This is equal to rclref_put(Key, Value, []) put(Key, Value, Options) 1 -spec put(rclref_object:key(), rclref_object:value(), [term()]) -> ok | {error, timeout} | {error, partial} | {error, term()}. store a Key-Value in N vnodes. When W vnodes respond with ok or more than N-W number of vnodes respond with an error, this function will return. If neither of these is satisified within TIMEOUT_PUT, then this function will return {error, timeout} Returns ok when W vnodes respond with ok. Returns {error, partial} when at least one of the vnodes (but not more than or equal to W vnodes) responds with ok before getting errors from more than N-W vnodes. Returns {error, [Reason]} when no vnodes respond with ok and more than N-W vnodes respond with an error. [Reason] is a list that contains error reasons of N-W+1 vnodes. Returns {error, timeout} when neither of these above are satisfied within TIMEOUT_PUT milliseconds. get(Key) 1 -spec get(rclref_object:key()) -> {ok, [rclref_object:value()]} | {error, timeout} | {error, partial} | {error, not_found} | {error, term()}. This is equal to get(Key, Value, Options) . get(Key, Options) 1 -spec get(rclref_object:key(), [term()]) -> {ok, [rclref_object:value()]} | {error, timeout} | {error, partial} | {error, not_found} | {error, term()}. get a Key-Value from N vnodes. When R number of vnodes respond with ok or more than N-R number of vnodes respond with an error, this fucntion will return. If neither of these is satisified with TIMEOUT_GET, then this function will return {error, timeout} On get, response from a vnode will be the either of {ok, RObj} , {error, not_found} , {error, Reason} Returns {ok, [Value]} when R vnodes respond with a value. [Value] is a list that contains values from R vnodes. Returns {error, partial} when at least one of the vnodes (but not more than or equal to R vnodes) responds with a value before getting errors from more than N-R vnodes. Returns {error, not_found} when no vnodes respond with a value and more than N-R vnodes respond with a error which are all not_found. Returns {error, [Reason]} when no vnodes respond with a value and more than N-R vnodes respond with a error which are not all not_found. [Reason] is a list that contains error reasons of N-R+1 vnodes. Returns {error, timeout} when neither of these above is satisified within TIMEOUT_GET milliseconds. delete(Key) 1 -spec delete(rclref_object:key()) -> ok | {error, timeout} | {error, partial} | {error, term()}. This is equal to delete(Key, []) . delete(Key, Options) 1 -spec delete(rclref_object:key(), [term()]) -> ok | {error, timeout} | {error, partial} | {error, term()}. This is equal to put(Key, undefined, Options) . Note that this will not delete the Key from the backend, however rclref_client:get(Key) will return {error, not_found} after calling this function. The reason why this is implemeted this way is explained in the [TODO] section. A Key-Value with an undefined value is called a tombstone. list_keys() 1 -spec list_keys() -> {ok, [rclref_object:key()]}. This is equal to list_keys([]) . list_keys(Options) 1 -spec list_keys([term()]) -> {ok, [rclref_object:key()]}. list all unique keys in the backend.","title":"UserAPI"},{"location":"userapi/#userapi","text":"","title":"UserAPI"},{"location":"userapi/#rclref_client","text":"","title":"rclref_client"},{"location":"userapi/#module","text":"rclref_client","title":"Module"},{"location":"userapi/#module-summary","text":"Basic functions for manipulating rclref","title":"Module Summary"},{"location":"userapi/#description","text":"This module provides basic funcitons for reading data from and storing data into rclref, a key-value store on riak-core-lite. put(Key, Value) put(Key, Value, Options) get(Key) get(Key, Options) delete(Key) delete(Key, Options) list_keys() list_keys(Options)","title":"Description"},{"location":"userapi/#putkey-value","text":"1 -spec put(rclref_object:key(), rclref_object:value()) -> ok | {error, timeout} | {error, partial} | {error, term()}. This is equal to rclref_put(Key, Value, [])","title":"put(Key, Value)"},{"location":"userapi/#putkey-value-options","text":"1 -spec put(rclref_object:key(), rclref_object:value(), [term()]) -> ok | {error, timeout} | {error, partial} | {error, term()}. store a Key-Value in N vnodes. When W vnodes respond with ok or more than N-W number of vnodes respond with an error, this function will return. If neither of these is satisified within TIMEOUT_PUT, then this function will return {error, timeout} Returns ok when W vnodes respond with ok. Returns {error, partial} when at least one of the vnodes (but not more than or equal to W vnodes) responds with ok before getting errors from more than N-W vnodes. Returns {error, [Reason]} when no vnodes respond with ok and more than N-W vnodes respond with an error. [Reason] is a list that contains error reasons of N-W+1 vnodes. Returns {error, timeout} when neither of these above are satisfied within TIMEOUT_PUT milliseconds.","title":"put(Key, Value, Options)"},{"location":"userapi/#getkey","text":"1 -spec get(rclref_object:key()) -> {ok, [rclref_object:value()]} | {error, timeout} | {error, partial} | {error, not_found} | {error, term()}. This is equal to get(Key, Value, Options) .","title":"get(Key)"},{"location":"userapi/#getkey-options","text":"1 -spec get(rclref_object:key(), [term()]) -> {ok, [rclref_object:value()]} | {error, timeout} | {error, partial} | {error, not_found} | {error, term()}. get a Key-Value from N vnodes. When R number of vnodes respond with ok or more than N-R number of vnodes respond with an error, this fucntion will return. If neither of these is satisified with TIMEOUT_GET, then this function will return {error, timeout} On get, response from a vnode will be the either of {ok, RObj} , {error, not_found} , {error, Reason} Returns {ok, [Value]} when R vnodes respond with a value. [Value] is a list that contains values from R vnodes. Returns {error, partial} when at least one of the vnodes (but not more than or equal to R vnodes) responds with a value before getting errors from more than N-R vnodes. Returns {error, not_found} when no vnodes respond with a value and more than N-R vnodes respond with a error which are all not_found. Returns {error, [Reason]} when no vnodes respond with a value and more than N-R vnodes respond with a error which are not all not_found. [Reason] is a list that contains error reasons of N-R+1 vnodes. Returns {error, timeout} when neither of these above is satisified within TIMEOUT_GET milliseconds.","title":"get(Key, Options)"},{"location":"userapi/#deletekey","text":"1 -spec delete(rclref_object:key()) -> ok | {error, timeout} | {error, partial} | {error, term()}. This is equal to delete(Key, []) .","title":"delete(Key)"},{"location":"userapi/#deletekey-options","text":"1 -spec delete(rclref_object:key(), [term()]) -> ok | {error, timeout} | {error, partial} | {error, term()}. This is equal to put(Key, undefined, Options) . Note that this will not delete the Key from the backend, however rclref_client:get(Key) will return {error, not_found} after calling this function. The reason why this is implemeted this way is explained in the [TODO] section. A Key-Value with an undefined value is called a tombstone.","title":"delete(Key, Options)"},{"location":"userapi/#list_keys","text":"1 -spec list_keys() -> {ok, [rclref_object:key()]}. This is equal to list_keys([]) .","title":"list_keys()"},{"location":"userapi/#list_keysoptions","text":"1 -spec list_keys([term()]) -> {ok, [rclref_object:key()]}. list all unique keys in the backend.","title":"list_keys(Options)"},{"location":"vnodes/","text":"Vnodes This page will explain how to implement the vnode module, rclref_vnode.erl in detail. Warning Please check out the repository for the latest code. All commands requested by the user will eventually become commands to the vnode sent from the coordiantor. Commands to the vnode will be handled by handle_command function in the vnode module, which is rclref_vnode.erl in rclref. Let's look at how they are implemented for each request. initializing Before understanding how a vnode handles a request, let's look at how it initializes. %% API start_vnode ( I ) -> riak_core_vnode_master : get_vnode_pid ( I , ? MODULE ). init ([ Partition ]) -> Mod = case rclref_config : storage_backend () of ets -> rclref_ets_backend ; dets -> rclref_dets_backend ; _ -> ? assert ( false ) end , { ok , ModState } = Mod : start ( Partition , []), logger : debug ( \"Successfully started ~p backend for partition ~p \" , [ Mod , Partition ]), State = #state { partition = Partition , mod = Mod , modstate = ModState }, { ok , State }. On initialization, it choose the backend module by reading the configuration and start a database (ets or dets) process. put A put request from the client will be converted to {kv_put_request, RObj, Pid, Node} by the coordinator. RObj stands for riak_object and this is a wrapper that wraps the basic components of the key-value object which is defined in riak_object.erl . - record ( r_content , { value :: value (), vclock = vectorclock : new () :: vclock ()}). - record ( r_object , { key :: key (), r_content :: #r_content {}, partition :: non_neg_integer () | undefined , node :: node () | undefined }). Pid is the process id of the put coordinator for the vnode to send back the results. Node is the node of the client to update the vector clock. handle_command ({ kv_put_request , RObj , Pid , Node }, _ Sender , State0 = #state { partition = Partition , mod = Mod , modstate = ModState0 }) -> Key = rclref_object : key ( RObj ), Value = rclref_object : value ( RObj ), % get will be issued before put % If a key is new to backend, store it with a new vector clock % If a key is not new to backend, store it with an updated vector clock % If get returns an error, put will be ignored case Mod : get ( Key , ModState0 ) of { ok , not_found , ModState1 } -> % Create content with a new vector clock VClock = rclref_object : new_vclock (), NewVClock = rclref_object : increment_vclock ( Node , VClock ), NewContent = rclref_object : new_content ( Value , NewVClock ), case Mod : put ( Key , NewContent , ModState1 ) of { ok , ModState2 } -> NewRObj = rclref_object : new ( Key , NewContent , Partition , node ()), rclref_put_statem : result_of_put ( Pid , { ok , NewRObj }), State1 = State0 #state { modstate = ModState2 }, { noreply , State1 }; { error , Reason , ModState2 } -> logger : error ( \"Failed to put kv with key: ~p , content: ~p for partition: ~p , \" \"error: ~p \" , [ Key , NewContent , Partition , Reason ]), VnodeError = rclref_object : new_error ( Reason , Partition , node ()), rclref_put_statem : result_of_put ( Pid , { error , VnodeError }), State1 = State0 #state { modstate = ModState2 }, { noreply , State1 } end ; { ok , Content , ModState1 } -> % Create content with an updated vector clock VClock = rclref_object : vclock ( Content ), NewVClock = rclref_object : increment_vclock ( Node , VClock ), NewContent = rclref_object : new_content ( Value , NewVClock ), case Mod : put ( Key , NewContent , ModState1 ) of { ok , ModState2 } -> NewRObj = rclref_object : new ( Key , NewContent , Partition , node ()), rclref_put_statem : result_of_put ( Pid , { ok , NewRObj }), State1 = State0 #state { modstate = ModState2 }, { noreply , State1 }; { error , Reason , ModState2 } -> logger : error ( \"Failed to put kv with key: ~p , content: ~p for partition: ~p , \" \"error: ~p \" , [ Key , NewContent , Partition , Reason ]), VnodeError = rclref_object : new_error ( Reason , Partition , node ()), rclref_put_statem : result_of_put ( Pid , { error , VnodeError }), State1 = State0 #state { modstate = ModState2 }, { noreply , State1 } end ; { error , Reason , ModState1 } -> logger : error ( \"Failed to get kv (before put) with key: ~p for partition: ~p , \" \"error: ~p \" , [ Key , Partition , Reason ]), VnodeError = rclref_object : new_error ( Reason , Partition , node ()), rclref_put_statem : result_of_put ( Pid , { error , VnodeError }), State1 = State0 #state { modstate = ModState1 }, { noreply , State1 } end ; As commneted in the snippet above, a get to the database will be executed before the put request to see if the key is new or not. If the key is not new, it will have to update the vectorclock of the object and put the new value. If the key is new, it will just put the value. If the put succeed, it will call rclref_put_statem:result_of_put(Pid, {ok, NewRObj}) to notify the put coordinator that put has succeeded. If the put errored, it will call rclref_put_statem:result_of_put(Pid, {error, VnodeError}) to nofity the put coordinator that put has failed. get A get request is converted to {kv_get_request, Key, Pid} . Pid is the process id of the get coordinator. handle_command ({ kv_get_request , Key , Pid }, _ Sender , State0 = #state { partition = Partition , mod = Mod , modstate = ModState0 }) -> case Mod : get ( Key , ModState0 ) of { ok , not_found , ModState1 } -> VnodeError = rclref_object : new_error ( not_found , Partition , node ()), ok = rclref_get_statem : result_of_get ( Pid , { error , VnodeError }), State1 = State0 #state { modstate = ModState1 }, { noreply , State1 }; { ok , Content , ModState1 } -> RObj = rclref_object : new ( Key , Content , Partition , node ()), ok = rclref_get_statem : result_of_get ( Pid , { ok , RObj }), State1 = State0 #state { modstate = ModState1 }, { noreply , State1 }; { error , Reason , ModState1 } -> logger : error ( \"Failed to get kv with key: ~p for partition: ~p , error: ~p \" , [ Key , Partition , Reason ]), VnodeError = rclref_object : new_error ( Reason , Partition , node ()), rclref_get_statem : result_of_get ( Pid , { error , VnodeError }), State1 = State0 #state { modstate = ModState1 }, { noreply , State1 } end ; It will simply get the Key from the backend and return the results to the get coordinator. If the get succeeded, rclref_get_statem:result_of_get(Pid, {ok, RObj}) will be called. If the get errored or the key was not_found, rclref_get_statem:result_of_get(Pid, {error, VnodeError}) will be called. delete A delete request form the client is acutally converted to a put request with Key=Key, Value=undefined by the LowLevelAPI ( rclref.erl ). This means that the key is not completely deleted from the backend after the delete request. The reason why it is implemeted this way is to have better fault tolerancy. See the vector clock section in the other ' page. A key-value with undefined value is called a tombstone. handoff Handoff is a mechanism used when riak_core_lite decides to relocate a vnode to another node. There are two major types of handoffs depending on the context. Hinted Handoff To ensure high availability of the database, riak-core allows writing even when the primary node responsible for the write is down by making another node take over the responsibility. This node is called secondary node or fallback node. When the primary node returns to service, the vnodes in the secondary node will pass back the data it has to the vnodes in the primary node. This exchange of data is called hinted handoff. Ownership Handoff An ownership handoff happens when a cluster member joins or leaves the cluster. Changes to the cluster will cause reassignment of vnodes to nodes which will trigger the handoff of data. This handoff is called ownership handoff. Implementing the following functions in the vnode module is required in order to activate handoff. handle_handoff_command ( #riak_core_fold_req_v2 { foldfun = FoldFun , acc0 = Acc0 }, _ Sender , State = #state { mod = Mod , modstate = ModState }) -> % FoldFun % -type fold_objects_fun() :: fun((term(), term(), any()) -> any() | no_return()). Acc = Mod : fold_objects ( FoldFun , Acc0 , [], ModState ), { reply , Acc , State }; handle_handoff_command ( Message , _ Sender , State ) -> logger : warning ( \"handoff command ~p , ignoring\" , [ Message ]), { noreply , State }. handoff_starting ( TargetNode , State = #state { partition = Partition }) -> logger : info ( \"handoff starting ~p : ~p \" , [ Partition , TargetNode ]), { true , State }. handoff_cancelled ( State = #state { partition = Partition }) -> logger : info ( \"handoff cancelled ~p \" , [ Partition ]), { ok , State }. handoff_finished ( TargetNode , State = #state { partition = Partition }) -> logger : info ( \"handoff finished ~p : ~p \" , [ Partition , TargetNode ]), { ok , State }. handle_handoff_data ( BinData , State0 = #state { partition = Partition , mod = Mod , modstate = ModState0 }) -> { Key , Content } = binary_to_term ( BinData ), logger : info ( \"handoff data received ~p : ~p \" , [ Partition , Key ]), { ok , ModState1 } = Mod : put ( Key , Content , ModState0 ), State1 = State0 #state { modstate = ModState1 }, { reply , ok , State1 }. encode_handoff_item ( Key , Content ) -> term_to_binary ({ Key , Content }). handle_overload_command (_, _, _) -> ok . handle_overload_info (_, _ Idx ) -> ok . is_empty ( State = #state { mod = Mod , modstate = ModState }) -> case Mod : is_empty ( ModState ) of true -> logger : info ( \"is_empty: ~p \" , [ true ]), { true , State }; false -> logger : info ( \"is_empty: ~p \" , [ false ]), { false , State }; Other -> logger : error ( \"is_empty error reason : ~p \" , [ Other ]), { false , State } end . delete ( State0 = #state { partition = Partition , mod = Mod , modstate = ModState0 }) -> logger : info ( \"delete partition: ~p \" , [ Partition ]), { ok , ModState1 } = Mod : drop ( ModState0 ), ok = Mod : stop ( ModState1 ), State1 = State0 #state { modstate = ModState1 }, { ok , State1 }. coverage Coverage calls are used for operations that involve the entire key space. For such operations, it is necessary to gather responses from all the vnodes. For example, in order to obtain a list of keys in the database, it needs to ask all the vnodes because keys are distributed around the cluster. 4 types coverage calls are supported in rclref in the LowLevelAPI. list_unique_keys list_all_keys list_unique_objects list_all_objects In order to implement coverage calls, what we need to do first is to migrate riak_core_coverage_fsm.erl and riak_core_coverage_plan to our repository is needed at the moment. These modules come from the riak_core project because they are currently omitted from riak_core_lite . They are planned to be added to the riak_core_lite_util repository after updating the fsm to gen_statem. The handler for coverage calls are implemented in the following way. handle_coverage ({_, keys }, _ KeySpaces , {_, ReqId , _}, State0 = #state { partition = _ Partition , mod = Mod , modstate = ModState0 }) -> Acc0 = [], Fun = fun ( Key , Accum ) -> [ Key ] ++ Accum end , Acc1 = Mod : fold_keys ( Fun , Acc0 , ModState0 ), { reply , { ReqId , Acc1 }, State0 }; handle_coverage ({_, objects }, _ KeySpaces , {_, ReqId , _}, State0 = #state { partition = Partition , mod = Mod , modstate = ModState0 }) -> Acc0 = [], Fun = fun ( Key , Content , Accum ) -> [ rclref_object : new ( Key , Content , Partition , node ())] ++ Accum end , Acc1 = Mod : fold_objects ( Fun , Acc0 , ModState0 ), { reply , { ReqId , Acc1 }, State0 }.","title":"Vnodes"},{"location":"vnodes/#vnodes","text":"This page will explain how to implement the vnode module, rclref_vnode.erl in detail. Warning Please check out the repository for the latest code. All commands requested by the user will eventually become commands to the vnode sent from the coordiantor. Commands to the vnode will be handled by handle_command function in the vnode module, which is rclref_vnode.erl in rclref. Let's look at how they are implemented for each request.","title":"Vnodes"},{"location":"vnodes/#initializing","text":"Before understanding how a vnode handles a request, let's look at how it initializes. %% API start_vnode ( I ) -> riak_core_vnode_master : get_vnode_pid ( I , ? MODULE ). init ([ Partition ]) -> Mod = case rclref_config : storage_backend () of ets -> rclref_ets_backend ; dets -> rclref_dets_backend ; _ -> ? assert ( false ) end , { ok , ModState } = Mod : start ( Partition , []), logger : debug ( \"Successfully started ~p backend for partition ~p \" , [ Mod , Partition ]), State = #state { partition = Partition , mod = Mod , modstate = ModState }, { ok , State }. On initialization, it choose the backend module by reading the configuration and start a database (ets or dets) process.","title":"initializing"},{"location":"vnodes/#put","text":"A put request from the client will be converted to {kv_put_request, RObj, Pid, Node} by the coordinator. RObj stands for riak_object and this is a wrapper that wraps the basic components of the key-value object which is defined in riak_object.erl . - record ( r_content , { value :: value (), vclock = vectorclock : new () :: vclock ()}). - record ( r_object , { key :: key (), r_content :: #r_content {}, partition :: non_neg_integer () | undefined , node :: node () | undefined }). Pid is the process id of the put coordinator for the vnode to send back the results. Node is the node of the client to update the vector clock. handle_command ({ kv_put_request , RObj , Pid , Node }, _ Sender , State0 = #state { partition = Partition , mod = Mod , modstate = ModState0 }) -> Key = rclref_object : key ( RObj ), Value = rclref_object : value ( RObj ), % get will be issued before put % If a key is new to backend, store it with a new vector clock % If a key is not new to backend, store it with an updated vector clock % If get returns an error, put will be ignored case Mod : get ( Key , ModState0 ) of { ok , not_found , ModState1 } -> % Create content with a new vector clock VClock = rclref_object : new_vclock (), NewVClock = rclref_object : increment_vclock ( Node , VClock ), NewContent = rclref_object : new_content ( Value , NewVClock ), case Mod : put ( Key , NewContent , ModState1 ) of { ok , ModState2 } -> NewRObj = rclref_object : new ( Key , NewContent , Partition , node ()), rclref_put_statem : result_of_put ( Pid , { ok , NewRObj }), State1 = State0 #state { modstate = ModState2 }, { noreply , State1 }; { error , Reason , ModState2 } -> logger : error ( \"Failed to put kv with key: ~p , content: ~p for partition: ~p , \" \"error: ~p \" , [ Key , NewContent , Partition , Reason ]), VnodeError = rclref_object : new_error ( Reason , Partition , node ()), rclref_put_statem : result_of_put ( Pid , { error , VnodeError }), State1 = State0 #state { modstate = ModState2 }, { noreply , State1 } end ; { ok , Content , ModState1 } -> % Create content with an updated vector clock VClock = rclref_object : vclock ( Content ), NewVClock = rclref_object : increment_vclock ( Node , VClock ), NewContent = rclref_object : new_content ( Value , NewVClock ), case Mod : put ( Key , NewContent , ModState1 ) of { ok , ModState2 } -> NewRObj = rclref_object : new ( Key , NewContent , Partition , node ()), rclref_put_statem : result_of_put ( Pid , { ok , NewRObj }), State1 = State0 #state { modstate = ModState2 }, { noreply , State1 }; { error , Reason , ModState2 } -> logger : error ( \"Failed to put kv with key: ~p , content: ~p for partition: ~p , \" \"error: ~p \" , [ Key , NewContent , Partition , Reason ]), VnodeError = rclref_object : new_error ( Reason , Partition , node ()), rclref_put_statem : result_of_put ( Pid , { error , VnodeError }), State1 = State0 #state { modstate = ModState2 }, { noreply , State1 } end ; { error , Reason , ModState1 } -> logger : error ( \"Failed to get kv (before put) with key: ~p for partition: ~p , \" \"error: ~p \" , [ Key , Partition , Reason ]), VnodeError = rclref_object : new_error ( Reason , Partition , node ()), rclref_put_statem : result_of_put ( Pid , { error , VnodeError }), State1 = State0 #state { modstate = ModState1 }, { noreply , State1 } end ; As commneted in the snippet above, a get to the database will be executed before the put request to see if the key is new or not. If the key is not new, it will have to update the vectorclock of the object and put the new value. If the key is new, it will just put the value. If the put succeed, it will call rclref_put_statem:result_of_put(Pid, {ok, NewRObj}) to notify the put coordinator that put has succeeded. If the put errored, it will call rclref_put_statem:result_of_put(Pid, {error, VnodeError}) to nofity the put coordinator that put has failed.","title":"put"},{"location":"vnodes/#get","text":"A get request is converted to {kv_get_request, Key, Pid} . Pid is the process id of the get coordinator. handle_command ({ kv_get_request , Key , Pid }, _ Sender , State0 = #state { partition = Partition , mod = Mod , modstate = ModState0 }) -> case Mod : get ( Key , ModState0 ) of { ok , not_found , ModState1 } -> VnodeError = rclref_object : new_error ( not_found , Partition , node ()), ok = rclref_get_statem : result_of_get ( Pid , { error , VnodeError }), State1 = State0 #state { modstate = ModState1 }, { noreply , State1 }; { ok , Content , ModState1 } -> RObj = rclref_object : new ( Key , Content , Partition , node ()), ok = rclref_get_statem : result_of_get ( Pid , { ok , RObj }), State1 = State0 #state { modstate = ModState1 }, { noreply , State1 }; { error , Reason , ModState1 } -> logger : error ( \"Failed to get kv with key: ~p for partition: ~p , error: ~p \" , [ Key , Partition , Reason ]), VnodeError = rclref_object : new_error ( Reason , Partition , node ()), rclref_get_statem : result_of_get ( Pid , { error , VnodeError }), State1 = State0 #state { modstate = ModState1 }, { noreply , State1 } end ; It will simply get the Key from the backend and return the results to the get coordinator. If the get succeeded, rclref_get_statem:result_of_get(Pid, {ok, RObj}) will be called. If the get errored or the key was not_found, rclref_get_statem:result_of_get(Pid, {error, VnodeError}) will be called.","title":"get"},{"location":"vnodes/#delete","text":"A delete request form the client is acutally converted to a put request with Key=Key, Value=undefined by the LowLevelAPI ( rclref.erl ). This means that the key is not completely deleted from the backend after the delete request. The reason why it is implemeted this way is to have better fault tolerancy. See the vector clock section in the other ' page. A key-value with undefined value is called a tombstone.","title":"delete"},{"location":"vnodes/#handoff","text":"Handoff is a mechanism used when riak_core_lite decides to relocate a vnode to another node. There are two major types of handoffs depending on the context. Hinted Handoff To ensure high availability of the database, riak-core allows writing even when the primary node responsible for the write is down by making another node take over the responsibility. This node is called secondary node or fallback node. When the primary node returns to service, the vnodes in the secondary node will pass back the data it has to the vnodes in the primary node. This exchange of data is called hinted handoff. Ownership Handoff An ownership handoff happens when a cluster member joins or leaves the cluster. Changes to the cluster will cause reassignment of vnodes to nodes which will trigger the handoff of data. This handoff is called ownership handoff. Implementing the following functions in the vnode module is required in order to activate handoff. handle_handoff_command ( #riak_core_fold_req_v2 { foldfun = FoldFun , acc0 = Acc0 }, _ Sender , State = #state { mod = Mod , modstate = ModState }) -> % FoldFun % -type fold_objects_fun() :: fun((term(), term(), any()) -> any() | no_return()). Acc = Mod : fold_objects ( FoldFun , Acc0 , [], ModState ), { reply , Acc , State }; handle_handoff_command ( Message , _ Sender , State ) -> logger : warning ( \"handoff command ~p , ignoring\" , [ Message ]), { noreply , State }. handoff_starting ( TargetNode , State = #state { partition = Partition }) -> logger : info ( \"handoff starting ~p : ~p \" , [ Partition , TargetNode ]), { true , State }. handoff_cancelled ( State = #state { partition = Partition }) -> logger : info ( \"handoff cancelled ~p \" , [ Partition ]), { ok , State }. handoff_finished ( TargetNode , State = #state { partition = Partition }) -> logger : info ( \"handoff finished ~p : ~p \" , [ Partition , TargetNode ]), { ok , State }. handle_handoff_data ( BinData , State0 = #state { partition = Partition , mod = Mod , modstate = ModState0 }) -> { Key , Content } = binary_to_term ( BinData ), logger : info ( \"handoff data received ~p : ~p \" , [ Partition , Key ]), { ok , ModState1 } = Mod : put ( Key , Content , ModState0 ), State1 = State0 #state { modstate = ModState1 }, { reply , ok , State1 }. encode_handoff_item ( Key , Content ) -> term_to_binary ({ Key , Content }). handle_overload_command (_, _, _) -> ok . handle_overload_info (_, _ Idx ) -> ok . is_empty ( State = #state { mod = Mod , modstate = ModState }) -> case Mod : is_empty ( ModState ) of true -> logger : info ( \"is_empty: ~p \" , [ true ]), { true , State }; false -> logger : info ( \"is_empty: ~p \" , [ false ]), { false , State }; Other -> logger : error ( \"is_empty error reason : ~p \" , [ Other ]), { false , State } end . delete ( State0 = #state { partition = Partition , mod = Mod , modstate = ModState0 }) -> logger : info ( \"delete partition: ~p \" , [ Partition ]), { ok , ModState1 } = Mod : drop ( ModState0 ), ok = Mod : stop ( ModState1 ), State1 = State0 #state { modstate = ModState1 }, { ok , State1 }.","title":"handoff"},{"location":"vnodes/#coverage","text":"Coverage calls are used for operations that involve the entire key space. For such operations, it is necessary to gather responses from all the vnodes. For example, in order to obtain a list of keys in the database, it needs to ask all the vnodes because keys are distributed around the cluster. 4 types coverage calls are supported in rclref in the LowLevelAPI. list_unique_keys list_all_keys list_unique_objects list_all_objects In order to implement coverage calls, what we need to do first is to migrate riak_core_coverage_fsm.erl and riak_core_coverage_plan to our repository is needed at the moment. These modules come from the riak_core project because they are currently omitted from riak_core_lite . They are planned to be added to the riak_core_lite_util repository after updating the fsm to gen_statem. The handler for coverage calls are implemented in the following way. handle_coverage ({_, keys }, _ KeySpaces , {_, ReqId , _}, State0 = #state { partition = _ Partition , mod = Mod , modstate = ModState0 }) -> Acc0 = [], Fun = fun ( Key , Accum ) -> [ Key ] ++ Accum end , Acc1 = Mod : fold_keys ( Fun , Acc0 , ModState0 ), { reply , { ReqId , Acc1 }, State0 }; handle_coverage ({_, objects }, _ KeySpaces , {_, ReqId , _}, State0 = #state { partition = Partition , mod = Mod , modstate = ModState0 }) -> Acc0 = [], Fun = fun ( Key , Content , Accum ) -> [ rclref_object : new ( Key , Content , Partition , node ())] ++ Accum end , Acc1 = Mod : fold_objects ( Fun , Acc0 , ModState0 ), { reply , { ReqId , Acc1 }, State0 }.","title":"coverage"}]}