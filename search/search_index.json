{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to the rclref develoment site rclref is a reference implementation of a key-value store built on riak-core-lite. rclref was created as part of Google Summer of Code 2020 with the aim of exercising various APIs of riak-core-lite with documented support. Updated version of the code is here . Development languages and tools The code is fully written in Erlang OTP > 21. License rclref is released under Apache License, Version 2.0 Table of Cotents How to setup riak_core_lite application? How are put, get, delete implemented in rclref? How to test distributed Erlang application using Common Test? How to benchmark riak_core_lite application? How to actually use rclref?","title":"Home"},{"location":"#welcome-to-the-rclref-develoment-site","text":"rclref is a reference implementation of a key-value store built on riak-core-lite. rclref was created as part of Google Summer of Code 2020 with the aim of exercising various APIs of riak-core-lite with documented support. Updated version of the code is here .","title":"Welcome to the rclref develoment site"},{"location":"#development-languages-and-tools","text":"The code is fully written in Erlang OTP > 21.","title":"Development languages and tools"},{"location":"#license","text":"rclref is released under Apache License, Version 2.0","title":"License"},{"location":"#table-of-cotents","text":"How to setup riak_core_lite application? How are put, get, delete implemented in rclref? How to test distributed Erlang application using Common Test? How to benchmark riak_core_lite application? How to actually use rclref?","title":"Table of Cotents"},{"location":"backend/","text":"Backend As shown in the diagram in TODO, each vnode will have their own backend to store the key-value. Backend Behaviour In order to make a generic backend that can support storages engines like ets or dets or even other modules depending on user preference, we will first implement a backend behaviour called rclref_backend.erl . In this module, we will declare functions that are essential for a backend to work. - module ( rclref_backend ). - type state () :: term (). - type fold_keys_fun () :: fun (( term (), any ()) -> any () | no_return ()). - type fold_objects_fun () :: fun (( term (), term (), any ()) -> any () | no_return ()). - type fold_acc () :: term (). - type fold_opts () :: [ term ()]. - type fold_result () :: { ok , fold_acc ()} | { async , fun ()} | { error , term ()}. - callback start ( PartitionIndex :: non_neg_integer (), Config :: [{ atom (), term ()}]) -> { ok , state ()}. - callback stop ( state ()) -> ok . - callback get ( rclref_object : key (), state ()) -> { ok , Value :: term (), state ()} | { ok , not_found , state ()} | { error , term (), state ()}. - callback put ( rclref_object : key (), Value :: binary (), state ()) -> { ok , state ()} | { error , term (), state ()}. - callback delete ( rclref_object : key (), state ()) -> { ok , state ()} | { error , term (), state ()}. - callback drop ( state ()) -> { ok , state ()} | { error , term (), state ()}. - callback fold_keys ( fold_keys_fun (), fold_acc (), fold_opts (), state ()) -> fold_result (). - callback fold_objects ( fold_objects_fun (), fold_acc (), fold_opts (), state ()) -> fold_result (). - callback is_empty ( state ()) -> boolean () | { error , term ()}. - callback status ( state ()) -> [{ atom (), term ()}]. ETS backend After implementing rclref_backend.erl , we need to implement an actual backend that utilizes this behaviour. A sample implementation using Erlang Term Storage (ets) is given in the following snippet. Implementation using disk-based term storage (dets) is also provided in the repository. - module ( rclref_ets_backend ). - behaviour ( rclref_backend ). - record ( state , { table_id }). - export ([ start / 2 , stop / 1 , get / 2 , put / 3 , delete / 2 , drop / 1 , fold_keys / 3 , fold_keys / 4 , fold_objects / 3 , fold_objects / 4 , is_empty / 1 , status / 1 ]). start (_ PartitionIndex , _ Config ) -> TableId = ets : new ( ? MODULE , [ set , { write_concurrency , false }, { read_concurrency , false }]), State = #state { table_id = TableId }, { ok , State }. stop (_ State = #state { table_id = TableId }) -> true = ets : delete ( TableId ), ok . get ( Key , State = #state { table_id = TableId }) -> case ets : lookup ( TableId , Key ) of [] -> { ok , not_found , State }; [{_, Value }] -> { ok , Value , State }; Reason -> { error , Reason , State } end . put ( Key , Value , State = #state { table_id = TableId }) -> true = ets : insert ( TableId , { Key , Value }), { ok , State }. delete ( Key , State = #state { table_id = TableId }) -> true = ets : delete ( TableId , Key ), { ok , State }. drop ( State = #state { table_id = TableId }) -> true = ets : delete_all_objects ( TableId ), { ok , State }. is_empty (_ State = #state { table_id = TableId }) -> ets : first ( TableId ) =:= '$end_of_table' . fold_keys ( Fun , Acc , State ) -> fold_keys ( Fun , Acc , [], State ). fold_keys ( Fun , Acc0 , _ Options , _ State = #state { table_id = TableId }) -> FoldKeysFun = fun ({ K , _}, A ) -> Fun ( K , A ) end , ets : foldl ( FoldKeysFun , Acc0 , TableId ). fold_objects ( Fun , Acc , State ) -> fold_objects ( Fun , Acc , [], State ). fold_objects ( Fun , Acc0 , _ Options , _ State = #state { table_id = TableId }) -> FoldObjectsFun = fun ({ K , V }, A ) -> Fun ( K , V , A ) end , ets : foldl ( FoldObjectsFun , Acc0 , TableId ). status (_ State = #state { table_id = TableId }) -> ets : info ( TableId ). Now let's look at the implementation of vnodes to see how they use these backend modules.","title":"Backend"},{"location":"backend/#backend","text":"As shown in the diagram in TODO, each vnode will have their own backend to store the key-value.","title":"Backend"},{"location":"backend/#backend-behaviour","text":"In order to make a generic backend that can support storages engines like ets or dets or even other modules depending on user preference, we will first implement a backend behaviour called rclref_backend.erl . In this module, we will declare functions that are essential for a backend to work. - module ( rclref_backend ). - type state () :: term (). - type fold_keys_fun () :: fun (( term (), any ()) -> any () | no_return ()). - type fold_objects_fun () :: fun (( term (), term (), any ()) -> any () | no_return ()). - type fold_acc () :: term (). - type fold_opts () :: [ term ()]. - type fold_result () :: { ok , fold_acc ()} | { async , fun ()} | { error , term ()}. - callback start ( PartitionIndex :: non_neg_integer (), Config :: [{ atom (), term ()}]) -> { ok , state ()}. - callback stop ( state ()) -> ok . - callback get ( rclref_object : key (), state ()) -> { ok , Value :: term (), state ()} | { ok , not_found , state ()} | { error , term (), state ()}. - callback put ( rclref_object : key (), Value :: binary (), state ()) -> { ok , state ()} | { error , term (), state ()}. - callback delete ( rclref_object : key (), state ()) -> { ok , state ()} | { error , term (), state ()}. - callback drop ( state ()) -> { ok , state ()} | { error , term (), state ()}. - callback fold_keys ( fold_keys_fun (), fold_acc (), fold_opts (), state ()) -> fold_result (). - callback fold_objects ( fold_objects_fun (), fold_acc (), fold_opts (), state ()) -> fold_result (). - callback is_empty ( state ()) -> boolean () | { error , term ()}. - callback status ( state ()) -> [{ atom (), term ()}].","title":"Backend Behaviour"},{"location":"backend/#ets-backend","text":"After implementing rclref_backend.erl , we need to implement an actual backend that utilizes this behaviour. A sample implementation using Erlang Term Storage (ets) is given in the following snippet. Implementation using disk-based term storage (dets) is also provided in the repository. - module ( rclref_ets_backend ). - behaviour ( rclref_backend ). - record ( state , { table_id }). - export ([ start / 2 , stop / 1 , get / 2 , put / 3 , delete / 2 , drop / 1 , fold_keys / 3 , fold_keys / 4 , fold_objects / 3 , fold_objects / 4 , is_empty / 1 , status / 1 ]). start (_ PartitionIndex , _ Config ) -> TableId = ets : new ( ? MODULE , [ set , { write_concurrency , false }, { read_concurrency , false }]), State = #state { table_id = TableId }, { ok , State }. stop (_ State = #state { table_id = TableId }) -> true = ets : delete ( TableId ), ok . get ( Key , State = #state { table_id = TableId }) -> case ets : lookup ( TableId , Key ) of [] -> { ok , not_found , State }; [{_, Value }] -> { ok , Value , State }; Reason -> { error , Reason , State } end . put ( Key , Value , State = #state { table_id = TableId }) -> true = ets : insert ( TableId , { Key , Value }), { ok , State }. delete ( Key , State = #state { table_id = TableId }) -> true = ets : delete ( TableId , Key ), { ok , State }. drop ( State = #state { table_id = TableId }) -> true = ets : delete_all_objects ( TableId ), { ok , State }. is_empty (_ State = #state { table_id = TableId }) -> ets : first ( TableId ) =:= '$end_of_table' . fold_keys ( Fun , Acc , State ) -> fold_keys ( Fun , Acc , [], State ). fold_keys ( Fun , Acc0 , _ Options , _ State = #state { table_id = TableId }) -> FoldKeysFun = fun ({ K , _}, A ) -> Fun ( K , A ) end , ets : foldl ( FoldKeysFun , Acc0 , TableId ). fold_objects ( Fun , Acc , State ) -> fold_objects ( Fun , Acc , [], State ). fold_objects ( Fun , Acc0 , _ Options , _ State = #state { table_id = TableId }) -> FoldObjectsFun = fun ({ K , V }, A ) -> Fun ( K , V , A ) end , ets : foldl ( FoldObjectsFun , Acc0 , TableId ). status (_ State = #state { table_id = TableId }) -> ets : info ( TableId ). Now let's look at the implementation of vnodes to see how they use these backend modules.","title":"ETS backend"},{"location":"benchmark/","text":"How to benchmark riak_core_lite application? rcl_bench","title":"How to benchmark riak_core_lite application?"},{"location":"benchmark/#how-to-benchmark-riak_core_lite-application","text":"","title":"How to benchmark riak_core_lite application?"},{"location":"benchmark/#rcl_bench","text":"","title":"rcl_bench"},{"location":"put_get_delete/","text":"How are put, get, delete implemented in rclref? This page provides an overview of how put, get and delete are implemented in rclref. Code flow Put, get and delete have almost the same code flow. The code flow of rclref_client:get(Key) is shown in the following diagram. The main component of rclref is shown in the diagram above. When a user commands rclref_client:get(Key) , it will start a supervisor which manages a coodinator in simle one for one strategy. Then the coordinator will ask the vnodes for the requested data and send it back to the API module once it has collected a certain number of responses. Let's look at how each part of them are implemented from bottom up. Backend Two types of backend is provided in rclref, which are ETS and DETS. ETS is short for Erlang Term Storage which is an in-memory storage that can store erlang terms. DETS is short for Disk ETS which is an disk based persistent storage with almost the same interface as ETS. Since DETS store data in the disk, it is much slower than ETS but has smaller memory footprint. Read here for implementation details. Vnodes The main feature of riak_core(riak_core_lite) is to distribute client requests to processes in the nodes in the cluster. These processes are often referred to as virtual nodes (vnodes). The number of vnodes in a cluster is dependent on the size of the ring of that cluster. A ring is divided into a fixed number of partitions and each vnode is responsible for one of them. When a client makes a request, a hash will be calculated from a client\u2019s request denoting which partition of the ring (thus, vnode) is responsible for handling the request. This is called consistent hashing. With consistent hashing, the following can be achieved. Even distribution of key workload between vnodes. Smooth adaption to dynamic changes in the cluster by replication of data. A detailed explanation of consistent hashing is provided here . In rclref, a vnode handles the following requests. put, get, delete request handoff request coverage request Read here for implementation details. Coordinator Requests made by a client are handled by a coordinator. The coordinator will interact with the vnodes by sending and receiving the requests. For example, if it receives a put request, it generates a hash to determine which vnodes to send the requests to and send it to them. Usually, the coordinator will send the put request to multiple vnodes so that multiple copies of the object exist in the cluster. This is called replication and this ensures the fault tolerance of the database. Read here for implementation details. Supervisor Supervisors are used to manage the coordinators. They will restart the coordinator process when needed. Read here for implementation details. API In rclref, three APIs are provided that can be used to put, get and delete an object from the backend. LowLevelAPI UserAPI HttpAPI It is recommended that the user only use the UserLevelAPI and HttpAPI for manipulating the database. LowLevelAPI should only be used for debugging. The usage of UserAPI and HttpAPI is provided here . LowLevelAPI LowLevelAPI is provided by rclref.erl module. This API should only be used in the case of debugging because it reveals detailed information about the object on put, get and delete which should be transparent to the user of rclref. Such as node partition number vector clock In addition, some queries are exclusive to this module such as reap list_all_keys list_all_objects Read here for implementation details. UserAPI UserAPI is provided by rclref_client.erl module. Compared with the LowLevelAPI, this API reveals less information on put, get, and delete. Read here for implementation details. HttpAPI HttpAPI is provided using the rclref_http_handler.erl using the Cowboy library. This API reveals the same amount of information on put, get, and delete as the UserAPI. Read here for implementation details.","title":"How are put, get, delete implemented in rclref?"},{"location":"put_get_delete/#how-are-put-get-delete-implemented-in-rclref","text":"This page provides an overview of how put, get and delete are implemented in rclref.","title":"How are put, get, delete implemented in rclref?"},{"location":"put_get_delete/#code-flow","text":"Put, get and delete have almost the same code flow. The code flow of rclref_client:get(Key) is shown in the following diagram. The main component of rclref is shown in the diagram above. When a user commands rclref_client:get(Key) , it will start a supervisor which manages a coodinator in simle one for one strategy. Then the coordinator will ask the vnodes for the requested data and send it back to the API module once it has collected a certain number of responses. Let's look at how each part of them are implemented from bottom up.","title":"Code flow"},{"location":"put_get_delete/#backend","text":"Two types of backend is provided in rclref, which are ETS and DETS. ETS is short for Erlang Term Storage which is an in-memory storage that can store erlang terms. DETS is short for Disk ETS which is an disk based persistent storage with almost the same interface as ETS. Since DETS store data in the disk, it is much slower than ETS but has smaller memory footprint. Read here for implementation details.","title":"Backend"},{"location":"put_get_delete/#vnodes","text":"The main feature of riak_core(riak_core_lite) is to distribute client requests to processes in the nodes in the cluster. These processes are often referred to as virtual nodes (vnodes). The number of vnodes in a cluster is dependent on the size of the ring of that cluster. A ring is divided into a fixed number of partitions and each vnode is responsible for one of them. When a client makes a request, a hash will be calculated from a client\u2019s request denoting which partition of the ring (thus, vnode) is responsible for handling the request. This is called consistent hashing. With consistent hashing, the following can be achieved. Even distribution of key workload between vnodes. Smooth adaption to dynamic changes in the cluster by replication of data. A detailed explanation of consistent hashing is provided here . In rclref, a vnode handles the following requests. put, get, delete request handoff request coverage request Read here for implementation details.","title":"Vnodes"},{"location":"put_get_delete/#coordinator","text":"Requests made by a client are handled by a coordinator. The coordinator will interact with the vnodes by sending and receiving the requests. For example, if it receives a put request, it generates a hash to determine which vnodes to send the requests to and send it to them. Usually, the coordinator will send the put request to multiple vnodes so that multiple copies of the object exist in the cluster. This is called replication and this ensures the fault tolerance of the database. Read here for implementation details.","title":"Coordinator"},{"location":"put_get_delete/#supervisor","text":"Supervisors are used to manage the coordinators. They will restart the coordinator process when needed. Read here for implementation details.","title":"Supervisor"},{"location":"put_get_delete/#api","text":"In rclref, three APIs are provided that can be used to put, get and delete an object from the backend. LowLevelAPI UserAPI HttpAPI It is recommended that the user only use the UserLevelAPI and HttpAPI for manipulating the database. LowLevelAPI should only be used for debugging. The usage of UserAPI and HttpAPI is provided here .","title":"API"},{"location":"put_get_delete/#lowlevelapi","text":"LowLevelAPI is provided by rclref.erl module. This API should only be used in the case of debugging because it reveals detailed information about the object on put, get and delete which should be transparent to the user of rclref. Such as node partition number vector clock In addition, some queries are exclusive to this module such as reap list_all_keys list_all_objects Read here for implementation details.","title":"LowLevelAPI"},{"location":"put_get_delete/#userapi","text":"UserAPI is provided by rclref_client.erl module. Compared with the LowLevelAPI, this API reveals less information on put, get, and delete. Read here for implementation details.","title":"UserAPI"},{"location":"put_get_delete/#httpapi","text":"HttpAPI is provided using the rclref_http_handler.erl using the Cowboy library. This API reveals the same amount of information on put, get, and delete as the UserAPI. Read here for implementation details.","title":"HttpAPI"},{"location":"setup/","text":"How to setup riak_core_lite application? Erlang Install Erlang OTP version 22 rebar3 Install rebar3 riak_core_lite See here for how to setup riak_core_lite application. elvis Elvis is a Erlang style reviewer. Install Elvis from here . Configure it by creating elvis.config in the repository. The following snippet is the configuration used in rclref. %linting and style rules [{ elvis , [{ config , [#{ dirs => [ \"apps/*/src\" ], filter => \"*.erl\" , rules => [{ elvis_style , line_length , #{ ignore => [], limit => 100 , skip_comments => false }}, { elvis_style , no_tabs }, { elvis_style , no_trailing_whitespace }, { elvis_style , macro_names , #{ ignore => []}}, { elvis_style , macro_module_names }, { elvis_style , operator_spaces , #{ rules => [{ right , \",\" }, { right , \"++\" }, { left , \"++\" }, { right , \"--\" }, { left , \"--\" }]}}, %{elvis_style, god_modules, %#{limit => 40, % ignore => []}}, { elvis_style , used_ignored_variable }, { elvis_style , no_behavior_info }, { elvis_style , module_naming_convention , #{ regex => \"^[a-z]([a-z0-9]*_?)*(_SUITE)?$\" , ignore => []} }, { elvis_style , function_naming_convention , #{ regex => \"^[a-z]([a-z0-9]*_?)*$\" } %base: ^([a-z][a-z0-9]*_?)*$ }, { elvis_style , state_record_and_type }, { elvis_style , no_spec_with_records } ] }, #{ dirs => [ \".\" ], filter => \"Makefile\" , rules => [{ elvis_project , no_deps_master_erlang_mk , #{ ignore => []}}, { elvis_project , protocol_for_deps_erlang_mk , #{ ignore => []}}] }, #{ dirs => [ \".\" ], filter => \"rebar.config\" , rules => [{ elvis_project , no_deps_master_rebar , #{ ignore => []}}, { elvis_project , protocol_for_deps_rebar , #{ ignore => []}}] } ] }] }]. After configuring, the code can be reviewed by elvis rock --config elvis.config . rebar3_format rebar3_format is a code formatter for Erlang. Add the following lines to rebar.config . { plugins , [ rebar3_format ]}. { format , [{ files , [ \"apps/rclref/src/*.erl\" , \"test/*.erl\" , \"test/utils/*.erl\" ]}]}. The code can be formatted using rebar3 format . dialyzer A static type checking can be done by rebar3 dialyzer .","title":"How to setup riak_core_lite application?"},{"location":"setup/#how-to-setup-riak_core_lite-application","text":"","title":"How to setup riak_core_lite application?"},{"location":"setup/#erlang","text":"Install Erlang OTP version 22","title":"Erlang"},{"location":"setup/#rebar3","text":"Install rebar3","title":"rebar3"},{"location":"setup/#riak_core_lite","text":"See here for how to setup riak_core_lite application.","title":"riak_core_lite"},{"location":"setup/#elvis","text":"Elvis is a Erlang style reviewer. Install Elvis from here . Configure it by creating elvis.config in the repository. The following snippet is the configuration used in rclref. %linting and style rules [{ elvis , [{ config , [#{ dirs => [ \"apps/*/src\" ], filter => \"*.erl\" , rules => [{ elvis_style , line_length , #{ ignore => [], limit => 100 , skip_comments => false }}, { elvis_style , no_tabs }, { elvis_style , no_trailing_whitespace }, { elvis_style , macro_names , #{ ignore => []}}, { elvis_style , macro_module_names }, { elvis_style , operator_spaces , #{ rules => [{ right , \",\" }, { right , \"++\" }, { left , \"++\" }, { right , \"--\" }, { left , \"--\" }]}}, %{elvis_style, god_modules, %#{limit => 40, % ignore => []}}, { elvis_style , used_ignored_variable }, { elvis_style , no_behavior_info }, { elvis_style , module_naming_convention , #{ regex => \"^[a-z]([a-z0-9]*_?)*(_SUITE)?$\" , ignore => []} }, { elvis_style , function_naming_convention , #{ regex => \"^[a-z]([a-z0-9]*_?)*$\" } %base: ^([a-z][a-z0-9]*_?)*$ }, { elvis_style , state_record_and_type }, { elvis_style , no_spec_with_records } ] }, #{ dirs => [ \".\" ], filter => \"Makefile\" , rules => [{ elvis_project , no_deps_master_erlang_mk , #{ ignore => []}}, { elvis_project , protocol_for_deps_erlang_mk , #{ ignore => []}}] }, #{ dirs => [ \".\" ], filter => \"rebar.config\" , rules => [{ elvis_project , no_deps_master_rebar , #{ ignore => []}}, { elvis_project , protocol_for_deps_rebar , #{ ignore => []}}] } ] }] }]. After configuring, the code can be reviewed by elvis rock --config elvis.config .","title":"elvis"},{"location":"setup/#rebar3_format","text":"rebar3_format is a code formatter for Erlang. Add the following lines to rebar.config . { plugins , [ rebar3_format ]}. { format , [{ files , [ \"apps/rclref/src/*.erl\" , \"test/*.erl\" , \"test/utils/*.erl\" ]}]}. The code can be formatted using rebar3 format .","title":"rebar3_format"},{"location":"setup/#dialyzer","text":"A static type checking can be done by rebar3 dialyzer .","title":"dialyzer"},{"location":"test/","text":"How to test distributed Erlang application using Common Test? This page provides an overview of how to test distributed application in Erlang. In rclref, Common Test (CT) is used for integrated testing. This post explains how to use CT for distributed applications assuming that the reader already knows how to use CT in a single node environment. The issue in testing distributed application in Erlang often relies on how to spawn multiple Erlang nodes from CT and how to manage their logs. The Goal of this post is to be able to test distirbuted Erlang application using rebar3 and understand how to organize the logs of several distributed nodes. The following is a snippet from client_SUITE.erl in rclref repository. init_per_suite ( Config ) -> application : ensure_all_started ( rclref ), Names = [ node1 ], Ports = [ 30400 ], Nodes = node_utils : set_up_nodes ( Names , Ports , [{ module , ? MODULE }]), [{ module , ? MODULE }, { names , Names }, { nodes , Nodes }, { ports , Ports } | Config ]. end_per_suite ( Config ) -> Nodes = ? config ( nodes , Config ), node_utils : kill_nodes ( Nodes ), Config . put_get_delete_test ( Config ) -> [ Node ] = ? config ( nodes , Config ), Keys = [ \"key--\" ++ integer_to_list ( Num ) || Num <- lists : seq ( 1 , 20 )], Values = [ \"value--\" ++ integer_to_list ( Num ) || Num <- lists : seq ( 1 , 20 )], % check not_found lists : foreach ( fun ( Key ) -> { error , not_found } = rpc : call ( Node , rclref_client , get , [ Key ]) end , Keys ), % put values lists : foreach ( fun ({ Key , Value }) -> ok = rpc : call ( Node , rclref_client , put , [ Key , Value ]) end , lists : zip ( Keys , Values )), % confirm values lists : foreach ( fun ({ Key , Value }) -> { ok , GotValues } = rpc : call ( Node , rclref_client , get , [ Key ]), true = lists : all ( fun ( GotValue ) -> Value =:= GotValue end , GotValues ) end , lists : zip ( Keys , Values )), % delete values lists : foreach ( fun ( Key ) -> ok = rpc : call ( Node , rclref_client , delete , [ Key ]) end , Keys ), % check not_found lists : foreach ( fun ( Key ) -> { error , not_found } = rpc : call ( Node , rclref_client , get , [ Key ]) end , Keys ), ok . The init_per_suite/1 will start an applicaiotn with nodename \"node1\" on port 30400 by calling node_utils:set_upnodes(Names, Ports, [{module, ?MODULE}]) . Internally, the node_util module basically spawns a slave node with ct_slave:start/2 and configures environmental variales. CT will automatically call put_get_delete_test/1 after init_per_suite/1 is called. put_get_delete_test/1 is a basic test storing and deleteing 20 key-values to the slave node that has just been staretd by init_per_suite/1 . Note that in order to access the remote node, remote procedure call should be used. For example, putting a key-value in the slave node is done by ok = rpc:call(Node, rclref_client, put, [Key, Value]) . Now let's see the node_utls module in more detail. - spec set_up_nodes ([ atom ()], [ non_neg_integer ()], [ tuple ()]) -> [ node ()]. set_up_nodes ( Names , Ports , Config ) -> NodesWithStatus = node_utils : pmap ( fun ({ Name , Port }) -> node_utils : start_node ( Name , Port , Config ) end , lists : zip ( Names , Ports )), Nodes = [ Node || { connect , Node } <- NodesWithStatus ], ok = riak_utils : wait_until_ring_converged ( Nodes ), Nodes . As shown in the snippet above, a node is spawned by node_utls:start_node/3 . The function node_utils:pmap/2 is an asynchronous map fuction which is used to start multiple slave nodes asynchronously. - spec start_node ( atom (), non_neg_integer (), [ tuple ()]) -> { connect , node ()} | { ready , node ()}. start_node ( Name , Port , Config ) -> ct : log ( \"Starting node ~p \" , [ Name ]), CodePath = lists : filter ( fun filelib : is_dir / 1 , code : get_path ()), { ok , Cwd } = file : get_cwd (), % RclrefFolder is .../rclref/_build/test _ RclrefFolder = filename : dirname ( filename : dirname ( Cwd )), NodeConfig = [{ init_timeout , 3000 }, { startup_timeout , 3000 }, { monitor_master , true }, { startup_functions , [{ code , set_path , [ CodePath ]}]}], case ct_slave : start ( Name , NodeConfig ) of { ok , Node } -> % Load application to allow configuring the environment before starting ok = rpc : call ( Node , application , load , [ riak_core ]), ok = rpc : call ( Node , application , load , [ rclref ]), % Get remote working dir of node % NodeWorkingDir is .../rclref/_build/test/logs/ct_run.test@127.0.0.1.2020-00-00_00.00.00 { ok , NodeWorkingDir } = rpc : call ( Node , file , get_cwd , []), SuiteName = proplists : get_value ( module , Config , '' ), % Data Dirs ok = rpc : call ( Node , application , set_env , [ riak_core , ring_state_dir , filename : join ([ NodeWorkingDir , \"suites\" , SuiteName , Node , \"data/ring\" ])]), ok = rpc : call ( Node , application , set_env , [ riak_core , platform_data_dir , filename : join ([ NodeWorkingDir , \"suites\" , SuiteName , Node , \"data\" ])]), ok = rpc : call ( Node , application , set_env , [ riak_core , schema_dirs , filename : join ([ NodeWorkingDir , \"suites\" , SuiteName , Node , \"data\" ])]), % Set ports ok = rpc : call ( Node , application , set_env , [ riak_core , handoff_port , Port ]), ok = rpc : call ( Node , application , set_env , [ rclref , http_port , Port + 1 ]), % Logging Configuration LogRoot = filename : join ([ NodeWorkingDir , \"suites\" , SuiteName , Node , \"logs\" ]), ok = rpc : call ( Node , application , set_env , [ rclref , logger , log_config ( LogRoot )]), rpc : call ( Node , logger , set_primary_config , [ level , all ]), rpc : call ( Node , logger , add_handlers , [ rclref ]), % redirect slave logs to ct_master logs ok = rpc : call ( Node , application , set_env , [ rclref , ct_master , node ()]), ConfLog = #{ level => debug , formatter => { logger_formatter , #{ single_line => true , max_size => 2048 }}, config => #{ type => standard_io }}, _ = rpc : call ( Node , logger , add_handler , [ rclref_redirect_ct , ct_redirect_handler , ConfLog ]), % Configuration ok = rpc : call ( Node , application , set_env , [ riak_core , ring_creation_size , 8 ]), { ok , _} = rpc : call ( Node , application , ensure_all_started , [ riak_core ]), { ok , _} = rpc : call ( Node , application , ensure_all_started , [ rclref ]), ct : pal ( \"Node ~p stated with (handoff) port ~p \" , [ Node , Port ]), { connect , Node }; { error , already_started , Node } -> ct : log ( \"Node ~p already started, reusing node\" , [ Node ]), { ready , Node }; { error , Reason , Node } -> ct : pal ( \"Error starting node ~p , reason ~p , will retry\" , [ Node , Reason ]), ct_slave : stop ( Name ), time_utils : wait_until_offline ( Node ), start_node ( Name , Port , Config ) end . start_node/3 is the main fuction for starting up the nodes. As soon as the slave node has started by using ct_slave:start/2 , it is loading the applicaiton by rpc calls, such as ok = rpc:call(Node, application, load, [riak_core]) and ok = rpc:call(Node, application, load, [rclref]) . Once these are called, you can update the environment vairbales from the default values with rpc:call(Node, appcliation, set_env, [...]) . In rclref, setting environmental values such as where to store the riak_core related data and which port is used for handoff and http communication are managed this way. % Logging Configuration LogRoot = filename : join ([ NodeWorkingDir , \"suites\" , SuiteName , Node , \"logs\" ]), ok = rpc : call ( Node , application , set_env , [ rclref , logger , log_config ( LogRoot )]), The snippet above is for setting up the logging environment. LogRoot is the log directory for each node. In rclref, nodes are not reused for each test suite for saftey reasons so logs are seperated from each suite. For test suite that uses two nodes, the log directory looks like the following. | -- handoff_SUITE | | -- node1@localhost | | | -- data | | | ` -- ring | | | | -- riak_core_ring.default.20200817183651 | | | ` -- riak_core_ring.default.20200817183720 | | ` -- logs | | | -- debug.log | | | -- error.log | | | -- info.log | | | -- notice.log | | ` -- warning.log | ` -- node2@localhost | | -- data | | ` -- ring | | | -- riak_core_ring.default.20200817183650 | | | -- riak_core_ring.default.20200817183710 | | ` -- riak_core_ring.default.20200817183720 | ` -- logs | | -- debug.log | | -- error.log | | -- info.log | | -- notice.log | ` -- warning.log","title":"How to test distributed Erlang application using Common Test?"},{"location":"test/#how-to-test-distributed-erlang-application-using-common-test","text":"This page provides an overview of how to test distributed application in Erlang. In rclref, Common Test (CT) is used for integrated testing. This post explains how to use CT for distributed applications assuming that the reader already knows how to use CT in a single node environment. The issue in testing distributed application in Erlang often relies on how to spawn multiple Erlang nodes from CT and how to manage their logs. The Goal of this post is to be able to test distirbuted Erlang application using rebar3 and understand how to organize the logs of several distributed nodes. The following is a snippet from client_SUITE.erl in rclref repository. init_per_suite ( Config ) -> application : ensure_all_started ( rclref ), Names = [ node1 ], Ports = [ 30400 ], Nodes = node_utils : set_up_nodes ( Names , Ports , [{ module , ? MODULE }]), [{ module , ? MODULE }, { names , Names }, { nodes , Nodes }, { ports , Ports } | Config ]. end_per_suite ( Config ) -> Nodes = ? config ( nodes , Config ), node_utils : kill_nodes ( Nodes ), Config . put_get_delete_test ( Config ) -> [ Node ] = ? config ( nodes , Config ), Keys = [ \"key--\" ++ integer_to_list ( Num ) || Num <- lists : seq ( 1 , 20 )], Values = [ \"value--\" ++ integer_to_list ( Num ) || Num <- lists : seq ( 1 , 20 )], % check not_found lists : foreach ( fun ( Key ) -> { error , not_found } = rpc : call ( Node , rclref_client , get , [ Key ]) end , Keys ), % put values lists : foreach ( fun ({ Key , Value }) -> ok = rpc : call ( Node , rclref_client , put , [ Key , Value ]) end , lists : zip ( Keys , Values )), % confirm values lists : foreach ( fun ({ Key , Value }) -> { ok , GotValues } = rpc : call ( Node , rclref_client , get , [ Key ]), true = lists : all ( fun ( GotValue ) -> Value =:= GotValue end , GotValues ) end , lists : zip ( Keys , Values )), % delete values lists : foreach ( fun ( Key ) -> ok = rpc : call ( Node , rclref_client , delete , [ Key ]) end , Keys ), % check not_found lists : foreach ( fun ( Key ) -> { error , not_found } = rpc : call ( Node , rclref_client , get , [ Key ]) end , Keys ), ok . The init_per_suite/1 will start an applicaiotn with nodename \"node1\" on port 30400 by calling node_utils:set_upnodes(Names, Ports, [{module, ?MODULE}]) . Internally, the node_util module basically spawns a slave node with ct_slave:start/2 and configures environmental variales. CT will automatically call put_get_delete_test/1 after init_per_suite/1 is called. put_get_delete_test/1 is a basic test storing and deleteing 20 key-values to the slave node that has just been staretd by init_per_suite/1 . Note that in order to access the remote node, remote procedure call should be used. For example, putting a key-value in the slave node is done by ok = rpc:call(Node, rclref_client, put, [Key, Value]) . Now let's see the node_utls module in more detail. - spec set_up_nodes ([ atom ()], [ non_neg_integer ()], [ tuple ()]) -> [ node ()]. set_up_nodes ( Names , Ports , Config ) -> NodesWithStatus = node_utils : pmap ( fun ({ Name , Port }) -> node_utils : start_node ( Name , Port , Config ) end , lists : zip ( Names , Ports )), Nodes = [ Node || { connect , Node } <- NodesWithStatus ], ok = riak_utils : wait_until_ring_converged ( Nodes ), Nodes . As shown in the snippet above, a node is spawned by node_utls:start_node/3 . The function node_utils:pmap/2 is an asynchronous map fuction which is used to start multiple slave nodes asynchronously. - spec start_node ( atom (), non_neg_integer (), [ tuple ()]) -> { connect , node ()} | { ready , node ()}. start_node ( Name , Port , Config ) -> ct : log ( \"Starting node ~p \" , [ Name ]), CodePath = lists : filter ( fun filelib : is_dir / 1 , code : get_path ()), { ok , Cwd } = file : get_cwd (), % RclrefFolder is .../rclref/_build/test _ RclrefFolder = filename : dirname ( filename : dirname ( Cwd )), NodeConfig = [{ init_timeout , 3000 }, { startup_timeout , 3000 }, { monitor_master , true }, { startup_functions , [{ code , set_path , [ CodePath ]}]}], case ct_slave : start ( Name , NodeConfig ) of { ok , Node } -> % Load application to allow configuring the environment before starting ok = rpc : call ( Node , application , load , [ riak_core ]), ok = rpc : call ( Node , application , load , [ rclref ]), % Get remote working dir of node % NodeWorkingDir is .../rclref/_build/test/logs/ct_run.test@127.0.0.1.2020-00-00_00.00.00 { ok , NodeWorkingDir } = rpc : call ( Node , file , get_cwd , []), SuiteName = proplists : get_value ( module , Config , '' ), % Data Dirs ok = rpc : call ( Node , application , set_env , [ riak_core , ring_state_dir , filename : join ([ NodeWorkingDir , \"suites\" , SuiteName , Node , \"data/ring\" ])]), ok = rpc : call ( Node , application , set_env , [ riak_core , platform_data_dir , filename : join ([ NodeWorkingDir , \"suites\" , SuiteName , Node , \"data\" ])]), ok = rpc : call ( Node , application , set_env , [ riak_core , schema_dirs , filename : join ([ NodeWorkingDir , \"suites\" , SuiteName , Node , \"data\" ])]), % Set ports ok = rpc : call ( Node , application , set_env , [ riak_core , handoff_port , Port ]), ok = rpc : call ( Node , application , set_env , [ rclref , http_port , Port + 1 ]), % Logging Configuration LogRoot = filename : join ([ NodeWorkingDir , \"suites\" , SuiteName , Node , \"logs\" ]), ok = rpc : call ( Node , application , set_env , [ rclref , logger , log_config ( LogRoot )]), rpc : call ( Node , logger , set_primary_config , [ level , all ]), rpc : call ( Node , logger , add_handlers , [ rclref ]), % redirect slave logs to ct_master logs ok = rpc : call ( Node , application , set_env , [ rclref , ct_master , node ()]), ConfLog = #{ level => debug , formatter => { logger_formatter , #{ single_line => true , max_size => 2048 }}, config => #{ type => standard_io }}, _ = rpc : call ( Node , logger , add_handler , [ rclref_redirect_ct , ct_redirect_handler , ConfLog ]), % Configuration ok = rpc : call ( Node , application , set_env , [ riak_core , ring_creation_size , 8 ]), { ok , _} = rpc : call ( Node , application , ensure_all_started , [ riak_core ]), { ok , _} = rpc : call ( Node , application , ensure_all_started , [ rclref ]), ct : pal ( \"Node ~p stated with (handoff) port ~p \" , [ Node , Port ]), { connect , Node }; { error , already_started , Node } -> ct : log ( \"Node ~p already started, reusing node\" , [ Node ]), { ready , Node }; { error , Reason , Node } -> ct : pal ( \"Error starting node ~p , reason ~p , will retry\" , [ Node , Reason ]), ct_slave : stop ( Name ), time_utils : wait_until_offline ( Node ), start_node ( Name , Port , Config ) end . start_node/3 is the main fuction for starting up the nodes. As soon as the slave node has started by using ct_slave:start/2 , it is loading the applicaiton by rpc calls, such as ok = rpc:call(Node, application, load, [riak_core]) and ok = rpc:call(Node, application, load, [rclref]) . Once these are called, you can update the environment vairbales from the default values with rpc:call(Node, appcliation, set_env, [...]) . In rclref, setting environmental values such as where to store the riak_core related data and which port is used for handoff and http communication are managed this way. % Logging Configuration LogRoot = filename : join ([ NodeWorkingDir , \"suites\" , SuiteName , Node , \"logs\" ]), ok = rpc : call ( Node , application , set_env , [ rclref , logger , log_config ( LogRoot )]), The snippet above is for setting up the logging environment. LogRoot is the log directory for each node. In rclref, nodes are not reused for each test suite for saftey reasons so logs are seperated from each suite. For test suite that uses two nodes, the log directory looks like the following. | -- handoff_SUITE | | -- node1@localhost | | | -- data | | | ` -- ring | | | | -- riak_core_ring.default.20200817183651 | | | ` -- riak_core_ring.default.20200817183720 | | ` -- logs | | | -- debug.log | | | -- error.log | | | -- info.log | | | -- notice.log | | ` -- warning.log | ` -- node2@localhost | | -- data | | ` -- ring | | | -- riak_core_ring.default.20200817183650 | | | -- riak_core_ring.default.20200817183710 | | ` -- riak_core_ring.default.20200817183720 | ` -- logs | | -- debug.log | | -- error.log | | -- info.log | | -- notice.log | ` -- warning.log","title":"How to test distributed Erlang application using Common Test?"},{"location":"usage/","text":"How to actually use rclref? This page descirbes how to use rclref as a key-value store. First start the application by make , make console . UserAPI Get a Key-Value with key = dog ( rclref @ 127 . 0 . 0 . 1 ) 1 > rclref_client : get ( << \"dog\" >> ). { error , not_found } Store a Key-Value with key = dog, value = cat ( rclref @ 127 . 0 . 0 . 1 ) 2 > rclref_client : put ( << \"dog\" >> , << \"cat\" >> ). ok Get a Key-Value with key = dog ( rclref @ 127 . 0 . 0 . 1 ) 3 > rclref_client : get ( << \"dog\" >> ). { ok ,[ << \"cat\" >> , << \"cat\" >> , << \"cat\" >> ]} List all keys ( rclref @ 127 . 0 . 0 . 1 ) 4 > rclref_client : list_keys (). { ok ,[ << \"dog\" >> ]} Delete a Key-Value with key = dog. (Internally, this will not delete the value but leave it as a tombstone) ( rclref @ 127 . 0 . 0 . 1 ) 5 > rclref_client : delete ( << \"dog\" >> ). ok Get a Key-Value with key = dog. Note that tombstones are not observable. ( rclref @ 127 . 0 . 0 . 1 ) 6 > rclref_client : get ( << \"dog\" >> ). { error , not_found } HttpAPI Get a Key-Value with key = dog | = > curl -X GET http://localhost:8080/rclref/dog { \"error\" : { \"code\" : 404 , \"reason\" : \"not_found\" } } Store a Key-Value with key = dog, value = cat | = > curl -X POST http://localhost:8080/rclref/dog -d 'cat' { \"ok\" : { \"code\" : 200 } } Get a Key-Value with key = dog | = > curl -X GET http://localhost:8080/rclref/dog { \"ok\" : { \"code\" : 200 , \"values\" : [ \"cat\" , \"cat\" , \"cat\" ] } } Delete a Key-Value with key = dog. (Internally, this will not delete the value but leave it as a tombstone) | = > curl -X DELETE http://localhost:8080/rclref/dog { \"ok\" : { \"code\" : 200 } } Get a Key-Value with key = dog. Note that tombstones are not observable. | = > curl -X GET http://localhost:8080/rclref/dog { \"error\" : { \"code\" : 404 , \"reason\" : \"not_found\" } }","title":"How to actually use rclref?"},{"location":"usage/#how-to-actually-use-rclref","text":"This page descirbes how to use rclref as a key-value store. First start the application by make , make console .","title":"How to actually use rclref?"},{"location":"usage/#userapi","text":"Get a Key-Value with key = dog ( rclref @ 127 . 0 . 0 . 1 ) 1 > rclref_client : get ( << \"dog\" >> ). { error , not_found } Store a Key-Value with key = dog, value = cat ( rclref @ 127 . 0 . 0 . 1 ) 2 > rclref_client : put ( << \"dog\" >> , << \"cat\" >> ). ok Get a Key-Value with key = dog ( rclref @ 127 . 0 . 0 . 1 ) 3 > rclref_client : get ( << \"dog\" >> ). { ok ,[ << \"cat\" >> , << \"cat\" >> , << \"cat\" >> ]} List all keys ( rclref @ 127 . 0 . 0 . 1 ) 4 > rclref_client : list_keys (). { ok ,[ << \"dog\" >> ]} Delete a Key-Value with key = dog. (Internally, this will not delete the value but leave it as a tombstone) ( rclref @ 127 . 0 . 0 . 1 ) 5 > rclref_client : delete ( << \"dog\" >> ). ok Get a Key-Value with key = dog. Note that tombstones are not observable. ( rclref @ 127 . 0 . 0 . 1 ) 6 > rclref_client : get ( << \"dog\" >> ). { error , not_found }","title":"UserAPI"},{"location":"usage/#httpapi","text":"Get a Key-Value with key = dog | = > curl -X GET http://localhost:8080/rclref/dog { \"error\" : { \"code\" : 404 , \"reason\" : \"not_found\" } } Store a Key-Value with key = dog, value = cat | = > curl -X POST http://localhost:8080/rclref/dog -d 'cat' { \"ok\" : { \"code\" : 200 } } Get a Key-Value with key = dog | = > curl -X GET http://localhost:8080/rclref/dog { \"ok\" : { \"code\" : 200 , \"values\" : [ \"cat\" , \"cat\" , \"cat\" ] } } Delete a Key-Value with key = dog. (Internally, this will not delete the value but leave it as a tombstone) | = > curl -X DELETE http://localhost:8080/rclref/dog { \"ok\" : { \"code\" : 200 } } Get a Key-Value with key = dog. Note that tombstones are not observable. | = > curl -X GET http://localhost:8080/rclref/dog { \"error\" : { \"code\" : 404 , \"reason\" : \"not_found\" } }","title":"HttpAPI"},{"location":"userapi/","text":"UserAPI rclref_client Module rclref_client Module Summary Basic functions for manipulating rclref Description This module provides basic funcitons for reading data from and storing data into rclref, a key-value store on riak-core-lite. put(Key, Value) put(Key, Value, Options) get(Key) get(Key, Options) delete(Key) delete(Key, Options) list_keys() list_keys(Options) put(Key, Value) 1 -spec put(rclref_object:key(), rclref_object:value()) -> ok | {error, timeout} | {error, partial} | {error, term()}. This is equal to rclref_put(Key, Value, []) put(Key, Value, Options) 1 -spec put(rclref_object:key(), rclref_object:value(), [term()]) -> ok | {error, timeout} | {error, partial} | {error, term()}. store a Key-Value in N vnodes. When W vnodes respond with ok or more than N-W number of vnodes respond with an error, this function will return. If neither of these is satisified within TIMEOUT_PUT, then this function will return {error, timeout} Returns ok when W vnodes respond with ok. Returns {error, partial} when at least one of the vnodes (but not more than or equal to W vnodes) responds with ok before getting errors from more than N-W vnodes. Returns {error, [Reason]} when no vnodes respond with ok and more than N-W vnodes respond with an error. [Reason] is a list that contains error reasons of N-W+1 vnodes. Returns {error, timeout} when neither of these above are satisfied within TIMEOUT_PUT milliseconds. get(Key) 1 -spec get(rclref_object:key()) -> {ok, [rclref_object:value()]} | {error, timeout} | {error, partial} | {error, not_found} | {error, term()}. This is equal to get(Key, Value, Options) . get(Key, Options) 1 -spec get(rclref_object:key(), [term()]) -> {ok, [rclref_object:value()]} | {error, timeout} | {error, partial} | {error, not_found} | {error, term()}. get a Key-Value from N vnodes. When R number of vnodes respond with ok or more than N-R number of vnodes respond with an error, this fucntion will return. If neither of these is satisified with TIMEOUT_GET, then this function will return {error, timeout} On get, response from a vnode will be the either of {ok, RObj} , {error, not_found} , {error, Reason} Returns {ok, [Value]} when R vnodes respond with a value. [Value] is a list that contains values from R vnodes. Returns {error, partial} when at least one of the vnodes (but not more than or equal to R vnodes) responds with a value before getting errors from more than N-R vnodes. Returns {error, not_found} when no vnodes respond with a value and more than N-R vnodes respond with a error which are all not_found. Returns {error, [Reason]} when no vnodes respond with a value and more than N-R vnodes respond with a error which are not all not_found. [Reason] is a list that contains error reasons of N-R+1 vnodes. Returns {error, timeout} when neither of these above is satisified within TIMEOUT_GET milliseconds. delete(Key) 1 -spec delete(rclref_object:key()) -> ok | {error, timeout} | {error, partial} | {error, term()}. This is equal to delete(Key, []) . delete(Key, Options) 1 -spec delete(rclref_object:key(), [term()]) -> ok | {error, timeout} | {error, partial} | {error, term()}. This is equal to put(Key, undefined, Options) . Note that this will not delete the Key from the backend, however rclref_client:get(Key) will return {error, not_found} after calling this function. The reason why this is implemeted this way is explained in the [TODO] section. A Key-Value with an undefined value is called a tombstone. list_keys() 1 -spec list_keys() -> {ok, [rclref_object:key()]}. This is equal to list_keys([]) . list_keys(Options) 1 -spec list_keys([term()]) -> {ok, [rclref_object:key()]}. list all unique keys in the backend.","title":"UserAPI"},{"location":"userapi/#userapi","text":"","title":"UserAPI"},{"location":"userapi/#rclref_client","text":"","title":"rclref_client"},{"location":"userapi/#module","text":"rclref_client","title":"Module"},{"location":"userapi/#module-summary","text":"Basic functions for manipulating rclref","title":"Module Summary"},{"location":"userapi/#description","text":"This module provides basic funcitons for reading data from and storing data into rclref, a key-value store on riak-core-lite. put(Key, Value) put(Key, Value, Options) get(Key) get(Key, Options) delete(Key) delete(Key, Options) list_keys() list_keys(Options)","title":"Description"},{"location":"userapi/#putkey-value","text":"1 -spec put(rclref_object:key(), rclref_object:value()) -> ok | {error, timeout} | {error, partial} | {error, term()}. This is equal to rclref_put(Key, Value, [])","title":"put(Key, Value)"},{"location":"userapi/#putkey-value-options","text":"1 -spec put(rclref_object:key(), rclref_object:value(), [term()]) -> ok | {error, timeout} | {error, partial} | {error, term()}. store a Key-Value in N vnodes. When W vnodes respond with ok or more than N-W number of vnodes respond with an error, this function will return. If neither of these is satisified within TIMEOUT_PUT, then this function will return {error, timeout} Returns ok when W vnodes respond with ok. Returns {error, partial} when at least one of the vnodes (but not more than or equal to W vnodes) responds with ok before getting errors from more than N-W vnodes. Returns {error, [Reason]} when no vnodes respond with ok and more than N-W vnodes respond with an error. [Reason] is a list that contains error reasons of N-W+1 vnodes. Returns {error, timeout} when neither of these above are satisfied within TIMEOUT_PUT milliseconds.","title":"put(Key, Value, Options)"},{"location":"userapi/#getkey","text":"1 -spec get(rclref_object:key()) -> {ok, [rclref_object:value()]} | {error, timeout} | {error, partial} | {error, not_found} | {error, term()}. This is equal to get(Key, Value, Options) .","title":"get(Key)"},{"location":"userapi/#getkey-options","text":"1 -spec get(rclref_object:key(), [term()]) -> {ok, [rclref_object:value()]} | {error, timeout} | {error, partial} | {error, not_found} | {error, term()}. get a Key-Value from N vnodes. When R number of vnodes respond with ok or more than N-R number of vnodes respond with an error, this fucntion will return. If neither of these is satisified with TIMEOUT_GET, then this function will return {error, timeout} On get, response from a vnode will be the either of {ok, RObj} , {error, not_found} , {error, Reason} Returns {ok, [Value]} when R vnodes respond with a value. [Value] is a list that contains values from R vnodes. Returns {error, partial} when at least one of the vnodes (but not more than or equal to R vnodes) responds with a value before getting errors from more than N-R vnodes. Returns {error, not_found} when no vnodes respond with a value and more than N-R vnodes respond with a error which are all not_found. Returns {error, [Reason]} when no vnodes respond with a value and more than N-R vnodes respond with a error which are not all not_found. [Reason] is a list that contains error reasons of N-R+1 vnodes. Returns {error, timeout} when neither of these above is satisified within TIMEOUT_GET milliseconds.","title":"get(Key, Options)"},{"location":"userapi/#deletekey","text":"1 -spec delete(rclref_object:key()) -> ok | {error, timeout} | {error, partial} | {error, term()}. This is equal to delete(Key, []) .","title":"delete(Key)"},{"location":"userapi/#deletekey-options","text":"1 -spec delete(rclref_object:key(), [term()]) -> ok | {error, timeout} | {error, partial} | {error, term()}. This is equal to put(Key, undefined, Options) . Note that this will not delete the Key from the backend, however rclref_client:get(Key) will return {error, not_found} after calling this function. The reason why this is implemeted this way is explained in the [TODO] section. A Key-Value with an undefined value is called a tombstone.","title":"delete(Key, Options)"},{"location":"userapi/#list_keys","text":"1 -spec list_keys() -> {ok, [rclref_object:key()]}. This is equal to list_keys([]) .","title":"list_keys()"},{"location":"userapi/#list_keysoptions","text":"1 -spec list_keys([term()]) -> {ok, [rclref_object:key()]}. list all unique keys in the backend.","title":"list_keys(Options)"}]}