{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to the rclref develoment site rclref is a reference implementation of a key-value store built on riak-core-lite. rclref was created as part of Google Summer of Code 2020 with the aim of exercising various APIs of riak-core-lite with documented support. Updated version of the code is here . Development languages and tools The code is fully written in Erlang OTP > 21. License rclref is released under Apache License, Version 2.0 Table of Cotents How to setup riak_core_lite application? How are put, get, delete implemented in rclref? How to test distributed Erlang application using Common Test? How to benchmark riak_core_lite application? How to actually use rclref?","title":"Home"},{"location":"#welcome-to-the-rclref-develoment-site","text":"rclref is a reference implementation of a key-value store built on riak-core-lite. rclref was created as part of Google Summer of Code 2020 with the aim of exercising various APIs of riak-core-lite with documented support. Updated version of the code is here .","title":"Welcome to the rclref develoment site"},{"location":"#development-languages-and-tools","text":"The code is fully written in Erlang OTP > 21.","title":"Development languages and tools"},{"location":"#license","text":"rclref is released under Apache License, Version 2.0","title":"License"},{"location":"#table-of-cotents","text":"How to setup riak_core_lite application? How are put, get, delete implemented in rclref? How to test distributed Erlang application using Common Test? How to benchmark riak_core_lite application? How to actually use rclref?","title":"Table of Cotents"},{"location":"backend/","text":"Backend Warning Please check out the repository for the latest code. As shown in the diagram, each vnode will have their own backend to store the key-value. Backend Behaviour In order to make a generic backend that can support storages engines like ets or dets or even other modules depending on the user's preference, we will first implement a backend behaviour called rclref_backend.erl . In this module, we will declare functions that are essential for a backend to work. - module ( rclref_backend ). - type state () :: term (). - type fold_keys_fun () :: fun (( term (), any ()) -> any () | no_return ()). - type fold_objects_fun () :: fun (( term (), term (), any ()) -> any () | no_return ()). - type fold_acc () :: term (). - type fold_opts () :: [ term ()]. - type fold_result () :: { ok , fold_acc ()} | { async , fun ()} | { error , term ()}. - callback start ( PartitionIndex :: non_neg_integer (), Config :: [{ atom (), term ()}]) -> { ok , state ()}. - callback stop ( state ()) -> ok . - callback get ( rclref_object : key (), state ()) -> { ok , Value :: term (), state ()} | { ok , not_found , state ()} | { error , term (), state ()}. - callback put ( rclref_object : key (), Value :: binary (), state ()) -> { ok , state ()} | { error , term (), state ()}. - callback delete ( rclref_object : key (), state ()) -> { ok , state ()} | { error , term (), state ()}. - callback drop ( state ()) -> { ok , state ()} | { error , term (), state ()}. - callback fold_keys ( fold_keys_fun (), fold_acc (), fold_opts (), state ()) -> fold_result (). - callback fold_objects ( fold_objects_fun (), fold_acc (), fold_opts (), state ()) -> fold_result (). - callback is_empty ( state ()) -> boolean () | { error , term ()}. - callback status ( state ()) -> [{ atom (), term ()}]. ETS backend After implementing rclref_backend.erl , we need to implement an actual backend that utilizes this behaviour. rclref_ets_backend.erl sample implementation using Erlang Term Storage (ets) is given in the following snippet. - module ( rclref_ets_backend ). - behaviour ( rclref_backend ). - record ( state , { table_id }). - export ([ start / 2 , stop / 1 , get / 2 , put / 3 , delete / 2 , drop / 1 , fold_keys / 3 , fold_keys / 4 , fold_objects / 3 , fold_objects / 4 , is_empty / 1 , status / 1 ]). start (_ PartitionIndex , _ Config ) -> TableId = ets : new ( ? MODULE , [ set , { write_concurrency , false }, { read_concurrency , false }]), State = #state { table_id = TableId }, { ok , State }. stop (_ State = #state { table_id = TableId }) -> true = ets : delete ( TableId ), ok . get ( Key , State = #state { table_id = TableId }) -> case ets : lookup ( TableId , Key ) of [] -> { ok , not_found , State }; [{_, Value }] -> { ok , Value , State }; Reason -> { error , Reason , State } end . put ( Key , Value , State = #state { table_id = TableId }) -> true = ets : insert ( TableId , { Key , Value }), { ok , State }. delete ( Key , State = #state { table_id = TableId }) -> true = ets : delete ( TableId , Key ), { ok , State }. drop ( State = #state { table_id = TableId }) -> true = ets : delete_all_objects ( TableId ), { ok , State }. is_empty (_ State = #state { table_id = TableId }) -> ets : first ( TableId ) =:= '$end_of_table' . fold_keys ( Fun , Acc , State ) -> fold_keys ( Fun , Acc , [], State ). fold_keys ( Fun , Acc0 , _ Options , _ State = #state { table_id = TableId }) -> FoldKeysFun = fun ({ K , _}, A ) -> Fun ( K , A ) end , ets : foldl ( FoldKeysFun , Acc0 , TableId ). fold_objects ( Fun , Acc , State ) -> fold_objects ( Fun , Acc , [], State ). fold_objects ( Fun , Acc0 , _ Options , _ State = #state { table_id = TableId }) -> FoldObjectsFun = fun ({ K , V }, A ) -> Fun ( K , V , A ) end , ets : foldl ( FoldObjectsFun , Acc0 , TableId ). status (_ State = #state { table_id = TableId }) -> ets : info ( TableId ). DETS backend Implementation using disk-based term storage (dets) is also provided in rclref_dets_backend . - module ( rclref_dets_backend ). - behaviour ( rclref_backend ). - record ( state , { table_id }). - export ([ start / 2 , stop / 1 , get / 2 , put / 3 , delete / 2 , drop / 1 , fold_keys / 3 , fold_keys / 4 , fold_objects / 3 , fold_objects / 4 , is_empty / 1 , status / 1 ]). start ( Partition , _ Config ) -> { ok , TableId } = dets : open_file ( integer_to_list ( Partition ), [{ type , set }]), State = #state { table_id = TableId }, { ok , State }. stop (_ State = #state { table_id = TableId }) -> ok = dets : close ( TableId ), ok . get ( Key , State = #state { table_id = TableId }) -> case dets : lookup ( TableId , Key ) of [] -> { ok , not_found , State }; [{_, Value }] -> { ok , Value , State }; Reason -> { error , Reason , State } end . put ( Key , Value , State = #state { table_id = TableId }) -> ok = dets : insert ( TableId , { Key , Value }), { ok , State }. delete ( Key , State = #state { table_id = TableId }) -> ok = dets : delete ( TableId , Key ), { ok , State }. drop ( State = #state { table_id = TableId }) -> ok = dets : delete_all_objects ( TableId ), { ok , State }. is_empty (_ State = #state { table_id = TableId }) -> dets : first ( TableId ) =:= '$end_of_table' . fold_keys ( Fun , Acc , State ) -> fold_keys ( Fun , Acc , [], State ). fold_keys ( Fun , Acc0 , _ Options , _ State = #state { table_id = TableId }) -> FoldKeysFun = fun ({ K , _}, A ) -> Fun ( K , A ) end , dets : foldl ( FoldKeysFun , Acc0 , TableId ). fold_objects ( Fun , Acc , State ) -> fold_objects ( Fun , Acc , [], State ). fold_objects ( Fun , Acc0 , _ Options , _ State = #state { table_id = TableId }) -> FoldObjectsFun = fun ({ K , V }, A ) -> Fun ( K , V , A ) end , dets : foldl ( FoldObjectsFun , Acc0 , TableId ). status (_ State = #state { table_id = TableId }) -> dets : info ( TableId ).","title":"Backend"},{"location":"backend/#backend","text":"Warning Please check out the repository for the latest code. As shown in the diagram, each vnode will have their own backend to store the key-value.","title":"Backend"},{"location":"backend/#backend-behaviour","text":"In order to make a generic backend that can support storages engines like ets or dets or even other modules depending on the user's preference, we will first implement a backend behaviour called rclref_backend.erl . In this module, we will declare functions that are essential for a backend to work. - module ( rclref_backend ). - type state () :: term (). - type fold_keys_fun () :: fun (( term (), any ()) -> any () | no_return ()). - type fold_objects_fun () :: fun (( term (), term (), any ()) -> any () | no_return ()). - type fold_acc () :: term (). - type fold_opts () :: [ term ()]. - type fold_result () :: { ok , fold_acc ()} | { async , fun ()} | { error , term ()}. - callback start ( PartitionIndex :: non_neg_integer (), Config :: [{ atom (), term ()}]) -> { ok , state ()}. - callback stop ( state ()) -> ok . - callback get ( rclref_object : key (), state ()) -> { ok , Value :: term (), state ()} | { ok , not_found , state ()} | { error , term (), state ()}. - callback put ( rclref_object : key (), Value :: binary (), state ()) -> { ok , state ()} | { error , term (), state ()}. - callback delete ( rclref_object : key (), state ()) -> { ok , state ()} | { error , term (), state ()}. - callback drop ( state ()) -> { ok , state ()} | { error , term (), state ()}. - callback fold_keys ( fold_keys_fun (), fold_acc (), fold_opts (), state ()) -> fold_result (). - callback fold_objects ( fold_objects_fun (), fold_acc (), fold_opts (), state ()) -> fold_result (). - callback is_empty ( state ()) -> boolean () | { error , term ()}. - callback status ( state ()) -> [{ atom (), term ()}].","title":"Backend Behaviour"},{"location":"backend/#ets-backend","text":"After implementing rclref_backend.erl , we need to implement an actual backend that utilizes this behaviour. rclref_ets_backend.erl sample implementation using Erlang Term Storage (ets) is given in the following snippet. - module ( rclref_ets_backend ). - behaviour ( rclref_backend ). - record ( state , { table_id }). - export ([ start / 2 , stop / 1 , get / 2 , put / 3 , delete / 2 , drop / 1 , fold_keys / 3 , fold_keys / 4 , fold_objects / 3 , fold_objects / 4 , is_empty / 1 , status / 1 ]). start (_ PartitionIndex , _ Config ) -> TableId = ets : new ( ? MODULE , [ set , { write_concurrency , false }, { read_concurrency , false }]), State = #state { table_id = TableId }, { ok , State }. stop (_ State = #state { table_id = TableId }) -> true = ets : delete ( TableId ), ok . get ( Key , State = #state { table_id = TableId }) -> case ets : lookup ( TableId , Key ) of [] -> { ok , not_found , State }; [{_, Value }] -> { ok , Value , State }; Reason -> { error , Reason , State } end . put ( Key , Value , State = #state { table_id = TableId }) -> true = ets : insert ( TableId , { Key , Value }), { ok , State }. delete ( Key , State = #state { table_id = TableId }) -> true = ets : delete ( TableId , Key ), { ok , State }. drop ( State = #state { table_id = TableId }) -> true = ets : delete_all_objects ( TableId ), { ok , State }. is_empty (_ State = #state { table_id = TableId }) -> ets : first ( TableId ) =:= '$end_of_table' . fold_keys ( Fun , Acc , State ) -> fold_keys ( Fun , Acc , [], State ). fold_keys ( Fun , Acc0 , _ Options , _ State = #state { table_id = TableId }) -> FoldKeysFun = fun ({ K , _}, A ) -> Fun ( K , A ) end , ets : foldl ( FoldKeysFun , Acc0 , TableId ). fold_objects ( Fun , Acc , State ) -> fold_objects ( Fun , Acc , [], State ). fold_objects ( Fun , Acc0 , _ Options , _ State = #state { table_id = TableId }) -> FoldObjectsFun = fun ({ K , V }, A ) -> Fun ( K , V , A ) end , ets : foldl ( FoldObjectsFun , Acc0 , TableId ). status (_ State = #state { table_id = TableId }) -> ets : info ( TableId ).","title":"ETS backend"},{"location":"backend/#dets-backend","text":"Implementation using disk-based term storage (dets) is also provided in rclref_dets_backend . - module ( rclref_dets_backend ). - behaviour ( rclref_backend ). - record ( state , { table_id }). - export ([ start / 2 , stop / 1 , get / 2 , put / 3 , delete / 2 , drop / 1 , fold_keys / 3 , fold_keys / 4 , fold_objects / 3 , fold_objects / 4 , is_empty / 1 , status / 1 ]). start ( Partition , _ Config ) -> { ok , TableId } = dets : open_file ( integer_to_list ( Partition ), [{ type , set }]), State = #state { table_id = TableId }, { ok , State }. stop (_ State = #state { table_id = TableId }) -> ok = dets : close ( TableId ), ok . get ( Key , State = #state { table_id = TableId }) -> case dets : lookup ( TableId , Key ) of [] -> { ok , not_found , State }; [{_, Value }] -> { ok , Value , State }; Reason -> { error , Reason , State } end . put ( Key , Value , State = #state { table_id = TableId }) -> ok = dets : insert ( TableId , { Key , Value }), { ok , State }. delete ( Key , State = #state { table_id = TableId }) -> ok = dets : delete ( TableId , Key ), { ok , State }. drop ( State = #state { table_id = TableId }) -> ok = dets : delete_all_objects ( TableId ), { ok , State }. is_empty (_ State = #state { table_id = TableId }) -> dets : first ( TableId ) =:= '$end_of_table' . fold_keys ( Fun , Acc , State ) -> fold_keys ( Fun , Acc , [], State ). fold_keys ( Fun , Acc0 , _ Options , _ State = #state { table_id = TableId }) -> FoldKeysFun = fun ({ K , _}, A ) -> Fun ( K , A ) end , dets : foldl ( FoldKeysFun , Acc0 , TableId ). fold_objects ( Fun , Acc , State ) -> fold_objects ( Fun , Acc , [], State ). fold_objects ( Fun , Acc0 , _ Options , _ State = #state { table_id = TableId }) -> FoldObjectsFun = fun ({ K , V }, A ) -> Fun ( K , V , A ) end , dets : foldl ( FoldObjectsFun , Acc0 , TableId ). status (_ State = #state { table_id = TableId }) -> dets : info ( TableId ).","title":"DETS backend"},{"location":"benchmark/","text":"How to benchmark riak_core_lite application? rcl_bench","title":"How to benchmark riak_core_lite application?"},{"location":"benchmark/#how-to-benchmark-riak_core_lite-application","text":"","title":"How to benchmark riak_core_lite application?"},{"location":"benchmark/#rcl_bench","text":"","title":"rcl_bench"},{"location":"coordinator/","text":"Coordinator Warning Please check out the repository for the latest code. This page provides an overview of how coordinators are implemented in rclref. What does a coordinator do? Applications that use distributed databases tend to store multiple versions of the same object because it results in better fault tolerance. In riak_core_lite, this is done by distributing the same request to multiple vnodes such as putting a key-value. When the client requests the key-value, even when the primary vnode responsible for the key-value is not responding due to a failure, it is possible to retrieve it from other nodes with the replicas. The coordinator is responsible for distributing the request to the vnodes and collecting the results from them. How many replicas does it make?","title":"Coordinator"},{"location":"coordinator/#coordinator","text":"Warning Please check out the repository for the latest code. This page provides an overview of how coordinators are implemented in rclref.","title":"Coordinator"},{"location":"coordinator/#what-does-a-coordinator-do","text":"Applications that use distributed databases tend to store multiple versions of the same object because it results in better fault tolerance. In riak_core_lite, this is done by distributing the same request to multiple vnodes such as putting a key-value. When the client requests the key-value, even when the primary vnode responsible for the key-value is not responding due to a failure, it is possible to retrieve it from other nodes with the replicas. The coordinator is responsible for distributing the request to the vnodes and collecting the results from them.","title":"What does a coordinator do?"},{"location":"coordinator/#how-many-replicas-does-it-make","text":"","title":"How many replicas does it make?"},{"location":"other/","text":"Other This page provides information on stuff that has not been explained in other pages. What are vector clocks? How to completely delete a key-value from backend?","title":"Other"},{"location":"other/#other","text":"This page provides information on stuff that has not been explained in other pages.","title":"Other"},{"location":"other/#what-are-vector-clocks","text":"","title":"What are vector clocks?"},{"location":"other/#how-to-completely-delete-a-key-value-from-backend","text":"","title":"How to completely delete a key-value from backend?"},{"location":"put_get_delete/","text":"How are put, get, delete implemented in rclref? Warning Please check out the repository for the latest code. This page provides an overview of how put, get and delete are implemented in rclref. Code flow Put, get and delete have almost the same code flow. The code flow of rclref_client:get(Key) is shown in the following diagram. The main component of rclref is shown in the diagram above. When a user commands rclref_client:get(Key) , it will start a supervisor which manages a coodinator in simle one for one strategy. Then the coordinator will ask the vnodes for the requested data and send it back to the API module once it has collected a certain number of responses. Let's look at how each part of them are implemented from bottom up. Backend Two types of backend is provided in rclref, which are ETS and DETS. ETS is short for Erlang Term Storage which is an in-memory storage that can store erlang terms. DETS is short for Disk ETS which is an disk based persistent storage with almost the same interface as ETS. Since DETS store data in the disk, it is much slower than ETS but has smaller memory footprint. Read here for implementation details. Vnodes The main feature of riak_core(riak_core_lite) is to distribute client requests to processes in the nodes in the cluster. These processes are often referred to as virtual nodes (vnodes). The number of vnodes in a cluster is dependent on the size of the ring of that cluster. A ring is divided into a fixed number of partitions and each vnode is responsible for one of them. When a client makes a request, a hash will be calculated from a client\u2019s request denoting which partition of the ring (thus, vnode) is responsible for handling the request. This is called consistent hashing. With consistent hashing, the following can be achieved. Even distribution of key workload between vnodes. Smooth adaption to dynamic changes in the cluster by replication of data. A detailed explanation of consistent hashing is provided here . In rclref, a vnode handles the following requests. put, get, delete request handoff request coverage request Read here for implementation details. Coordinator Requests made by a client are handled by a coordinator. The coordinator will interact with the vnodes by sending and receiving the requests. For example, if it receives a put request, it generates a hash to determine which vnodes to send the requests to and send it to them. Usually, the coordinator will send the put request to multiple vnodes so that multiple copies of the object exist in the cluster. This is called replication and this ensures the fault tolerance of the database. Read here for implementation details. Supervisor Supervisors are used to manage the coordinators. They will restart the coordinator process when needed. Read here for implementation details. API In rclref, three APIs are provided that can be used to put, get and delete an object from the backend. LowLevelAPI UserAPI HttpAPI It is recommended that the user only use the UserLevelAPI and HttpAPI for manipulating the database. LowLevelAPI should only be used for debugging. The usage of UserAPI and HttpAPI is provided here . LowLevelAPI LowLevelAPI is provided by rclref.erl module. This API should only be used in the case of debugging because it reveals detailed information about the object on put, get and delete which should be transparent to the user of rclref. Such as node partition number vector clock In addition, some queries are exclusive to this module such as reap list_all_keys list_all_objects Read here for implementation details. UserAPI UserAPI is provided by rclref_client.erl module. Compared with the LowLevelAPI, this API reveals less information on put, get, and delete. Read here for implementation details. HttpAPI HttpAPI is provided using the rclref_http_handler.erl using the Cowboy library. This API reveals the same amount of information on put, get, and delete as the UserAPI. Read here for implementation details.","title":"How are put, get, delete implemented in rclref?"},{"location":"put_get_delete/#how-are-put-get-delete-implemented-in-rclref","text":"Warning Please check out the repository for the latest code. This page provides an overview of how put, get and delete are implemented in rclref.","title":"How are put, get, delete implemented in rclref?"},{"location":"put_get_delete/#code-flow","text":"Put, get and delete have almost the same code flow. The code flow of rclref_client:get(Key) is shown in the following diagram. The main component of rclref is shown in the diagram above. When a user commands rclref_client:get(Key) , it will start a supervisor which manages a coodinator in simle one for one strategy. Then the coordinator will ask the vnodes for the requested data and send it back to the API module once it has collected a certain number of responses. Let's look at how each part of them are implemented from bottom up.","title":"Code flow"},{"location":"put_get_delete/#backend","text":"Two types of backend is provided in rclref, which are ETS and DETS. ETS is short for Erlang Term Storage which is an in-memory storage that can store erlang terms. DETS is short for Disk ETS which is an disk based persistent storage with almost the same interface as ETS. Since DETS store data in the disk, it is much slower than ETS but has smaller memory footprint. Read here for implementation details.","title":"Backend"},{"location":"put_get_delete/#vnodes","text":"The main feature of riak_core(riak_core_lite) is to distribute client requests to processes in the nodes in the cluster. These processes are often referred to as virtual nodes (vnodes). The number of vnodes in a cluster is dependent on the size of the ring of that cluster. A ring is divided into a fixed number of partitions and each vnode is responsible for one of them. When a client makes a request, a hash will be calculated from a client\u2019s request denoting which partition of the ring (thus, vnode) is responsible for handling the request. This is called consistent hashing. With consistent hashing, the following can be achieved. Even distribution of key workload between vnodes. Smooth adaption to dynamic changes in the cluster by replication of data. A detailed explanation of consistent hashing is provided here . In rclref, a vnode handles the following requests. put, get, delete request handoff request coverage request Read here for implementation details.","title":"Vnodes"},{"location":"put_get_delete/#coordinator","text":"Requests made by a client are handled by a coordinator. The coordinator will interact with the vnodes by sending and receiving the requests. For example, if it receives a put request, it generates a hash to determine which vnodes to send the requests to and send it to them. Usually, the coordinator will send the put request to multiple vnodes so that multiple copies of the object exist in the cluster. This is called replication and this ensures the fault tolerance of the database. Read here for implementation details.","title":"Coordinator"},{"location":"put_get_delete/#supervisor","text":"Supervisors are used to manage the coordinators. They will restart the coordinator process when needed. Read here for implementation details.","title":"Supervisor"},{"location":"put_get_delete/#api","text":"In rclref, three APIs are provided that can be used to put, get and delete an object from the backend. LowLevelAPI UserAPI HttpAPI It is recommended that the user only use the UserLevelAPI and HttpAPI for manipulating the database. LowLevelAPI should only be used for debugging. The usage of UserAPI and HttpAPI is provided here .","title":"API"},{"location":"put_get_delete/#lowlevelapi","text":"LowLevelAPI is provided by rclref.erl module. This API should only be used in the case of debugging because it reveals detailed information about the object on put, get and delete which should be transparent to the user of rclref. Such as node partition number vector clock In addition, some queries are exclusive to this module such as reap list_all_keys list_all_objects Read here for implementation details.","title":"LowLevelAPI"},{"location":"put_get_delete/#userapi","text":"UserAPI is provided by rclref_client.erl module. Compared with the LowLevelAPI, this API reveals less information on put, get, and delete. Read here for implementation details.","title":"UserAPI"},{"location":"put_get_delete/#httpapi","text":"HttpAPI is provided using the rclref_http_handler.erl using the Cowboy library. This API reveals the same amount of information on put, get, and delete as the UserAPI. Read here for implementation details.","title":"HttpAPI"},{"location":"setup/","text":"How to a setup riak_core_lite application? This page provides an overview of how to setup a riak_core_lite applicaiton. Erlang Install Erlang OTP version > 22 rebar3 Install rebar3 riak_core_lite Clone riak_core_lite template by the following command: mkdir -p ~/.config/rebar3/templates git clone https://github.com/riak-core-lite/rebar3_template_riak_core_lite.git ~/.config/rebar3/templates/rebar3_template_riak_core_lite Create a new riak_core_lite project: rebar3 new rebar3_riak_core_lite name = YOURAPP See here for details. elvis Elvis is a Erlang style reviewer. Install Elvis from here . Configure it by creating elvis.config in the repository. The following snippet is the configuration used in rclref. %linting and style rules [{ elvis , [{ config , [#{ dirs => [ \"apps/*/src\" ], filter => \"*.erl\" , rules => [{ elvis_style , line_length , #{ ignore => [], limit => 100 , skip_comments => false }}, { elvis_style , no_tabs }, { elvis_style , no_trailing_whitespace }, { elvis_style , macro_names , #{ ignore => []}}, { elvis_style , macro_module_names }, { elvis_style , operator_spaces , #{ rules => [{ right , \",\" }, { right , \"++\" }, { left , \"++\" }, { right , \"--\" }, { left , \"--\" }]}}, %{elvis_style, god_modules, %#{limit => 40, % ignore => []}}, { elvis_style , used_ignored_variable }, { elvis_style , no_behavior_info }, { elvis_style , module_naming_convention , #{ regex => \"^[a-z]([a-z0-9]*_?)*(_SUITE)?$\" , ignore => []} }, { elvis_style , function_naming_convention , #{ regex => \"^[a-z]([a-z0-9]*_?)*$\" } %base: ^([a-z][a-z0-9]*_?)*$ }, { elvis_style , state_record_and_type }, { elvis_style , no_spec_with_records } ] }, #{ dirs => [ \".\" ], filter => \"Makefile\" , rules => [{ elvis_project , no_deps_master_erlang_mk , #{ ignore => []}}, { elvis_project , protocol_for_deps_erlang_mk , #{ ignore => []}}] }, #{ dirs => [ \".\" ], filter => \"rebar.config\" , rules => [{ elvis_project , no_deps_master_rebar , #{ ignore => []}}, { elvis_project , protocol_for_deps_rebar , #{ ignore => []}}] } ] }] }]. After configuring, the code can be reviewed by: elvis rock --config elvis.config rebar3_format rebar3_format is a code formatter for Erlang. Add the following lines to rebar.config . { plugins , [ rebar3_format ]}. { format , [{ files , [ \"apps/rclref/src/*.erl\" , \"test/*.erl\" , \"test/utils/*.erl\" ]}]}. Then the code can be formatted by rebar3 format dialyzer A static type checking can be done by: rebar3 dialyzer","title":"How to setup a riak_core_lite application?"},{"location":"setup/#how-to-a-setup-riak_core_lite-application","text":"This page provides an overview of how to setup a riak_core_lite applicaiton.","title":"How to a setup riak_core_lite application?"},{"location":"setup/#erlang","text":"Install Erlang OTP version > 22","title":"Erlang"},{"location":"setup/#rebar3","text":"Install rebar3","title":"rebar3"},{"location":"setup/#riak_core_lite","text":"Clone riak_core_lite template by the following command: mkdir -p ~/.config/rebar3/templates git clone https://github.com/riak-core-lite/rebar3_template_riak_core_lite.git ~/.config/rebar3/templates/rebar3_template_riak_core_lite Create a new riak_core_lite project: rebar3 new rebar3_riak_core_lite name = YOURAPP See here for details.","title":"riak_core_lite"},{"location":"setup/#elvis","text":"Elvis is a Erlang style reviewer. Install Elvis from here . Configure it by creating elvis.config in the repository. The following snippet is the configuration used in rclref. %linting and style rules [{ elvis , [{ config , [#{ dirs => [ \"apps/*/src\" ], filter => \"*.erl\" , rules => [{ elvis_style , line_length , #{ ignore => [], limit => 100 , skip_comments => false }}, { elvis_style , no_tabs }, { elvis_style , no_trailing_whitespace }, { elvis_style , macro_names , #{ ignore => []}}, { elvis_style , macro_module_names }, { elvis_style , operator_spaces , #{ rules => [{ right , \",\" }, { right , \"++\" }, { left , \"++\" }, { right , \"--\" }, { left , \"--\" }]}}, %{elvis_style, god_modules, %#{limit => 40, % ignore => []}}, { elvis_style , used_ignored_variable }, { elvis_style , no_behavior_info }, { elvis_style , module_naming_convention , #{ regex => \"^[a-z]([a-z0-9]*_?)*(_SUITE)?$\" , ignore => []} }, { elvis_style , function_naming_convention , #{ regex => \"^[a-z]([a-z0-9]*_?)*$\" } %base: ^([a-z][a-z0-9]*_?)*$ }, { elvis_style , state_record_and_type }, { elvis_style , no_spec_with_records } ] }, #{ dirs => [ \".\" ], filter => \"Makefile\" , rules => [{ elvis_project , no_deps_master_erlang_mk , #{ ignore => []}}, { elvis_project , protocol_for_deps_erlang_mk , #{ ignore => []}}] }, #{ dirs => [ \".\" ], filter => \"rebar.config\" , rules => [{ elvis_project , no_deps_master_rebar , #{ ignore => []}}, { elvis_project , protocol_for_deps_rebar , #{ ignore => []}}] } ] }] }]. After configuring, the code can be reviewed by: elvis rock --config elvis.config","title":"elvis"},{"location":"setup/#rebar3_format","text":"rebar3_format is a code formatter for Erlang. Add the following lines to rebar.config . { plugins , [ rebar3_format ]}. { format , [{ files , [ \"apps/rclref/src/*.erl\" , \"test/*.erl\" , \"test/utils/*.erl\" ]}]}. Then the code can be formatted by rebar3 format","title":"rebar3_format"},{"location":"setup/#dialyzer","text":"A static type checking can be done by: rebar3 dialyzer","title":"dialyzer"},{"location":"supervisor/","text":"Supervisor This page provides an overview of how supervisors are implemented in rclref. Warning Please check out the repository for the latest code. What does a supervisor do? Supervisor in rclref supervises the coordinators. Since there are 3 coordinators, there are 3 supervisors as well. Coordinator Supervisor rclref_put_statem.erl rclref_put_statem_sup.erl rclref_get_statem.erl rclref_get_statem_sup.erl riak_core_coverage_fsm.erl rclref_coverage_fsm_sup.erl There is also another supervisor that supervises these supervisors. These supevisors are activated on starting up the application by this supervisor. This is defined in rclref_sup.erl . - module ( rclref_sup ). - behaviour ( supervisor ). - export ([ start_link / 0 ]). - export ([ init / 1 ]). % API start_link () -> supervisor : start_link ({ local , ? MODULE }, ? MODULE , []). % Callbacks init (_ Args ) -> VMaster = { rclref_vnode_master , { riak_core_vnode_master , start_link , [ rclref_vnode ]}, permanent , 5000 , worker , [ riak_core_vnode_master ]}, PutStatem = { rclref_put_statem_sup , { rclref_put_statem_sup , start_link , []}, permanent , infinity , supervisor , [ rclref_put_statem_sup ]}, GetStatem = { rclref_get_statem_sup , { rclref_get_statem_sup , start_link , []}, permanent , infinity , supervisor , [ rclref_get_statem_sup ]}, CoverageFsm = { rclref_coverage_fsm_sup , { rclref_coverage_fsm_sup , start_link , []}, permanent , infinity , supervisor , [ rclref_coverage_fsm_sup ]}, { ok , {{ one_for_one , 5 , 10 }, [ VMaster , PutStatem , GetStatem , CoverageFsm ]}}. put supervisor A put supervisor is defined in rclref_put_statem_sup.erl . - module ( rclref_put_statem_sup ). - behaviour ( supervisor ). - export ([ start_put_statem / 1 , stop_put_statem / 1 , start_link / 0 ]). - export ([ init / 1 ]). start_put_statem ( Args ) -> ReqId = reqid (), { ok , _} = supervisor : start_child ( ? MODULE , [[ ReqId ] ++ Args ]), { ok , ReqId }. stop_put_statem ( Pid ) -> ok = supervisor : terminate_child ( ? MODULE , Pid ), ok = supervisor : delete_child ( ? MODULE , Pid ). start_link () -> { ok , _} = supervisor : start_link ({ local , ? MODULE }, ? MODULE , []). % Callbacks init ([]) -> PutStatem = { undefined , { rclref_put_statem , start_link , []}, temporary , 5000 , worker , [ rclref_put_statem ]}, { ok , {{ simple_one_for_one , 10 , 10 }, [ PutStatem ]}}. % Internal Functions - spec reqid () -> non_neg_integer (). reqid () -> erlang : phash2 ( erlang : monotonic_time ()). The important function in the snippet above is the start_put_statem/1 . This function will be called by the LowLevelAPI to start up the coordinator","title":"Supervisor"},{"location":"supervisor/#supervisor","text":"This page provides an overview of how supervisors are implemented in rclref. Warning Please check out the repository for the latest code.","title":"Supervisor"},{"location":"supervisor/#what-does-a-supervisor-do","text":"Supervisor in rclref supervises the coordinators. Since there are 3 coordinators, there are 3 supervisors as well. Coordinator Supervisor rclref_put_statem.erl rclref_put_statem_sup.erl rclref_get_statem.erl rclref_get_statem_sup.erl riak_core_coverage_fsm.erl rclref_coverage_fsm_sup.erl There is also another supervisor that supervises these supervisors. These supevisors are activated on starting up the application by this supervisor. This is defined in rclref_sup.erl . - module ( rclref_sup ). - behaviour ( supervisor ). - export ([ start_link / 0 ]). - export ([ init / 1 ]). % API start_link () -> supervisor : start_link ({ local , ? MODULE }, ? MODULE , []). % Callbacks init (_ Args ) -> VMaster = { rclref_vnode_master , { riak_core_vnode_master , start_link , [ rclref_vnode ]}, permanent , 5000 , worker , [ riak_core_vnode_master ]}, PutStatem = { rclref_put_statem_sup , { rclref_put_statem_sup , start_link , []}, permanent , infinity , supervisor , [ rclref_put_statem_sup ]}, GetStatem = { rclref_get_statem_sup , { rclref_get_statem_sup , start_link , []}, permanent , infinity , supervisor , [ rclref_get_statem_sup ]}, CoverageFsm = { rclref_coverage_fsm_sup , { rclref_coverage_fsm_sup , start_link , []}, permanent , infinity , supervisor , [ rclref_coverage_fsm_sup ]}, { ok , {{ one_for_one , 5 , 10 }, [ VMaster , PutStatem , GetStatem , CoverageFsm ]}}.","title":"What does a supervisor do?"},{"location":"supervisor/#put-supervisor","text":"A put supervisor is defined in rclref_put_statem_sup.erl . - module ( rclref_put_statem_sup ). - behaviour ( supervisor ). - export ([ start_put_statem / 1 , stop_put_statem / 1 , start_link / 0 ]). - export ([ init / 1 ]). start_put_statem ( Args ) -> ReqId = reqid (), { ok , _} = supervisor : start_child ( ? MODULE , [[ ReqId ] ++ Args ]), { ok , ReqId }. stop_put_statem ( Pid ) -> ok = supervisor : terminate_child ( ? MODULE , Pid ), ok = supervisor : delete_child ( ? MODULE , Pid ). start_link () -> { ok , _} = supervisor : start_link ({ local , ? MODULE }, ? MODULE , []). % Callbacks init ([]) -> PutStatem = { undefined , { rclref_put_statem , start_link , []}, temporary , 5000 , worker , [ rclref_put_statem ]}, { ok , {{ simple_one_for_one , 10 , 10 }, [ PutStatem ]}}. % Internal Functions - spec reqid () -> non_neg_integer (). reqid () -> erlang : phash2 ( erlang : monotonic_time ()). The important function in the snippet above is the start_put_statem/1 . This function will be called by the LowLevelAPI to start up the coordinator","title":"put supervisor"},{"location":"test/","text":"How to test distributed Erlang application using Common Test? This page provides an overview of how to test distributed application in Erlang. In rclref, Common Test (CT) is used for integrated testing. This post explains how to use CT for distributed applications assuming that the reader already knows how to use CT in a single node environment. The issue in testing distributed application in Erlang often relies on how to spawn multiple Erlang nodes from CT and how to manage their logs. The Goal of this post is to be able to test distirbuted Erlang application using rebar3 and understand how to organize the logs of several distributed nodes. The following is a snippet from client_SUITE.erl in rclref repository. init_per_suite ( Config ) -> application : ensure_all_started ( rclref ), Names = [ node1 ], Ports = [ 30400 ], Nodes = node_utils : set_up_nodes ( Names , Ports , [{ module , ? MODULE }]), [{ module , ? MODULE }, { names , Names }, { nodes , Nodes }, { ports , Ports } | Config ]. end_per_suite ( Config ) -> Nodes = ? config ( nodes , Config ), node_utils : kill_nodes ( Nodes ), Config . put_get_delete_test ( Config ) -> [ Node ] = ? config ( nodes , Config ), Keys = [ \"key--\" ++ integer_to_list ( Num ) || Num <- lists : seq ( 1 , 20 )], Values = [ \"value--\" ++ integer_to_list ( Num ) || Num <- lists : seq ( 1 , 20 )], % check not_found lists : foreach ( fun ( Key ) -> { error , not_found } = rpc : call ( Node , rclref_client , get , [ Key ]) end , Keys ), % put values lists : foreach ( fun ({ Key , Value }) -> ok = rpc : call ( Node , rclref_client , put , [ Key , Value ]) end , lists : zip ( Keys , Values )), % confirm values lists : foreach ( fun ({ Key , Value }) -> { ok , GotValues } = rpc : call ( Node , rclref_client , get , [ Key ]), true = lists : all ( fun ( GotValue ) -> Value =:= GotValue end , GotValues ) end , lists : zip ( Keys , Values )), % delete values lists : foreach ( fun ( Key ) -> ok = rpc : call ( Node , rclref_client , delete , [ Key ]) end , Keys ), % check not_found lists : foreach ( fun ( Key ) -> { error , not_found } = rpc : call ( Node , rclref_client , get , [ Key ]) end , Keys ), ok . The init_per_suite/1 will start an applicaiotn with nodename \"node1\" on port 30400 by calling node_utils:set_upnodes(Names, Ports, [{module, ?MODULE}]) . Internally, the node_util module basically spawns a slave node with ct_slave:start/2 and configures environmental variales. CT will automatically call put_get_delete_test/1 after init_per_suite/1 is called. put_get_delete_test/1 is a basic test storing and deleteing 20 key-values to the slave node that has just been staretd by init_per_suite/1 . Note that in order to access the remote node, remote procedure call should be used. For example, putting a key-value in the slave node is done by ok = rpc:call(Node, rclref_client, put, [Key, Value]) . Now let's see the node_utls module in more detail. - spec set_up_nodes ([ atom ()], [ non_neg_integer ()], [ tuple ()]) -> [ node ()]. set_up_nodes ( Names , Ports , Config ) -> NodesWithStatus = node_utils : pmap ( fun ({ Name , Port }) -> node_utils : start_node ( Name , Port , Config ) end , lists : zip ( Names , Ports )), Nodes = [ Node || { connect , Node } <- NodesWithStatus ], ok = riak_utils : wait_until_ring_converged ( Nodes ), Nodes . As shown in the snippet above, a node is spawned by node_utls:start_node/3 . The function node_utils:pmap/2 is an asynchronous map fuction which is used to start multiple slave nodes asynchronously. - spec start_node ( atom (), non_neg_integer (), [ tuple ()]) -> { connect , node ()} | { ready , node ()}. start_node ( Name , Port , Config ) -> ct : log ( \"Starting node ~p \" , [ Name ]), CodePath = lists : filter ( fun filelib : is_dir / 1 , code : get_path ()), { ok , Cwd } = file : get_cwd (), % RclrefFolder is .../rclref/_build/test _ RclrefFolder = filename : dirname ( filename : dirname ( Cwd )), NodeConfig = [{ init_timeout , 3000 }, { startup_timeout , 3000 }, { monitor_master , true }, { startup_functions , [{ code , set_path , [ CodePath ]}]}], case ct_slave : start ( Name , NodeConfig ) of { ok , Node } -> % Load application to allow configuring the environment before starting ok = rpc : call ( Node , application , load , [ riak_core ]), ok = rpc : call ( Node , application , load , [ rclref ]), % Get remote working dir of node % NodeWorkingDir is .../rclref/_build/test/logs/ct_run.test@127.0.0.1.2020-00-00_00.00.00 { ok , NodeWorkingDir } = rpc : call ( Node , file , get_cwd , []), SuiteName = proplists : get_value ( module , Config , '' ), % Data Dirs ok = rpc : call ( Node , application , set_env , [ riak_core , ring_state_dir , filename : join ([ NodeWorkingDir , \"suites\" , SuiteName , Node , \"data/ring\" ])]), ok = rpc : call ( Node , application , set_env , [ riak_core , platform_data_dir , filename : join ([ NodeWorkingDir , \"suites\" , SuiteName , Node , \"data\" ])]), ok = rpc : call ( Node , application , set_env , [ riak_core , schema_dirs , filename : join ([ NodeWorkingDir , \"suites\" , SuiteName , Node , \"data\" ])]), % Set ports ok = rpc : call ( Node , application , set_env , [ riak_core , handoff_port , Port ]), ok = rpc : call ( Node , application , set_env , [ rclref , http_port , Port + 1 ]), % Logging Configuration LogRoot = filename : join ([ NodeWorkingDir , \"suites\" , SuiteName , Node , \"logs\" ]), ok = rpc : call ( Node , application , set_env , [ rclref , logger , log_config ( LogRoot )]), rpc : call ( Node , logger , set_primary_config , [ level , all ]), rpc : call ( Node , logger , add_handlers , [ rclref ]), % redirect slave logs to ct_master logs ok = rpc : call ( Node , application , set_env , [ rclref , ct_master , node ()]), ConfLog = #{ level => debug , formatter => { logger_formatter , #{ single_line => true , max_size => 2048 }}, config => #{ type => standard_io }}, _ = rpc : call ( Node , logger , add_handler , [ rclref_redirect_ct , ct_redirect_handler , ConfLog ]), % Configuration ok = rpc : call ( Node , application , set_env , [ riak_core , ring_creation_size , 8 ]), { ok , _} = rpc : call ( Node , application , ensure_all_started , [ riak_core ]), { ok , _} = rpc : call ( Node , application , ensure_all_started , [ rclref ]), ct : pal ( \"Node ~p stated with (handoff) port ~p \" , [ Node , Port ]), { connect , Node }; { error , already_started , Node } -> ct : log ( \"Node ~p already started, reusing node\" , [ Node ]), { ready , Node }; { error , Reason , Node } -> ct : pal ( \"Error starting node ~p , reason ~p , will retry\" , [ Node , Reason ]), ct_slave : stop ( Name ), time_utils : wait_until_offline ( Node ), start_node ( Name , Port , Config ) end . start_node/3 is the main fuction for starting up the nodes. As soon as the slave node has started by using ct_slave:start/2 , it is loading the applicaiton by rpc calls, such as ok = rpc:call(Node, application, load, [riak_core]) and ok = rpc:call(Node, application, load, [rclref]) . Once these are called, you can update the environment vairbales from the default values with rpc:call(Node, appcliation, set_env, [...]) . In rclref, setting environmental values such as where to store the riak_core related data and which port is used for handoff and http communication are managed this way. % Logging Configuration LogRoot = filename : join ([ NodeWorkingDir , \"suites\" , SuiteName , Node , \"logs\" ]), ok = rpc : call ( Node , application , set_env , [ rclref , logger , log_config ( LogRoot )]), The snippet above is for setting up the logging environment. LogRoot is the log directory for each node. In rclref, nodes are not reused for each test suite for saftey reasons so logs are seperated from each suite. For test suite that uses two nodes, the log directory looks like the following. | -- handoff_SUITE | | -- node1@localhost | | | -- data | | | ` -- ring | | | | -- riak_core_ring.default.20200817183651 | | | ` -- riak_core_ring.default.20200817183720 | | ` -- logs | | | -- debug.log | | | -- error.log | | | -- info.log | | | -- notice.log | | ` -- warning.log | ` -- node2@localhost | | -- data | | ` -- ring | | | -- riak_core_ring.default.20200817183650 | | | -- riak_core_ring.default.20200817183710 | | ` -- riak_core_ring.default.20200817183720 | ` -- logs | | -- debug.log | | -- error.log | | -- info.log | | -- notice.log | ` -- warning.log","title":"How to test distributed Erlang application using Common Test?"},{"location":"test/#how-to-test-distributed-erlang-application-using-common-test","text":"This page provides an overview of how to test distributed application in Erlang. In rclref, Common Test (CT) is used for integrated testing. This post explains how to use CT for distributed applications assuming that the reader already knows how to use CT in a single node environment. The issue in testing distributed application in Erlang often relies on how to spawn multiple Erlang nodes from CT and how to manage their logs. The Goal of this post is to be able to test distirbuted Erlang application using rebar3 and understand how to organize the logs of several distributed nodes. The following is a snippet from client_SUITE.erl in rclref repository. init_per_suite ( Config ) -> application : ensure_all_started ( rclref ), Names = [ node1 ], Ports = [ 30400 ], Nodes = node_utils : set_up_nodes ( Names , Ports , [{ module , ? MODULE }]), [{ module , ? MODULE }, { names , Names }, { nodes , Nodes }, { ports , Ports } | Config ]. end_per_suite ( Config ) -> Nodes = ? config ( nodes , Config ), node_utils : kill_nodes ( Nodes ), Config . put_get_delete_test ( Config ) -> [ Node ] = ? config ( nodes , Config ), Keys = [ \"key--\" ++ integer_to_list ( Num ) || Num <- lists : seq ( 1 , 20 )], Values = [ \"value--\" ++ integer_to_list ( Num ) || Num <- lists : seq ( 1 , 20 )], % check not_found lists : foreach ( fun ( Key ) -> { error , not_found } = rpc : call ( Node , rclref_client , get , [ Key ]) end , Keys ), % put values lists : foreach ( fun ({ Key , Value }) -> ok = rpc : call ( Node , rclref_client , put , [ Key , Value ]) end , lists : zip ( Keys , Values )), % confirm values lists : foreach ( fun ({ Key , Value }) -> { ok , GotValues } = rpc : call ( Node , rclref_client , get , [ Key ]), true = lists : all ( fun ( GotValue ) -> Value =:= GotValue end , GotValues ) end , lists : zip ( Keys , Values )), % delete values lists : foreach ( fun ( Key ) -> ok = rpc : call ( Node , rclref_client , delete , [ Key ]) end , Keys ), % check not_found lists : foreach ( fun ( Key ) -> { error , not_found } = rpc : call ( Node , rclref_client , get , [ Key ]) end , Keys ), ok . The init_per_suite/1 will start an applicaiotn with nodename \"node1\" on port 30400 by calling node_utils:set_upnodes(Names, Ports, [{module, ?MODULE}]) . Internally, the node_util module basically spawns a slave node with ct_slave:start/2 and configures environmental variales. CT will automatically call put_get_delete_test/1 after init_per_suite/1 is called. put_get_delete_test/1 is a basic test storing and deleteing 20 key-values to the slave node that has just been staretd by init_per_suite/1 . Note that in order to access the remote node, remote procedure call should be used. For example, putting a key-value in the slave node is done by ok = rpc:call(Node, rclref_client, put, [Key, Value]) . Now let's see the node_utls module in more detail. - spec set_up_nodes ([ atom ()], [ non_neg_integer ()], [ tuple ()]) -> [ node ()]. set_up_nodes ( Names , Ports , Config ) -> NodesWithStatus = node_utils : pmap ( fun ({ Name , Port }) -> node_utils : start_node ( Name , Port , Config ) end , lists : zip ( Names , Ports )), Nodes = [ Node || { connect , Node } <- NodesWithStatus ], ok = riak_utils : wait_until_ring_converged ( Nodes ), Nodes . As shown in the snippet above, a node is spawned by node_utls:start_node/3 . The function node_utils:pmap/2 is an asynchronous map fuction which is used to start multiple slave nodes asynchronously. - spec start_node ( atom (), non_neg_integer (), [ tuple ()]) -> { connect , node ()} | { ready , node ()}. start_node ( Name , Port , Config ) -> ct : log ( \"Starting node ~p \" , [ Name ]), CodePath = lists : filter ( fun filelib : is_dir / 1 , code : get_path ()), { ok , Cwd } = file : get_cwd (), % RclrefFolder is .../rclref/_build/test _ RclrefFolder = filename : dirname ( filename : dirname ( Cwd )), NodeConfig = [{ init_timeout , 3000 }, { startup_timeout , 3000 }, { monitor_master , true }, { startup_functions , [{ code , set_path , [ CodePath ]}]}], case ct_slave : start ( Name , NodeConfig ) of { ok , Node } -> % Load application to allow configuring the environment before starting ok = rpc : call ( Node , application , load , [ riak_core ]), ok = rpc : call ( Node , application , load , [ rclref ]), % Get remote working dir of node % NodeWorkingDir is .../rclref/_build/test/logs/ct_run.test@127.0.0.1.2020-00-00_00.00.00 { ok , NodeWorkingDir } = rpc : call ( Node , file , get_cwd , []), SuiteName = proplists : get_value ( module , Config , '' ), % Data Dirs ok = rpc : call ( Node , application , set_env , [ riak_core , ring_state_dir , filename : join ([ NodeWorkingDir , \"suites\" , SuiteName , Node , \"data/ring\" ])]), ok = rpc : call ( Node , application , set_env , [ riak_core , platform_data_dir , filename : join ([ NodeWorkingDir , \"suites\" , SuiteName , Node , \"data\" ])]), ok = rpc : call ( Node , application , set_env , [ riak_core , schema_dirs , filename : join ([ NodeWorkingDir , \"suites\" , SuiteName , Node , \"data\" ])]), % Set ports ok = rpc : call ( Node , application , set_env , [ riak_core , handoff_port , Port ]), ok = rpc : call ( Node , application , set_env , [ rclref , http_port , Port + 1 ]), % Logging Configuration LogRoot = filename : join ([ NodeWorkingDir , \"suites\" , SuiteName , Node , \"logs\" ]), ok = rpc : call ( Node , application , set_env , [ rclref , logger , log_config ( LogRoot )]), rpc : call ( Node , logger , set_primary_config , [ level , all ]), rpc : call ( Node , logger , add_handlers , [ rclref ]), % redirect slave logs to ct_master logs ok = rpc : call ( Node , application , set_env , [ rclref , ct_master , node ()]), ConfLog = #{ level => debug , formatter => { logger_formatter , #{ single_line => true , max_size => 2048 }}, config => #{ type => standard_io }}, _ = rpc : call ( Node , logger , add_handler , [ rclref_redirect_ct , ct_redirect_handler , ConfLog ]), % Configuration ok = rpc : call ( Node , application , set_env , [ riak_core , ring_creation_size , 8 ]), { ok , _} = rpc : call ( Node , application , ensure_all_started , [ riak_core ]), { ok , _} = rpc : call ( Node , application , ensure_all_started , [ rclref ]), ct : pal ( \"Node ~p stated with (handoff) port ~p \" , [ Node , Port ]), { connect , Node }; { error , already_started , Node } -> ct : log ( \"Node ~p already started, reusing node\" , [ Node ]), { ready , Node }; { error , Reason , Node } -> ct : pal ( \"Error starting node ~p , reason ~p , will retry\" , [ Node , Reason ]), ct_slave : stop ( Name ), time_utils : wait_until_offline ( Node ), start_node ( Name , Port , Config ) end . start_node/3 is the main fuction for starting up the nodes. As soon as the slave node has started by using ct_slave:start/2 , it is loading the applicaiton by rpc calls, such as ok = rpc:call(Node, application, load, [riak_core]) and ok = rpc:call(Node, application, load, [rclref]) . Once these are called, you can update the environment vairbales from the default values with rpc:call(Node, appcliation, set_env, [...]) . In rclref, setting environmental values such as where to store the riak_core related data and which port is used for handoff and http communication are managed this way. % Logging Configuration LogRoot = filename : join ([ NodeWorkingDir , \"suites\" , SuiteName , Node , \"logs\" ]), ok = rpc : call ( Node , application , set_env , [ rclref , logger , log_config ( LogRoot )]), The snippet above is for setting up the logging environment. LogRoot is the log directory for each node. In rclref, nodes are not reused for each test suite for saftey reasons so logs are seperated from each suite. For test suite that uses two nodes, the log directory looks like the following. | -- handoff_SUITE | | -- node1@localhost | | | -- data | | | ` -- ring | | | | -- riak_core_ring.default.20200817183651 | | | ` -- riak_core_ring.default.20200817183720 | | ` -- logs | | | -- debug.log | | | -- error.log | | | -- info.log | | | -- notice.log | | ` -- warning.log | ` -- node2@localhost | | -- data | | ` -- ring | | | -- riak_core_ring.default.20200817183650 | | | -- riak_core_ring.default.20200817183710 | | ` -- riak_core_ring.default.20200817183720 | ` -- logs | | -- debug.log | | -- error.log | | -- info.log | | -- notice.log | ` -- warning.log","title":"How to test distributed Erlang application using Common Test?"},{"location":"usage/","text":"How to actually use rclref? This page descirbes how to use rclref as a key-value store. First start the application by make , make console . UserAPI Get a Key-Value with key = dog ( rclref @ 127 . 0 . 0 . 1 ) 1 > rclref_client : get ( << \"dog\" >> ). { error , not_found } Store a Key-Value with key = dog, value = cat ( rclref @ 127 . 0 . 0 . 1 ) 2 > rclref_client : put ( << \"dog\" >> , << \"cat\" >> ). ok Get a Key-Value with key = dog ( rclref @ 127 . 0 . 0 . 1 ) 3 > rclref_client : get ( << \"dog\" >> ). { ok ,[ << \"cat\" >> , << \"cat\" >> , << \"cat\" >> ]} List all keys ( rclref @ 127 . 0 . 0 . 1 ) 4 > rclref_client : list_keys (). { ok ,[ << \"dog\" >> ]} Delete a Key-Value with key = dog. (Internally, this will not delete the value but leave it as a tombstone) ( rclref @ 127 . 0 . 0 . 1 ) 5 > rclref_client : delete ( << \"dog\" >> ). ok Get a Key-Value with key = dog. Note that tombstones are not observable. ( rclref @ 127 . 0 . 0 . 1 ) 6 > rclref_client : get ( << \"dog\" >> ). { error , not_found } HttpAPI Get a Key-Value with key = dog | = > curl -X GET http://localhost:8080/rclref/dog { \"error\" : { \"code\" : 404 , \"reason\" : \"not_found\" } } Store a Key-Value with key = dog, value = cat | = > curl -X POST http://localhost:8080/rclref/dog -d 'cat' { \"ok\" : { \"code\" : 200 } } Get a Key-Value with key = dog | = > curl -X GET http://localhost:8080/rclref/dog { \"ok\" : { \"code\" : 200 , \"values\" : [ \"cat\" , \"cat\" , \"cat\" ] } } Delete a Key-Value with key = dog. (Internally, this will not delete the value but leave it as a tombstone) | = > curl -X DELETE http://localhost:8080/rclref/dog { \"ok\" : { \"code\" : 200 } } Get a Key-Value with key = dog. Note that tombstones are not observable. | = > curl -X GET http://localhost:8080/rclref/dog { \"error\" : { \"code\" : 404 , \"reason\" : \"not_found\" } }","title":"How to actually use rclref?"},{"location":"usage/#how-to-actually-use-rclref","text":"This page descirbes how to use rclref as a key-value store. First start the application by make , make console .","title":"How to actually use rclref?"},{"location":"usage/#userapi","text":"Get a Key-Value with key = dog ( rclref @ 127 . 0 . 0 . 1 ) 1 > rclref_client : get ( << \"dog\" >> ). { error , not_found } Store a Key-Value with key = dog, value = cat ( rclref @ 127 . 0 . 0 . 1 ) 2 > rclref_client : put ( << \"dog\" >> , << \"cat\" >> ). ok Get a Key-Value with key = dog ( rclref @ 127 . 0 . 0 . 1 ) 3 > rclref_client : get ( << \"dog\" >> ). { ok ,[ << \"cat\" >> , << \"cat\" >> , << \"cat\" >> ]} List all keys ( rclref @ 127 . 0 . 0 . 1 ) 4 > rclref_client : list_keys (). { ok ,[ << \"dog\" >> ]} Delete a Key-Value with key = dog. (Internally, this will not delete the value but leave it as a tombstone) ( rclref @ 127 . 0 . 0 . 1 ) 5 > rclref_client : delete ( << \"dog\" >> ). ok Get a Key-Value with key = dog. Note that tombstones are not observable. ( rclref @ 127 . 0 . 0 . 1 ) 6 > rclref_client : get ( << \"dog\" >> ). { error , not_found }","title":"UserAPI"},{"location":"usage/#httpapi","text":"Get a Key-Value with key = dog | = > curl -X GET http://localhost:8080/rclref/dog { \"error\" : { \"code\" : 404 , \"reason\" : \"not_found\" } } Store a Key-Value with key = dog, value = cat | = > curl -X POST http://localhost:8080/rclref/dog -d 'cat' { \"ok\" : { \"code\" : 200 } } Get a Key-Value with key = dog | = > curl -X GET http://localhost:8080/rclref/dog { \"ok\" : { \"code\" : 200 , \"values\" : [ \"cat\" , \"cat\" , \"cat\" ] } } Delete a Key-Value with key = dog. (Internally, this will not delete the value but leave it as a tombstone) | = > curl -X DELETE http://localhost:8080/rclref/dog { \"ok\" : { \"code\" : 200 } } Get a Key-Value with key = dog. Note that tombstones are not observable. | = > curl -X GET http://localhost:8080/rclref/dog { \"error\" : { \"code\" : 404 , \"reason\" : \"not_found\" } }","title":"HttpAPI"},{"location":"userapi/","text":"UserAPI rclref_client Module rclref_client Module Summary Basic functions for manipulating rclref Description This module provides basic funcitons for reading data from and storing data into rclref, a key-value store on riak-core-lite. put(Key, Value) put(Key, Value, Options) get(Key) get(Key, Options) delete(Key) delete(Key, Options) list_keys() list_keys(Options) put(Key, Value) 1 -spec put(rclref_object:key(), rclref_object:value()) -> ok | {error, timeout} | {error, partial} | {error, term()}. This is equal to rclref_put(Key, Value, []) put(Key, Value, Options) 1 -spec put(rclref_object:key(), rclref_object:value(), [term()]) -> ok | {error, timeout} | {error, partial} | {error, term()}. store a Key-Value in N vnodes. When W vnodes respond with ok or more than N-W number of vnodes respond with an error, this function will return. If neither of these is satisified within TIMEOUT_PUT, then this function will return {error, timeout} Returns ok when W vnodes respond with ok. Returns {error, partial} when at least one of the vnodes (but not more than or equal to W vnodes) responds with ok before getting errors from more than N-W vnodes. Returns {error, [Reason]} when no vnodes respond with ok and more than N-W vnodes respond with an error. [Reason] is a list that contains error reasons of N-W+1 vnodes. Returns {error, timeout} when neither of these above are satisfied within TIMEOUT_PUT milliseconds. get(Key) 1 -spec get(rclref_object:key()) -> {ok, [rclref_object:value()]} | {error, timeout} | {error, partial} | {error, not_found} | {error, term()}. This is equal to get(Key, Value, Options) . get(Key, Options) 1 -spec get(rclref_object:key(), [term()]) -> {ok, [rclref_object:value()]} | {error, timeout} | {error, partial} | {error, not_found} | {error, term()}. get a Key-Value from N vnodes. When R number of vnodes respond with ok or more than N-R number of vnodes respond with an error, this fucntion will return. If neither of these is satisified with TIMEOUT_GET, then this function will return {error, timeout} On get, response from a vnode will be the either of {ok, RObj} , {error, not_found} , {error, Reason} Returns {ok, [Value]} when R vnodes respond with a value. [Value] is a list that contains values from R vnodes. Returns {error, partial} when at least one of the vnodes (but not more than or equal to R vnodes) responds with a value before getting errors from more than N-R vnodes. Returns {error, not_found} when no vnodes respond with a value and more than N-R vnodes respond with a error which are all not_found. Returns {error, [Reason]} when no vnodes respond with a value and more than N-R vnodes respond with a error which are not all not_found. [Reason] is a list that contains error reasons of N-R+1 vnodes. Returns {error, timeout} when neither of these above is satisified within TIMEOUT_GET milliseconds. delete(Key) 1 -spec delete(rclref_object:key()) -> ok | {error, timeout} | {error, partial} | {error, term()}. This is equal to delete(Key, []) . delete(Key, Options) 1 -spec delete(rclref_object:key(), [term()]) -> ok | {error, timeout} | {error, partial} | {error, term()}. This is equal to put(Key, undefined, Options) . Note that this will not delete the Key from the backend, however rclref_client:get(Key) will return {error, not_found} after calling this function. The reason why this is implemeted this way is explained in the [TODO] section. A Key-Value with an undefined value is called a tombstone. list_keys() 1 -spec list_keys() -> {ok, [rclref_object:key()]}. This is equal to list_keys([]) . list_keys(Options) 1 -spec list_keys([term()]) -> {ok, [rclref_object:key()]}. list all unique keys in the backend.","title":"UserAPI"},{"location":"userapi/#userapi","text":"","title":"UserAPI"},{"location":"userapi/#rclref_client","text":"","title":"rclref_client"},{"location":"userapi/#module","text":"rclref_client","title":"Module"},{"location":"userapi/#module-summary","text":"Basic functions for manipulating rclref","title":"Module Summary"},{"location":"userapi/#description","text":"This module provides basic funcitons for reading data from and storing data into rclref, a key-value store on riak-core-lite. put(Key, Value) put(Key, Value, Options) get(Key) get(Key, Options) delete(Key) delete(Key, Options) list_keys() list_keys(Options)","title":"Description"},{"location":"userapi/#putkey-value","text":"1 -spec put(rclref_object:key(), rclref_object:value()) -> ok | {error, timeout} | {error, partial} | {error, term()}. This is equal to rclref_put(Key, Value, [])","title":"put(Key, Value)"},{"location":"userapi/#putkey-value-options","text":"1 -spec put(rclref_object:key(), rclref_object:value(), [term()]) -> ok | {error, timeout} | {error, partial} | {error, term()}. store a Key-Value in N vnodes. When W vnodes respond with ok or more than N-W number of vnodes respond with an error, this function will return. If neither of these is satisified within TIMEOUT_PUT, then this function will return {error, timeout} Returns ok when W vnodes respond with ok. Returns {error, partial} when at least one of the vnodes (but not more than or equal to W vnodes) responds with ok before getting errors from more than N-W vnodes. Returns {error, [Reason]} when no vnodes respond with ok and more than N-W vnodes respond with an error. [Reason] is a list that contains error reasons of N-W+1 vnodes. Returns {error, timeout} when neither of these above are satisfied within TIMEOUT_PUT milliseconds.","title":"put(Key, Value, Options)"},{"location":"userapi/#getkey","text":"1 -spec get(rclref_object:key()) -> {ok, [rclref_object:value()]} | {error, timeout} | {error, partial} | {error, not_found} | {error, term()}. This is equal to get(Key, Value, Options) .","title":"get(Key)"},{"location":"userapi/#getkey-options","text":"1 -spec get(rclref_object:key(), [term()]) -> {ok, [rclref_object:value()]} | {error, timeout} | {error, partial} | {error, not_found} | {error, term()}. get a Key-Value from N vnodes. When R number of vnodes respond with ok or more than N-R number of vnodes respond with an error, this fucntion will return. If neither of these is satisified with TIMEOUT_GET, then this function will return {error, timeout} On get, response from a vnode will be the either of {ok, RObj} , {error, not_found} , {error, Reason} Returns {ok, [Value]} when R vnodes respond with a value. [Value] is a list that contains values from R vnodes. Returns {error, partial} when at least one of the vnodes (but not more than or equal to R vnodes) responds with a value before getting errors from more than N-R vnodes. Returns {error, not_found} when no vnodes respond with a value and more than N-R vnodes respond with a error which are all not_found. Returns {error, [Reason]} when no vnodes respond with a value and more than N-R vnodes respond with a error which are not all not_found. [Reason] is a list that contains error reasons of N-R+1 vnodes. Returns {error, timeout} when neither of these above is satisified within TIMEOUT_GET milliseconds.","title":"get(Key, Options)"},{"location":"userapi/#deletekey","text":"1 -spec delete(rclref_object:key()) -> ok | {error, timeout} | {error, partial} | {error, term()}. This is equal to delete(Key, []) .","title":"delete(Key)"},{"location":"userapi/#deletekey-options","text":"1 -spec delete(rclref_object:key(), [term()]) -> ok | {error, timeout} | {error, partial} | {error, term()}. This is equal to put(Key, undefined, Options) . Note that this will not delete the Key from the backend, however rclref_client:get(Key) will return {error, not_found} after calling this function. The reason why this is implemeted this way is explained in the [TODO] section. A Key-Value with an undefined value is called a tombstone.","title":"delete(Key, Options)"},{"location":"userapi/#list_keys","text":"1 -spec list_keys() -> {ok, [rclref_object:key()]}. This is equal to list_keys([]) .","title":"list_keys()"},{"location":"userapi/#list_keysoptions","text":"1 -spec list_keys([term()]) -> {ok, [rclref_object:key()]}. list all unique keys in the backend.","title":"list_keys(Options)"},{"location":"vnodes/","text":"Vnodes This page will explain how to implement the vnode module, rclref_vnode.erl in detail. Warning Please check out the repository for the latest code. All commands requested by the user will eventually become commands to the vnode sent from the coordiantor. Commands to the vnode will be handled by handle_command function in the vnode module, which is rclref_vnode.erl in rclref. Let's look at how they are implemented for each request. initializing Before understanding how a vnode handles a request, let's look at how it initializes. %% API start_vnode ( I ) -> riak_core_vnode_master : get_vnode_pid ( I , ? MODULE ). init ([ Partition ]) -> Mod = case rclref_config : storage_backend () of ets -> rclref_ets_backend ; dets -> rclref_dets_backend ; _ -> ? assert ( false ) end , { ok , ModState } = Mod : start ( Partition , []), logger : debug ( \"Successfully started ~p backend for partition ~p \" , [ Mod , Partition ]), State = #state { partition = Partition , mod = Mod , modstate = ModState }, { ok , State }. On initialization, it choose the backend module by reading the configuration and start a database (ets or dets) process. put A put request from the client will be converted to {kv_put_request, RObj, Pid, Node} by the coordinator. RObj stands for riak_object and this is a wrapper that wraps the basic components of the key-value object which is defined in riak_object.erl . - record ( r_content , { value :: value (), vclock = vectorclock : new () :: vclock ()}). - record ( r_object , { key :: key (), r_content :: #r_content {}, partition :: non_neg_integer () | undefined , node :: node () | undefined }). Pid is the process id of the put coordinator for the vnode to send back the results. Node is the node of the client to update the vector clock. handle_command ({ kv_put_request , RObj , Pid , Node }, _ Sender , State0 = #state { partition = Partition , mod = Mod , modstate = ModState0 }) -> Key = rclref_object : key ( RObj ), Value = rclref_object : value ( RObj ), % get will be issued before put % If a key is new to backend, store it with a new vector clock % If a key is not new to backend, store it with an updated vector clock % If get returns an error, put will be ignored case Mod : get ( Key , ModState0 ) of { ok , not_found , ModState1 } -> % Create content with a new vector clock VClock = rclref_object : new_vclock (), NewVClock = rclref_object : increment_vclock ( Node , VClock ), NewContent = rclref_object : new_content ( Value , NewVClock ), case Mod : put ( Key , NewContent , ModState1 ) of { ok , ModState2 } -> NewRObj = rclref_object : new ( Key , NewContent , Partition , node ()), rclref_put_statem : result_of_put ( Pid , { ok , NewRObj }), State1 = State0 #state { modstate = ModState2 }, { noreply , State1 }; { error , Reason , ModState2 } -> logger : error ( \"Failed to put kv with key: ~p , content: ~p for partition: ~p , \" \"error: ~p \" , [ Key , NewContent , Partition , Reason ]), VnodeError = rclref_object : new_error ( Reason , Partition , node ()), rclref_put_statem : result_of_put ( Pid , { error , VnodeError }), State1 = State0 #state { modstate = ModState2 }, { noreply , State1 } end ; { ok , Content , ModState1 } -> % Create content with an updated vector clock VClock = rclref_object : vclock ( Content ), NewVClock = rclref_object : increment_vclock ( Node , VClock ), NewContent = rclref_object : new_content ( Value , NewVClock ), case Mod : put ( Key , NewContent , ModState1 ) of { ok , ModState2 } -> NewRObj = rclref_object : new ( Key , NewContent , Partition , node ()), rclref_put_statem : result_of_put ( Pid , { ok , NewRObj }), State1 = State0 #state { modstate = ModState2 }, { noreply , State1 }; { error , Reason , ModState2 } -> logger : error ( \"Failed to put kv with key: ~p , content: ~p for partition: ~p , \" \"error: ~p \" , [ Key , NewContent , Partition , Reason ]), VnodeError = rclref_object : new_error ( Reason , Partition , node ()), rclref_put_statem : result_of_put ( Pid , { error , VnodeError }), State1 = State0 #state { modstate = ModState2 }, { noreply , State1 } end ; { error , Reason , ModState1 } -> logger : error ( \"Failed to get kv (before put) with key: ~p for partition: ~p , \" \"error: ~p \" , [ Key , Partition , Reason ]), VnodeError = rclref_object : new_error ( Reason , Partition , node ()), rclref_put_statem : result_of_put ( Pid , { error , VnodeError }), State1 = State0 #state { modstate = ModState1 }, { noreply , State1 } end ; As commneted in the snippet above, a get to the database will be executed before the put request to see if the key is new or not. If the key is not new, it will have to update the vectorclock of the object and put the new value. If the key is new, it will just put the value. If the put succeed, it will call rclref_put_statem:result_of_put(Pid, {ok, NewRObj}) to notify the put coordinator that put has succeeded. If the put errored, it will call rclref_put_statem:result_of_put(Pid, {error, VnodeError}) to nofity the put coordinator that put has failed. get A get request is converted to {kv_get_request, Key, Pid} . Pid is the process id of the get coordinator. handle_command ({ kv_get_request , Key , Pid }, _ Sender , State0 = #state { partition = Partition , mod = Mod , modstate = ModState0 }) -> case Mod : get ( Key , ModState0 ) of { ok , not_found , ModState1 } -> VnodeError = rclref_object : new_error ( not_found , Partition , node ()), ok = rclref_get_statem : result_of_get ( Pid , { error , VnodeError }), State1 = State0 #state { modstate = ModState1 }, { noreply , State1 }; { ok , Content , ModState1 } -> RObj = rclref_object : new ( Key , Content , Partition , node ()), ok = rclref_get_statem : result_of_get ( Pid , { ok , RObj }), State1 = State0 #state { modstate = ModState1 }, { noreply , State1 }; { error , Reason , ModState1 } -> logger : error ( \"Failed to get kv with key: ~p for partition: ~p , error: ~p \" , [ Key , Partition , Reason ]), VnodeError = rclref_object : new_error ( Reason , Partition , node ()), rclref_get_statem : result_of_get ( Pid , { error , VnodeError }), State1 = State0 #state { modstate = ModState1 }, { noreply , State1 } end ; It will simply get the Key from the backend and return the results to the get coordinator. If the get succeeded, rclref_get_statem:result_of_get(Pid, {ok, RObj}) will be called. If the get errored or the key was not_found, rclref_get_statem:result_of_get(Pid, {error, VnodeError}) will be called. delete A delete request form the client is acutally converted to a put request with Key=Key, Value=undefined by the LowLevelAPI ( rclref.erl ). This means that the key is not completely deleted from the backend after the delete request. The reason why it is implemeted this way is to have better fault tolerancy. See the vector clock section in the other ' page. A key-value with undefined value is called a tombstone. handoff Handoff is a mechanism used when riak_core_lite decides to relocate a vnode to another node. There are two major types of handoffs depending on the context. Hinted Handoff To ensure high availability of the database, riak-core allows writing even when the primary node responsible for the write is down by making another node take over the responsibility. This node is called secondary node or fallback node. When the primary node returns to service, the vnodes in the secondary node will pass back the data it has to the vnodes in the primary node. This exchange of data is called hinted handoff. Ownership Handoff An ownership handoff happens when a cluster member joins or leaves the cluster. Changes to the cluster will cause reassignment of vnodes to nodes which will trigger the handoff of data. This handoff is called ownership handoff. Implementing the following functions in the vnode module is required in order to activate handoff. handle_handoff_command ( #riak_core_fold_req_v2 { foldfun = FoldFun , acc0 = Acc0 }, _ Sender , State = #state { mod = Mod , modstate = ModState }) -> % FoldFun % -type fold_objects_fun() :: fun((term(), term(), any()) -> any() | no_return()). Acc = Mod : fold_objects ( FoldFun , Acc0 , [], ModState ), { reply , Acc , State }; handle_handoff_command ( Message , _ Sender , State ) -> logger : warning ( \"handoff command ~p , ignoring\" , [ Message ]), { noreply , State }. handoff_starting ( TargetNode , State = #state { partition = Partition }) -> logger : info ( \"handoff starting ~p : ~p \" , [ Partition , TargetNode ]), { true , State }. handoff_cancelled ( State = #state { partition = Partition }) -> logger : info ( \"handoff cancelled ~p \" , [ Partition ]), { ok , State }. handoff_finished ( TargetNode , State = #state { partition = Partition }) -> logger : info ( \"handoff finished ~p : ~p \" , [ Partition , TargetNode ]), { ok , State }. handle_handoff_data ( BinData , State0 = #state { partition = Partition , mod = Mod , modstate = ModState0 }) -> { Key , Content } = binary_to_term ( BinData ), logger : info ( \"handoff data received ~p : ~p \" , [ Partition , Key ]), { ok , ModState1 } = Mod : put ( Key , Content , ModState0 ), State1 = State0 #state { modstate = ModState1 }, { reply , ok , State1 }. encode_handoff_item ( Key , Content ) -> term_to_binary ({ Key , Content }). handle_overload_command (_, _, _) -> ok . handle_overload_info (_, _ Idx ) -> ok . is_empty ( State = #state { mod = Mod , modstate = ModState }) -> case Mod : is_empty ( ModState ) of true -> logger : info ( \"is_empty: ~p \" , [ true ]), { true , State }; false -> logger : info ( \"is_empty: ~p \" , [ false ]), { false , State }; Other -> logger : error ( \"is_empty error reason : ~p \" , [ Other ]), { false , State } end . delete ( State0 = #state { partition = Partition , mod = Mod , modstate = ModState0 }) -> logger : info ( \"delete partition: ~p \" , [ Partition ]), { ok , ModState1 } = Mod : drop ( ModState0 ), ok = Mod : stop ( ModState1 ), State1 = State0 #state { modstate = ModState1 }, { ok , State1 }. coverage Coverage calls are used for operations that involve the entire key space. For such operations, it is necessary to gather responses from all the vnodes. For example, in order to obtain a list of keys in the database, it needs to ask all the vnodes because keys are distributed around the cluster. 4 types coverage calls are supported in rclref in the LowLevelAPI. list_unique_keys list_all_keys list_unique_objects list_all_objects In order to implement coverage calls, what we need to do first is to migrate riak_core_coverage_fsm.erl and riak_core_coverage_plan to our repository is needed at the moment. These modules come from the riak_core project because they are currently omitted from riak_core_lite . They are planned to be added to the riak_core_lite_util repository after updating the fsm to gen_statem. The handler for coverage calls are implemented in the following way. handle_coverage ({_, keys }, _ KeySpaces , {_, ReqId , _}, State0 = #state { partition = _ Partition , mod = Mod , modstate = ModState0 }) -> Acc0 = [], Fun = fun ( Key , Accum ) -> [ Key ] ++ Accum end , Acc1 = Mod : fold_keys ( Fun , Acc0 , ModState0 ), { reply , { ReqId , Acc1 }, State0 }; handle_coverage ({_, objects }, _ KeySpaces , {_, ReqId , _}, State0 = #state { partition = Partition , mod = Mod , modstate = ModState0 }) -> Acc0 = [], Fun = fun ( Key , Content , Accum ) -> [ rclref_object : new ( Key , Content , Partition , node ())] ++ Accum end , Acc1 = Mod : fold_objects ( Fun , Acc0 , ModState0 ), { reply , { ReqId , Acc1 }, State0 }.","title":"Vnodes"},{"location":"vnodes/#vnodes","text":"This page will explain how to implement the vnode module, rclref_vnode.erl in detail. Warning Please check out the repository for the latest code. All commands requested by the user will eventually become commands to the vnode sent from the coordiantor. Commands to the vnode will be handled by handle_command function in the vnode module, which is rclref_vnode.erl in rclref. Let's look at how they are implemented for each request.","title":"Vnodes"},{"location":"vnodes/#initializing","text":"Before understanding how a vnode handles a request, let's look at how it initializes. %% API start_vnode ( I ) -> riak_core_vnode_master : get_vnode_pid ( I , ? MODULE ). init ([ Partition ]) -> Mod = case rclref_config : storage_backend () of ets -> rclref_ets_backend ; dets -> rclref_dets_backend ; _ -> ? assert ( false ) end , { ok , ModState } = Mod : start ( Partition , []), logger : debug ( \"Successfully started ~p backend for partition ~p \" , [ Mod , Partition ]), State = #state { partition = Partition , mod = Mod , modstate = ModState }, { ok , State }. On initialization, it choose the backend module by reading the configuration and start a database (ets or dets) process.","title":"initializing"},{"location":"vnodes/#put","text":"A put request from the client will be converted to {kv_put_request, RObj, Pid, Node} by the coordinator. RObj stands for riak_object and this is a wrapper that wraps the basic components of the key-value object which is defined in riak_object.erl . - record ( r_content , { value :: value (), vclock = vectorclock : new () :: vclock ()}). - record ( r_object , { key :: key (), r_content :: #r_content {}, partition :: non_neg_integer () | undefined , node :: node () | undefined }). Pid is the process id of the put coordinator for the vnode to send back the results. Node is the node of the client to update the vector clock. handle_command ({ kv_put_request , RObj , Pid , Node }, _ Sender , State0 = #state { partition = Partition , mod = Mod , modstate = ModState0 }) -> Key = rclref_object : key ( RObj ), Value = rclref_object : value ( RObj ), % get will be issued before put % If a key is new to backend, store it with a new vector clock % If a key is not new to backend, store it with an updated vector clock % If get returns an error, put will be ignored case Mod : get ( Key , ModState0 ) of { ok , not_found , ModState1 } -> % Create content with a new vector clock VClock = rclref_object : new_vclock (), NewVClock = rclref_object : increment_vclock ( Node , VClock ), NewContent = rclref_object : new_content ( Value , NewVClock ), case Mod : put ( Key , NewContent , ModState1 ) of { ok , ModState2 } -> NewRObj = rclref_object : new ( Key , NewContent , Partition , node ()), rclref_put_statem : result_of_put ( Pid , { ok , NewRObj }), State1 = State0 #state { modstate = ModState2 }, { noreply , State1 }; { error , Reason , ModState2 } -> logger : error ( \"Failed to put kv with key: ~p , content: ~p for partition: ~p , \" \"error: ~p \" , [ Key , NewContent , Partition , Reason ]), VnodeError = rclref_object : new_error ( Reason , Partition , node ()), rclref_put_statem : result_of_put ( Pid , { error , VnodeError }), State1 = State0 #state { modstate = ModState2 }, { noreply , State1 } end ; { ok , Content , ModState1 } -> % Create content with an updated vector clock VClock = rclref_object : vclock ( Content ), NewVClock = rclref_object : increment_vclock ( Node , VClock ), NewContent = rclref_object : new_content ( Value , NewVClock ), case Mod : put ( Key , NewContent , ModState1 ) of { ok , ModState2 } -> NewRObj = rclref_object : new ( Key , NewContent , Partition , node ()), rclref_put_statem : result_of_put ( Pid , { ok , NewRObj }), State1 = State0 #state { modstate = ModState2 }, { noreply , State1 }; { error , Reason , ModState2 } -> logger : error ( \"Failed to put kv with key: ~p , content: ~p for partition: ~p , \" \"error: ~p \" , [ Key , NewContent , Partition , Reason ]), VnodeError = rclref_object : new_error ( Reason , Partition , node ()), rclref_put_statem : result_of_put ( Pid , { error , VnodeError }), State1 = State0 #state { modstate = ModState2 }, { noreply , State1 } end ; { error , Reason , ModState1 } -> logger : error ( \"Failed to get kv (before put) with key: ~p for partition: ~p , \" \"error: ~p \" , [ Key , Partition , Reason ]), VnodeError = rclref_object : new_error ( Reason , Partition , node ()), rclref_put_statem : result_of_put ( Pid , { error , VnodeError }), State1 = State0 #state { modstate = ModState1 }, { noreply , State1 } end ; As commneted in the snippet above, a get to the database will be executed before the put request to see if the key is new or not. If the key is not new, it will have to update the vectorclock of the object and put the new value. If the key is new, it will just put the value. If the put succeed, it will call rclref_put_statem:result_of_put(Pid, {ok, NewRObj}) to notify the put coordinator that put has succeeded. If the put errored, it will call rclref_put_statem:result_of_put(Pid, {error, VnodeError}) to nofity the put coordinator that put has failed.","title":"put"},{"location":"vnodes/#get","text":"A get request is converted to {kv_get_request, Key, Pid} . Pid is the process id of the get coordinator. handle_command ({ kv_get_request , Key , Pid }, _ Sender , State0 = #state { partition = Partition , mod = Mod , modstate = ModState0 }) -> case Mod : get ( Key , ModState0 ) of { ok , not_found , ModState1 } -> VnodeError = rclref_object : new_error ( not_found , Partition , node ()), ok = rclref_get_statem : result_of_get ( Pid , { error , VnodeError }), State1 = State0 #state { modstate = ModState1 }, { noreply , State1 }; { ok , Content , ModState1 } -> RObj = rclref_object : new ( Key , Content , Partition , node ()), ok = rclref_get_statem : result_of_get ( Pid , { ok , RObj }), State1 = State0 #state { modstate = ModState1 }, { noreply , State1 }; { error , Reason , ModState1 } -> logger : error ( \"Failed to get kv with key: ~p for partition: ~p , error: ~p \" , [ Key , Partition , Reason ]), VnodeError = rclref_object : new_error ( Reason , Partition , node ()), rclref_get_statem : result_of_get ( Pid , { error , VnodeError }), State1 = State0 #state { modstate = ModState1 }, { noreply , State1 } end ; It will simply get the Key from the backend and return the results to the get coordinator. If the get succeeded, rclref_get_statem:result_of_get(Pid, {ok, RObj}) will be called. If the get errored or the key was not_found, rclref_get_statem:result_of_get(Pid, {error, VnodeError}) will be called.","title":"get"},{"location":"vnodes/#delete","text":"A delete request form the client is acutally converted to a put request with Key=Key, Value=undefined by the LowLevelAPI ( rclref.erl ). This means that the key is not completely deleted from the backend after the delete request. The reason why it is implemeted this way is to have better fault tolerancy. See the vector clock section in the other ' page. A key-value with undefined value is called a tombstone.","title":"delete"},{"location":"vnodes/#handoff","text":"Handoff is a mechanism used when riak_core_lite decides to relocate a vnode to another node. There are two major types of handoffs depending on the context. Hinted Handoff To ensure high availability of the database, riak-core allows writing even when the primary node responsible for the write is down by making another node take over the responsibility. This node is called secondary node or fallback node. When the primary node returns to service, the vnodes in the secondary node will pass back the data it has to the vnodes in the primary node. This exchange of data is called hinted handoff. Ownership Handoff An ownership handoff happens when a cluster member joins or leaves the cluster. Changes to the cluster will cause reassignment of vnodes to nodes which will trigger the handoff of data. This handoff is called ownership handoff. Implementing the following functions in the vnode module is required in order to activate handoff. handle_handoff_command ( #riak_core_fold_req_v2 { foldfun = FoldFun , acc0 = Acc0 }, _ Sender , State = #state { mod = Mod , modstate = ModState }) -> % FoldFun % -type fold_objects_fun() :: fun((term(), term(), any()) -> any() | no_return()). Acc = Mod : fold_objects ( FoldFun , Acc0 , [], ModState ), { reply , Acc , State }; handle_handoff_command ( Message , _ Sender , State ) -> logger : warning ( \"handoff command ~p , ignoring\" , [ Message ]), { noreply , State }. handoff_starting ( TargetNode , State = #state { partition = Partition }) -> logger : info ( \"handoff starting ~p : ~p \" , [ Partition , TargetNode ]), { true , State }. handoff_cancelled ( State = #state { partition = Partition }) -> logger : info ( \"handoff cancelled ~p \" , [ Partition ]), { ok , State }. handoff_finished ( TargetNode , State = #state { partition = Partition }) -> logger : info ( \"handoff finished ~p : ~p \" , [ Partition , TargetNode ]), { ok , State }. handle_handoff_data ( BinData , State0 = #state { partition = Partition , mod = Mod , modstate = ModState0 }) -> { Key , Content } = binary_to_term ( BinData ), logger : info ( \"handoff data received ~p : ~p \" , [ Partition , Key ]), { ok , ModState1 } = Mod : put ( Key , Content , ModState0 ), State1 = State0 #state { modstate = ModState1 }, { reply , ok , State1 }. encode_handoff_item ( Key , Content ) -> term_to_binary ({ Key , Content }). handle_overload_command (_, _, _) -> ok . handle_overload_info (_, _ Idx ) -> ok . is_empty ( State = #state { mod = Mod , modstate = ModState }) -> case Mod : is_empty ( ModState ) of true -> logger : info ( \"is_empty: ~p \" , [ true ]), { true , State }; false -> logger : info ( \"is_empty: ~p \" , [ false ]), { false , State }; Other -> logger : error ( \"is_empty error reason : ~p \" , [ Other ]), { false , State } end . delete ( State0 = #state { partition = Partition , mod = Mod , modstate = ModState0 }) -> logger : info ( \"delete partition: ~p \" , [ Partition ]), { ok , ModState1 } = Mod : drop ( ModState0 ), ok = Mod : stop ( ModState1 ), State1 = State0 #state { modstate = ModState1 }, { ok , State1 }.","title":"handoff"},{"location":"vnodes/#coverage","text":"Coverage calls are used for operations that involve the entire key space. For such operations, it is necessary to gather responses from all the vnodes. For example, in order to obtain a list of keys in the database, it needs to ask all the vnodes because keys are distributed around the cluster. 4 types coverage calls are supported in rclref in the LowLevelAPI. list_unique_keys list_all_keys list_unique_objects list_all_objects In order to implement coverage calls, what we need to do first is to migrate riak_core_coverage_fsm.erl and riak_core_coverage_plan to our repository is needed at the moment. These modules come from the riak_core project because they are currently omitted from riak_core_lite . They are planned to be added to the riak_core_lite_util repository after updating the fsm to gen_statem. The handler for coverage calls are implemented in the following way. handle_coverage ({_, keys }, _ KeySpaces , {_, ReqId , _}, State0 = #state { partition = _ Partition , mod = Mod , modstate = ModState0 }) -> Acc0 = [], Fun = fun ( Key , Accum ) -> [ Key ] ++ Accum end , Acc1 = Mod : fold_keys ( Fun , Acc0 , ModState0 ), { reply , { ReqId , Acc1 }, State0 }; handle_coverage ({_, objects }, _ KeySpaces , {_, ReqId , _}, State0 = #state { partition = Partition , mod = Mod , modstate = ModState0 }) -> Acc0 = [], Fun = fun ( Key , Content , Accum ) -> [ rclref_object : new ( Key , Content , Partition , node ())] ++ Accum end , Acc1 = Mod : fold_objects ( Fun , Acc0 , ModState0 ), { reply , { ReqId , Acc1 }, State0 }.","title":"coverage"}]}